var searchDocuments = {"references/eClassifiers/Kernel/inheritance.html":{"path":"Kernel/Inheritance","link-uuid":"21b12a12-e870-4192-bc9c-cdadb55070b0","title":"Inheritance","content":"Supertypes ","timestamp":1763300447590},"references/eClassifiers/OpenAITextGenerationService/inheritance.html":{"path":"OpenAITextGenerationService/Inheritance","link-uuid":"8203009f-e98d-4747-9421-baa6f16c1501","title":"Inheritance","content":"Supertypes ","timestamp":1763300447714},"references/eClassifiers/OpenAIChatCompletion/index.html":{"link-uuid":"1ceeb598-001d-431e-b5b2-b293d95f8ba6","title":"OpenAIChatCompletion","content":"OpenAIChatCompletion in Microsoft Semantic Kernel Java The OpenAIChatCompletion in Microsoft Semantic Kernel for Java enables integration with OpenAI&rsquo;s chat completion API. This service allows developers to simulate a back-and-forth conversation with an AI agent using the OpenAI language models. Here&rsquo;s how you can use OpenAIChatCompletion in your Java project: Maven Dependency Ensure that you include the required Maven artifact for Microsoft Semantic Kernel OpenAI services in your pom.xml: &lt;dependency&gt;\n    &lt;groupId&gt;com.microsoft.semantic-kernel&lt;/groupId&gt;\n    &lt;artifactId&gt;semantickernel-aiservices-openai&lt;/artifactId&gt;\n    &lt;version&gt;1.4.0&lt;/version&gt;\n&lt;/dependency&gt;\n Creating the Client and Service To begin using the OpenAIChatCompletion service, you&rsquo;ll first need to set up an OpenAI client and use it to create a chat completion service: import com.azure.ai.openai.OpenAIAsyncClient;\nimport com.azure.ai.openai.OpenAIClientBuilder;\nimport com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;\nimport com.microsoft.semantickernel.aiservices.openai.chatcompletion.OpenAIChatCompletion;\n\n// Create the client\nOpenAIAsyncClient client = new OpenAIClientBuilder()\n    .credential(openAIClientCredentials)\n    .buildAsyncClient();\n\n// Create the chat completion service\nChatCompletionService openAIChatCompletion = OpenAIChatCompletion.builder()\n    .withOpenAIAsyncClient(client)\n    .withModelId(modelId)\n    .build();\n\n// Initialize the kernel\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, openAIChatCompletion)\n    .build();\n Using the Chat Completion Service Once the OpenAIChatCompletion service has been set up, you can initiate a conversation with the AI by sending prompts and receiving responses: import com.microsoft.semantickernel.services.chatcompletion.ChatHistory;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatMessageContent;\n\n// Create a history object to store the conversation\nChatHistory history = new ChatHistory();\nhistory.addUserMessage(&quot;Hello, how are you?&quot;);\n\n// Get chat completion responses\nChatCompletionService chatCompletionService = kernel.getService(ChatCompletionService.class);\nList&lt;ChatMessageContent&lt;?&gt;&gt; response = chatCompletionService.getChatMessageContentsAsync(\n    history,\n    kernel,\n    null  // Optional InvocationContext\n).block();\n\n// Print the AI's response\nresponse.forEach(result -&gt; {\n    if (result.getAuthorRole() == AuthorRole.ASSISTANT &amp;&amp; result.getContent() != null) {\n        System.out.println(&quot;Assistant &gt; &quot; + result.getContent());\n    }\n});\n Important Considerations Asynchronous Client: The OpenAIAsyncClient is used to handle asynchronous tasks and retrieve responses from the AI service efficiently. Chat History: Maintain a ChatHistory to keep track of the conversation&rsquo;s state, allowing the AI to understand context over multiple exchanges. Handle Responses: The response from the AI can be iterated over to handle each message, allowing conditional processing based on the message role (e.g., User or Assistant). This setup provides a simple way to leverage OpenAI&rsquo;s language models to create interactive and dynamic AI-driven applications within the Java ecosystem using Microsoft Semantic Kernel. Diagram ","timestamp":1763300447668},"references/eClassifiers/PromptTemplateConfig/references/eStructuralFeatures/template/index.html":{"path":"PromptTemplateConfig/Attributes/template","link-uuid":"f14aa508-592f-4cdb-877e-e5b5a36782f9","title":"template","content":"Type EString Multiplicity 0..1 The PromptTemplateConfig class in the Microsoft Semantic Kernel Java SDK is used to configure a prompt template. One of its key properties is the template, which defines the prompt string itself. This property is crucial because it holds the actual template that defines the structure and content of the prompt that will be used with AI services. Here&rsquo;s an example of using the template property in Java: import com.microsoft.semantickernel.semanticfunctions.*;\n\npublic class PromptTemplateExample {\n    public static void main(String[] args) {\n        // Create a new PromptTemplateConfig.Builder instance to set up our template configuration\n        PromptTemplateConfig.Builder builder = new PromptTemplateConfig.Builder();\n\n        // Set the template for the prompt\n        builder.withTemplate(&quot;Tell a story about {{$topic}} that is {{$length}} sentences long.&quot;);\n\n        // Build the PromptTemplateConfig\n        PromptTemplateConfig promptConfig = builder.build();\n\n        // Access the template property\n        String template = promptConfig.getTemplate();\n        System.out.println(&quot;Prompt Template: &quot; + template);\n    }\n}\n This snippet demonstrates how to set and retrieve the prompt template string using the PromptTemplateConfig class in Java. The withTemplate method is used to specify the template, which can then be retrieved using the getTemplate() method after the configuration is built. This allows for dynamic template creation and manipulation within Semantic Kernel applications.","timestamp":1763300448029},"references/eClassifiers/GeminiChatCompletion/index.html":{"link-uuid":"1575c8ad-2cec-49b6-951a-a26bd84e837c","title":"GeminiChatCompletion","content":"The GeminiChatCompletion class in Microsoft Semantic Kernel Java is a specialized implementation for generating chat completions using the Gemini model. It is part of the com.microsoft.semantickernel.aiservices.google.chatcompletion package and extends the GeminiService class, implementing the ChatCompletionService interface. Key Features: Builder Pattern: Provides a static builder() method to create instances using a fluent API. Async Methods: Supports asynchronous operations for retrieving chat message contents and streaming chat messages. Constructor: To create an instance of GeminiChatCompletion, you need to pass a VertexAI client and a model ID: VertexAI client = // Initialize your VertexAI client\nString modelId = &quot;your-model-id&quot;;\nGeminiChatCompletion geminiChatCompletion = new GeminiChatCompletion(client, modelId);\n Methods: Async Chat Message Retrieval: Use getChatMessageContentsAsync to retrieve chat messages asynchronously. ChatHistory chatHistory = new ChatHistory();  // Assume this is initialized\nKernel kernel = new Kernel();  // Assume this is initialized\nInvocationContext invocationContext = new InvocationContext();  // Assume this is initialized\n\nMono&lt;List&lt;ChatMessageContent&lt;?&gt;&gt;&gt; chatContents = geminiChatCompletion.getChatMessageContentsAsync(chatHistory, kernel, invocationContext);\n Async Streaming Chat Message Retrieval: For streaming capabilities, use getStreamingChatMessageContentsAsync. Flux&lt;StreamingChatContent&lt;?&gt;&gt; streamingContents = geminiChatCompletion.getStreamingChatMessageContentsAsync(chatHistory, kernel, invocationContext);\n Function Calls: The class can perform function calls using performFunctionCall. GeminiFunctionCall geminiFunctionCall = // Initialize your Gemini function call\nMono&lt;GeminiFunctionCall&gt; functionResult = geminiChatCompletion.performFunctionCall(kernel, invocationContext, geminiFunctionCall);\n These methods leverage the reactive programming model in Java through Mono and Flux from Project Reactor, allowing developers to handle asynchronous data streams effectively. The GeminiChatCompletion class supports integration with Google&rsquo;s Vertex AI to provide dynamic chat completion services in your Semantic Kernel Java applications. Diagram ","timestamp":1763300447289},"references/eClassifiers/JsonSchemaResponseFormat/inheritance.html":{"path":"JsonSchemaResponseFormat/Inheritance","link-uuid":"d4682480-4e1e-4acf-8f1c-4cf7a87410e8","title":"Inheritance","content":"Supertypes ","timestamp":1763300447557},"references/eClassifiers/ChatCompletionService/inheritance.html":{"path":"ChatCompletionService/Inheritance","link-uuid":"1a6a8305-202b-4a16-bdb1-da616cf3e070","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447154},"references/eClassifiers/ScriptedFunction/references/eStructuralFeatures/script/index.html":{"path":"ScriptedFunction/Attributes/script","link-uuid":"1d3e65ce-6ed8-4054-80cc-6d84bdd78f9d","title":"script","content":"Type EString Multiplicity 0..1 ScriptedFunction Script Property The ScriptedFunction in Semantic Kernel is a mechanism to create functions that are based on scripting, allowing for more dynamic and flexible behavior within the AI framework. The script property of a ScriptedFunction holds the script content that defines the function&rsquo;s behavior. This allows developers to write scripts that can execute logic at runtime, integrating seamlessly with AI models provided by Semantic Kernel. Example of ScriptedFunction in Java Here&rsquo;s how a ScriptedFunction could be conceptually designed and employed in a Java context, using its script property to execute scripts: import java.util.Map;\n\n// Hypothetical ScriptedFunction class\npublic class ScriptedFunction {\n    private String script;\n\n    public ScriptedFunction(String script) {\n        this.script = script;\n    }\n\n    public Object execute(Map&lt;String, Object&gt; variables) {\n        // The script would be executed in a scripting engine; this is pseudocode\n        ScriptingEngine engine = getScriptingEngine();\n        engine.setVariables(variables);\n        return engine.executeScript(this.script);\n    }\n\n    private ScriptingEngine getScriptingEngine() {\n        // Initialize a scripting engine, e.g., Java's built-in JavaScript engine\n        return new ScriptingEngine(&quot;JavaScript&quot;);\n    }\n}\n\n// Usage\npublic class Example {\n    public static void main(String[] args) {\n        String scriptContent = &quot;var result = variable1 + variable2; result;&quot;;\n        ScriptedFunction function = new ScriptedFunction(scriptContent);\n\n        Map&lt;String, Object&gt; variables = Map.of(\n            &quot;variable1&quot;, 10,\n            &quot;variable2&quot;, 20\n        );\n        \n        Object result = function.execute(variables);\n        System.out.println(&quot;Result: &quot; + result); // Outputs: Result: 30\n    }\n}\n\nclass ScriptingEngine {\n    private String language;\n\n    public ScriptingEngine(String language) {\n        this.language = language;\n    }\n\n    public void setVariables(Map&lt;String, Object&gt; variables) {\n        // Method to set variables in the script's context\n    }\n\n    public Object executeScript(String script) {\n        // Method to execute the script and return result\n        return null; // This is placeholder pseudocode\n    }\n}\n Key Points Dynamic Execution: The function script dynamically executes logic at runtime, which is especially useful for AI-driven applications that require flexible responses. Integration: This allows for seamless integration with AI models, enabling them to call these functions as part of their workflow. Scripting Engine: The example uses a hypothetical ScriptingEngine, which might involve using Java&rsquo;s built-in scripting capabilities, such as the Nashorn JavaScript engine, or other scripting libraries. This example provides a conceptual framework for understanding how ScriptedFunction might be used within the Java ecosystem of Microsoft Semantic Kernel, with the script property being central to its functionality.","timestamp":1763300448090},"references/eClassifiers/FunctionInvokingHook/inheritance.html":{"path":"FunctionInvokingHook/Inheritance","link-uuid":"76103ddd-5836-463a-96ae-e87ae7fd12db","title":"Inheritance","content":"Supertypes ","timestamp":1763300447265},"references/eClassifiers/OpenAiAudioToTextService/inheritance.html":{"path":"OpenAiAudioToTextService/Inheritance","link-uuid":"fad178c7-1750-4ba9-966b-64561bfcc8cd","title":"Inheritance","content":"Supertypes ","timestamp":1763300447647},"references/eClassifiers/PreToolCallHook/inheritance.html":{"path":"PreToolCallHook/Inheritance","link-uuid":"30df0ef8-cfca-4c40-b99a-c621512a0362","title":"Inheritance","content":"Supertypes ","timestamp":1763300447853},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/maxTokens/index.html":{"path":"PromptExecutionSettings/Attributes/maxTokens","link-uuid":"ac325a0e-714c-438f-a809-49c58e671cb3","title":"maxTokens","content":"Type EIntegerObject Multiplicity 0..1 PromptExecutionSettings maxTokens Property in Java The maxTokens property in the PromptExecutionSettings class specifies the maximum number of tokens that can be generated in the output of a prompt execution. This setting is critical for controlling the length and potentially the cost associated with the generation of AI outputs in applications using Microsoft Semantic Kernel for Java. Default Value The default maxTokens value is 256 if it is not explicitly provided. Usage in Java The maxTokens property is accessed and modified using the PromptExecutionSettings.Builder class in Java, which facilitates building an instance of PromptExecutionSettings with customized properties. Below is an example of how to set the maxTokens property using the builder pattern: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\n// Create a new builder instance to configure PromptExecutionSettings\nPromptExecutionSettings.Builder builder = PromptExecutionSettings.builder();\n\n// Set the maxTokens to a specified value, say 512\nbuilder.withMaxTokens(512);\n\n// Build the PromptExecutionSettings with the configured maxTokens\nPromptExecutionSettings settings = builder.build();\n\n// Use the settings in your AI service\nSystem.out.println(&quot;Max Tokens: &quot; + settings.getMaxTokens());\n Considerations When setting the maxTokens value, it is important to ensure that the total token count (the sum of prompt tokens and maxTokens) does not exceed the context length of the model being used. Adjusting this setting can help manage the balance between the length of the AI output and the computational resources. This property is crucial for applications that need to fine-tune their resource usage and output size when interacting with AI models in the Semantic Kernel environment.","timestamp":1763300447890},"references/eClassifiers/ChatCompletionService/index.html":{"link-uuid":"4400c014-1b43-4d4c-8a2a-c28f0acdc72d","title":"ChatCompletionService","content":"ChatCompletionService (Java) &mdash; Summary and Usage Namespace: com.microsoft.semantickernel.services.chatcompletion Artifact: com.microsoft.semantic-kernel:semantickernel-api:1.4.0 Definition: ChatCompletionService is the Java interface for chat-based LLM interaction in Semantic Kernel. It extends TextAIService and provides async APIs (Project Reactor) to generate chat responses from either a ChatHistory or a raw prompt string. Key related types: - ChatHistory: maintains ordered messages across roles (user, assistant, system). - ChatMessageContent: represents a returned message. - AuthorRole: enum for message roles. - StreamingChatContent: streaming content type (see note on streaming below). Core methods Mono&lt;List&lt;ChatMessageContent&lt;?&gt;&gt;&gt; getChatMessageContentsAsync(ChatHistory chatHistory, Kernel kernel, InvocationContext invocationContext) Mono&lt;List&lt;ChatMessageContent&lt;?&gt;&gt;&gt; getChatMessageContentsAsync(String prompt, Kernel kernel, InvocationContext invocationContext) Flux&lt;StreamingChatContent&lt;?&gt;&gt; getStreamingChatMessageContentsAsync(ChatHistory chatHistory, Kernel kernel, InvocationContext invocationContext) Flux&lt;StreamingChatContent&lt;?&gt;&gt; getStreamingChatMessageContentsAsync(String prompt, Kernel kernel, InvocationContext invocationContext) Note: Documentation states streaming responses are currently unavailable in Semantic Kernel for Java. Add a provider implementation and register with the Kernel Typically you use a connector (e.g., OpenAI) that implements ChatCompletionService. import com.azure.ai.openai.OpenAIAsyncClient;\nimport com.azure.ai.openai.OpenAIClientBuilder;\nimport com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.aiservices.openai.chatcompletion.OpenAIChatCompletion;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;\n\n// Build provider client (Azure OpenAI or OpenAI)\n// Example: OpenAI (non-Azure)\nOpenAIAsyncClient client = new OpenAIClientBuilder()\n    .credential(openAIClientCredentials)\n    .buildAsyncClient();\n\n// Create the chat completion service\nChatCompletionService chat = OpenAIChatCompletion.builder()\n    .withOpenAIAsyncClient(client)\n    .withModelId(&quot;gpt-4o-mini&quot;) // your model id\n    .build();\n\n// Register service in the kernel\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chat)\n    .build();\n Retrieve the service later: ChatCompletionService chatCompletionService = kernel.getService(ChatCompletionService.class);\n Non\u2011streaming chat with ChatHistory import com.microsoft.semantickernel.services.chatcompletion.ChatHistory;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatMessageContent;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\n\nChatHistory history = new ChatHistory();\nhistory.addSystemMessage(&quot;You are a helpful assistant.&quot;);\nhistory.addUserMessage(&quot;Hello, how are you?&quot;);\n\n// Optional: configure invocation (see function calling below)\nInvocationContext invocationContext = null;\n\n// Invoke\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, invocationContext)\n    .block();\n\n// Print and append returned messages\nresults.forEach(r -&gt; System.out.println(r.getContent()));\n// By default, ChatCompletionService returns only the new messages &mdash; add them to continue the thread:\nhistory.addAll(results);\n Prompt-only (no prior ChatHistory) usage: List&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(&quot;Write a haiku about mountains&quot;, kernel, null)\n    .block();\n\nresults.forEach(r -&gt; System.out.println(r.getContent()));\n Function calling (tools) via InvocationContext To enable auto function calling (planning), you must: - Register plugins on the Kernel (so functions are discoverable). - Pass the Kernel and an InvocationContext that allows tool calls. import com.microsoft.semantickernel.orchestration.InvocationContext;\nimport com.microsoft.semantickernel.orchestration.InvocationReturnMode;\nimport com.microsoft.semantickernel.orchestration.ToolCallBehavior;\n\n// Example InvocationContext enabling tool calls to kernel functions\nInvocationContext ctx = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.LAST_MESSAGE_ONLY)\n    .withToolCallBehavior(ToolCallBehavior.allowAllKernelFunctions(true))\n    .build();\n\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, ctx)\n    .block();\n Important: - The Kernel must be supplied when invoking ChatCompletionService for function calling to work (plugins are registered on the Kernel). - If you disable auto-invoke, your application is responsible for invoking tool calls and then appending tool results to ChatHistory. Notes and limitations (Java) Streaming: Documentation notes streaming responses are not supported in Semantic Kernel for Java. Chat history reduction: Not available in Java. Simulated tool-call message injection APIs (as in .NET/Python) are not supported in Java; manual handling is required when auto-invoke is disabled. Package index (what&rsquo;s in the chatcompletion package) ChatHistory: build and manage conversation state. ChatMessageContent: message container returned by services. ChatCompletionService: the primary interface you call. StreamingChatContent: type for streaming chunks (API present; streaming not supported per docs). AuthorRole: identifies message authors (User, Assistant, System). Diagram ","timestamp":1763300447151},"references/eClassifiers/ScriptedFunction/inheritance.html":{"path":"ScriptedFunction/Inheritance","link-uuid":"750814bf-3af8-45aa-97a3-7d5aced0ae49","title":"Inheritance","content":"Supertypes ","timestamp":1763300448079},"references/eClassifiers/AIService/inheritance.html":{"path":"AIService/Inheritance","link-uuid":"cf7ed3f1-3a4f-4b56-aa00-2c90b0c50422","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447061},"references/eClassifiers/OpenAIChatCompletion/inheritance.html":{"path":"OpenAIChatCompletion/Inheritance","link-uuid":"55685277-3792-4eac-bae1-ca5d4245130a","title":"Inheritance","content":"Supertypes ","timestamp":1763300447669},"references/eClassifiers/PromptRenderedHook/index.html":{"link-uuid":"bee05b08-eee6-47d4-ba3d-2f19a5b39526","title":"PromptRenderedHook","content":"The PromptRenderedHook is a part of the Microsoft Semantic Kernel Java&rsquo;s hooks system, which allows you to intercept events when a prompt is rendered in the Semantic Kernel. Hooks provide a way to modify or take action at specific points during the execution process within the kernel&rsquo;s operation. PromptRenderedHook Purpose: Represents a hook that is executed after a prompt has been rendered. This can be useful for logging, auditing, or modifying the rendered output before it continues in the processing pipeline. Implementation: This hook is part of a broader system where you can add various hooks to interact with different stages of the kernel&rsquo;s processing. Here&rsquo;s a basic structure on how you might use PromptRenderedHook in a Java application using Semantic Kernel: import com.microsoft.semantickernel.hooks.KernelHooks;\nimport com.microsoft.semantickernel.hooks.PromptRenderedEvent;\nimport com.microsoft.semantickernel.hooks.KernelHook;\n\n// Create a hook function\nKernelHook.PromptRenderedHook&lt;PromptRenderedEvent&gt; promptRenderedHook = event -&gt; {\n    System.out.println(&quot;Prompt was rendered: &quot; + event.getRenderedPrompt());\n    return event;\n};\n\n// Create KernelHooks instance\nKernelHooks kernelHooks = new KernelHooks();\n\n// Add your PromptRenderedHook to KernelHooks\nkernelHooks.addPromptRenderedHook(promptRenderedHook);\n\n// Use this kernelHooks instance when initializing or configuring your kernel to have these hooks executed.\n In this example, the added hook will simply print the rendered prompt to the console, but you could expand this to include more complex logic as needed, such as modifying the prompt, saving it to a database, or interacting with other parts of your application. Adding Hooks to the Kernel When you set up your kernel, you would typically pass the KernelHooks instance into the kernel configuration so your hooks are executed at the appropriate times. // When building or configuring the kernel\nKernel kernel = Kernel.builder()\n    .withHooks(kernelHooks) // Add hooks to the kernel here\n    .build();\n By integrating hooks like PromptRenderedHook, developers can gain deeper insight and control over the behavior of Semantic Kernel, enabling more sophisticated and responsive AI solutions. Diagram ","timestamp":1763300447977},"references/eClassifiers/InputVariable/references/eStructuralFeatures/required/index.html":{"path":"InputVariable/Attributes/required","link-uuid":"05936dda-c626-4ebf-ba1b-b73eed64c204","title":"required","content":"Type EBoolean Multiplicity 0..1 In the context of Microsoft Semantic Kernel for Java, the InputVariable class is used to define variables that are associated with a kernel prompt template. Among other properties, InputVariable includes a JSON schema to describe the variable, which may include whether the variable is required. Key Points for the required Property in InputVariable: Purpose: The required attribute specifies whether the input variable must be provided when invoking the prompt. Type: This is a Boolean property. Example Java Code with the required Property: Here is an illustrative snippet showing how to define an InputVariable with the required property in Java: import io.github.semantickernel.prompt_template.InputVariable;\n\npublic class Example {\n    public static void main(String[] args) {\n        InputVariable messageVariable = new InputVariable(\n            &quot;message&quot;, // Variable name\n            &quot;This is the message.&quot;, // Description\n            true, // Required flag\n            &quot;default&quot; // Default value (optional, not needed if required is true)\n        );\n\n        // Example of description and default value definition\n        messageVariable.setDescription(&quot;A message to be echoed by the function&quot;);\n        // messageVariable.setDefault(&quot;default&quot;); // Optionally specify a default value\n    }\n}\n In this example, messageVariable is defined as an input variable that is required to be provided due to true being passed as the third argument indicating required. Note: The actual Java class for managing input variables might differ as this is a hypothetical representation created based on the Semantic Kernel concepts provided. Please ensure to conform to actual SDK documentation and APIs for precise implementation details. If the Java SDK does not support concatenating prompt templates the same way .NET or Python versions do, this concept serves as a general representation of how these properties might be structured. Always refer to the official documentation or SDK resources for specific implementations when available.","timestamp":1763300447434},"references/eClassifiers/Plugin/inheritance.html":{"path":"Plugin/Inheritance","link-uuid":"937e5271-9d62-4de9-9db6-d79d63cef2be","title":"Inheritance","content":"Supertypes ","timestamp":1763300447786},"references/eClassifiers/SpelFunction/inheritance.html":{"path":"SpelFunction/Inheritance","link-uuid":"433fe56b-4fe4-4e57-b386-2548948188d8","title":"Inheritance","content":"Supertypes ","timestamp":1763300448129},"references/eClassifiers/ScriptedFunction/references/eStructuralFeatures/engineMimeTypes/index.html":{"path":"ScriptedFunction/Attributes/engineMimeTypes","link-uuid":"96425311-8ac9-41ca-b9e1-d295e5458494","title":"engineMimeTypes","content":"Type EString Multiplicity 0..*","timestamp":1763300448085},"references/eClassifiers/Function/references/eStructuralFeatures/type/index.html":{"path":"Function/References/type","link-uuid":"5d8c7ee5-5372-473a-b50f-6b6307df16c7","title":"type","content":"Type OutputVariable Multiplicity 0..1 In Microsoft Semantic Kernel, when defining functions within plugins, a function is a key component and may possess a &ldquo;function type property.&rdquo; This property provides metadata about the function, such as its name and parameters, that can be used by AI models to understand and invoke it. Function Type Property in Java In Java, functions are typically annotated using @DefineKernelFunction, which includes metadata about the function. This metadata is essential for Semantic Kernel to serialize the function and its parameters, enabling it to communicate with AI models effectively. Here&rsquo;s a quick breakdown: Annotate Functions: Use the @DefineKernelFunction annotation to expose methods as kernel functions, providing a name and description. This makes the function discoverable by AI models. @DefineKernelFunction(\n    name = &quot;get_pizza_menu&quot;, \n    description = &quot;Get the pizza menu.&quot;\n)\npublic Mono&lt;Menu&gt; getPizzaMenuAsync() {\n    return pizzaService.getMenu();\n}\n Parameter Annotations: Each function parameter can be annotated using @KernelFunctionParameter, specifying its name, description, type, and whether it is required. This annotation helps the AI model understand the context and structure of the parameters it has to handle. public Mono&lt;CartDelta&gt; addPizzaToCart(\n    @KernelFunctionParameter(name = &quot;size&quot;, description = &quot;The size of the pizza&quot;, type = com.pizzashopo.PizzaSize.class, required = true)\n    PizzaSize size,\n    @KernelFunctionParameter(name = &quot;toppings&quot;, description = &quot;The toppings to add to the pizza&quot;, type = com.pizzashopo.PizzaToppings.class)\n    List&lt;PizzaToppings&gt; toppings\n) {\n    // Function logic here\n}\n Function Execution: Once functions are defined with annotations, they can be serialized into JSON schema. This schema is utilized for interactions between your Java code and AI models, allowing the models to make function calls with understanding of the expected inputs and outputs. Example Usage: In practice, implementing a function requires adding it to the Semantic Kernel, which then uses the metadata you&rsquo;ve defined to inform the AI model how to correctly invoke this function. Functions with the @DefineKernelFunction annotation will be auto-discovered and made available as callable entities by an AI agent. These annotations help keep the function signatures clear and descriptive, aiding the AI model in making correct function calls. By following this approach, developers ensure that their Java functions are properly understood and can interact effectively with AI models through Semantic Kernel.","timestamp":1763300447216},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/temperature/index.html":{"path":"PromptExecutionSettings/Attributes/temperature","link-uuid":"af66ae2f-2279-4963-9910-f864866ee84b","title":"temperature","content":"Type EDoubleObject Multiplicity 0..1 The PromptExecutionSettings class in Microsoft Semantic Kernel Java provides configuration settings for prompt execution, and one of its configurable parameters is the temperature setting. This parameter controls the randomness of the output generated by the AI model. Temperature Property Definition: The temperature setting adjusts the randomness in the AI model&rsquo;s output. A lower temperature results in more deterministic and consistent outputs, while a higher temperature generates more varied and random outputs. Default Value: The default value for temperature is 1.0. Range: The temperature setting can be clamped to the range [0.0, 2.0]. How to Use in Java To use the temperature setting in your prompt execution, you can utilize the PromptExecutionSettings.Builder class to configure this property as follows: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport java.util.*;\n\n// Create a builder instance\nPromptExecutionSettings.Builder settingsBuilder = new PromptExecutionSettings.Builder();\n\n// Configure the temperature setting\nsettingsBuilder.withTemperature(0.7); // Example setting\n\n// Build the PromptExecutionSettings\nPromptExecutionSettings settings = settingsBuilder.build();\n In this example, the temperature is set to 0.7, making the AI model&rsquo;s response slightly more random compared to the default setting. Adjusting the temperature can help in customizing the behavior of the AI model for different use cases.","timestamp":1763300447906},"references/eClassifiers/Function/inheritance.html":{"path":"Function/Inheritance","link-uuid":"ad4cad73-20d3-4204-8042-cb63a3d35e1d","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447210},"references/eClassifiers/Kernel/references/eStructuralFeatures/services/index.html":{"path":"Kernel/References/services","link-uuid":"ed969774-a469-4d59-b703-d3cebfb8b39b","title":"services","content":"Type AIService Multiplicity 0..* The Semantic Kernel in Java is a central component that functions as a Dependency Injection container, managing all the services and plugins required to run an AI application. This centrality allows efficient orchestration of various AI tasks by the kernel itself. Kernel Services in Semantic Kernel Java: Services: These include AI services (e.g., chat completion) as well as other necessary services like logging and HTTP clients. The design is similar to the Service Provider pattern in .NET, supporting dependency injection. Plugins: These are components used by AI services to perform actions like data retrieval or API calls. They encapsulate specific functionalities that can be invoked by AI model for various tasks. Kernel Initialization: Below is an example of how to create and configure a kernel in Java by adding an AI service and a plugin: import microsoft.semantic.kernel.*;\nimport microsoft.semantic.kernel.connectors.ai.open_ai.*;\nimport microsoft.semantic.kernel.plugins.*;\n\npublic class MyKernelSetup {\n    public static void main(String[] args) {\n        // Initialize an OpenAI chat completion service\n        OpenAIChatCompletion chatCompletionService = OpenAIChatCompletion.builder()\n                .withOpenAIAsyncClient(myOpenAIClient)\n                .withModelId(&quot;deployment-id&quot;)\n                .build();\n\n        // Import an existing plugin; for instance, a LightsPlugin\n        KernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\n        // Build the kernel, integrating services and plugins\n        Kernel kernel = Kernel.builder()\n                .withAIService(ChatCompletionService.class, chatCompletionService)\n                .withPlugin(lightPlugin)\n                .build();\n    }\n}\n In the example above, the kernel integrates an OpenAI chat completion service and a plugin called LightsPlugin. The kernel facilitates automatic orchestration and efficient management of these components, as any prompt or operation executed will rely on this central service container. Overall, the Semantic Kernel allows the seamless interaction of AI functionalities with external systems via well-defined services and plugins, managed centrally for efficiency and scalability.","timestamp":1763300447618},"references/eClassifiers/Hook/references/eStructuralFeatures/priority/index.html":{"path":"Hook/Attributes/priority","link-uuid":"5000e79e-7dfa-4be8-9359-05d0138b9e1b","title":"priority","content":"Type EInt Multiplicity 0..1 The KernelHooks class in Microsoft Semantic Kernel Java allows developers to manage and control the sequence and behavior of various events in the kernel by using hooks. Hooks enable interception and modification of events during kernel execution. However, built-in facilities for explicitly setting priorities for the execution order of these hooks are not directly provided in the Java SDK documentation. In the Java SDK, the order of hook execution typically depends on the sequence in which hooks are added to the collection. The KernelHooks class allows for the addition, removal, and execution of hooks through its methods, but explicit priority settings aren&rsquo;t discussed. Here is a potential approach to managing hook execution order manually using Java, by controlling the order in which hooks are added: import com.microsoft.semantickernel.hooks.KernelHooks;\nimport com.microsoft.semantickernel.hooks.KernelHook;\n\npublic class ExampleUsage {\n    public static void main(String[] args) {\n        // Create a KernelHooks instance\n        KernelHooks hooks = new KernelHooks();\n\n        // Adding hooks with assumed logical &quot;priority&quot; by the order\n        hooks.addHook(&quot;firstHook&quot;, (event) -&gt; {\n            // Hook logic for first priority\n            System.out.println(&quot;First hook executed.&quot;);\n            return event;\n        });\n\n        hooks.addHook(&quot;secondHook&quot;, (event) -&gt; {\n            // Hook logic for second priority\n            System.out.println(&quot;Second hook executed.&quot;);\n            return event;\n        });\n\n        // Add more hooks as needed\n\n        // An event needing hook processing\n        Object event = new Object();\n\n        // Execute hooks\n        hooks.executeHooks(event);\n    }\n}\n In the above example, hooks are added in a specific sequence, implying their execution priority. This manual approach can be adjusted according to specific needs until the SDK offers more advanced priority management features. The executeHooks() method processes hooks in the order they were added. For more complex scenarios where explicit priority handling is desired, custom logic can be implemented to sort or structure hooks based on a priority value before registering them to the KernelHooks instance. NO_INFORMATION is given about explicit priority properties within the current Java SDK of Microsoft Semantic Kernel.","timestamp":1763300447352},"references/eClassifiers/AIServiceSelector/index.html":{"link-uuid":"a13731f7-92e2-4418-a40a-6d66b554000f","title":"AIServiceSelector","content":"The AIServiceSelector in Microsoft Semantic Kernel Java is used to query and obtain AI services available through the kernel. Key methods and concepts from the AIServiceSelector framework enable fine-grained control and selection of AI services based on the needs of various applications built using the Semantic Kernel. Here is a summary of how you might interact with the AIServiceSelector in the context of the Semantic Kernel Java, along with relevant code snippets: Accessing the AIServiceSelector from Kernel: You can retrieve the AIServiceSelector used within a Kernel instance to manage AI services efficiently. // Assuming you have a Kernel instance\nAIServiceSelector serviceSelector = kernel.getServiceSelector();\n Using AIServiceSelector to Manage Services: The AIServiceSelector helps in determining which specific AI service to use within the kernel when multiple services are available. Fluent API for Building Kernels: When building a kernel, you might specify an AIServiceSelector to manage how AI services are selected or queried. Kernel kernel = Kernel.builder()\n    .withServiceSelector(myServiceSelector)\n    .build();\n This framework facilitates seamless integration of multiple AI services, ensuring that the most appropriate service is used for specific operations within the Semantic Kernel environment. Note: Actual implementation details of interface methods and the specific behaviors of service selection would depend on how AIServiceSelector is configured and used within your application context. If you are integrating or customizing services extensively, you may interact with components designed to extend service selection logic according to particular needs. Diagram ","timestamp":1763300447096},"references/eClassifiers/TextResponseFormat/inheritance.html":{"path":"TextResponseFormat/Inheritance","link-uuid":"e108763f-23c2-4842-ae94-bf78336d1af6","title":"Inheritance","content":"Supertypes ","timestamp":1763300448218},"references/eClassifiers/OpenAiTextToAudioService/index.html":{"link-uuid":"ee9f9498-e4ee-403b-a508-9a25fdfe42b3","title":"OpenAiTextToAudioService","content":"The OpenAiTextToAudioService class in the Microsoft Semantic Kernel Java package com.microsoft.semantickernel.aiservices.openai.audio provides an implementation for converting text into audio using OpenAI&rsquo;s services. This class extends OpenAiService and implements the TextToAudioService interface. Summary Package: com.microsoft.semantickernel.aiservices.openai.audio Maven Artifact: com.microsoft.semantic-kernel:semantickernel-aiservices-openai:1.4.0 Purpose: Provides an implementation for converting text to audio. Constructor The main constructor of OpenAiTextToAudioService is defined as follows: public OpenAiTextToAudioService(OpenAIAsyncClient client, String modelId, String deploymentName)\n Parameters: client: The OpenAI client to be used. modelId: The identifier of the model to use. deploymentName: The name of the deployment. Methods getAudioContentAsync: Converts input text into audio content asynchronously. public Mono&lt;AudioContent&gt; getAudioContentAsync(String text, TextToAudioExecutionSettings executionSettings)\n Builder The OpenAiTextToAudioService provides a builder pattern to facilitate the creation and configuration of a text to audio service instance. OpenAiTextToAudioService.Builder builder = OpenAiTextToAudioService.builder();\nTextToAudioService service = builder.withOpenAIAsyncClient(client)\n                                    .withModelId(modelId)\n                                    .withDeploymentName(deploymentName)\n                                    .build();\n Use the builder to configure the service with methods such as withOpenAIAsyncClient, withModelId, and withDeploymentName before calling build() to create the service instance. This setup allows for flexible integration and deployment within Java applications that require the text-to-audio conversion feature provided by OpenAI models. Diagram ","timestamp":1763300447733},"references/eClassifiers/Kernel/references/eStructuralFeatures/plugins/index.html":{"path":"Kernel/References/plugins","link-uuid":"bdefd5cf-3df2-4402-9084-4e4e279cb50a","title":"plugins","content":"Type Plugin Multiplicity 0..* The KernelPlugin class in the com.microsoft.semantickernel.plugin package is integral to the Java implementation of Microsoft Semantic Kernel. It encapsulates a collection of functions that can be invoked by the Semantic Kernel, enabling AI applications to leverage these functions. Key Components: Constructor: To create an instance of the KernelPlugin, you use its constructor, which requires the name and description of the plugin, along with a map of the functions it contains. Map&lt;String, KernelFunction&lt;?&gt;&gt; functions = new HashMap&lt;&gt;();\nKernelPlugin plugin = new KernelPlugin(&quot;MyPlugin&quot;, &quot;Description of my plugin&quot;, functions);\n Method: addFunction: Adds a function to the plugin. plugin.addFunction(new KernelFunction&lt;&gt;(&quot;functionName&quot;, functionImplementation));\n Method: get: Retrieves a function by its name. KernelFunction&lt;?&gt; function = plugin.get(&quot;functionName&quot;);\n Method: getName: Returns the name of the plugin. String name = plugin.getName();\n Method: getDescription: Provides the description of the plugin. String description = plugin.getDescription();\n Method: getFunctions: Retrieves all functions in the plugin as a map. Map&lt;String, KernelFunction&lt;?&gt;&gt; allFunctions = plugin.getFunctions();\n Method: iterator: Returns an iterator to iterate over the functions within the plugin. Iterator&lt;KernelFunction&lt;?&gt;&gt; iterator = plugin.iterator();\n This structure allows functions to be seamlessly integrated and managed, creating a modular and extensible framework that aids in broadening the capabilities of AI applications using the Semantic Kernel.","timestamp":1763300447613},"references/eClassifiers/PromptFunction/inheritance.html":{"path":"PromptFunction/Inheritance","link-uuid":"d5d3ec52-9862-4a7e-b041-16b3eb5011b1","title":"Inheritance","content":"Supertypes ","timestamp":1763300447957},"references/eClassifiers/Invocable/references/eStructuralFeatures/promptExecutionSettings/index.html":{"path":"Invocable/References/promptExecutionSettings","link-uuid":"8aef06c1-b1cb-46ab-81c0-0c51a74623d0","title":"promptExecutionSettings","content":"Type PromptExecutionSettingsEntry Multiplicity 0..* The PromptExecutionSettings class in Microsoft Semantic Kernel Java is designed to configure execution settings for AI requests. It is part of the com.microsoft.semantickernel.orchestration package and is utilized to define various parameters for prompt execution, such as model settings and function invocation behavior. The class provides a builder pattern, accessible via the PromptExecutionSettings.Builder class, which allows for the concise configuration of various settings. Some key methods of this builder include: withModelId(String modelId): Sets the model ID for prompt execution, such as &ldquo;gpt-4&rdquo;. withMaxTokens(int maxTokens): Specifies the maximum number of tokens to generate in the output. withTemperature(double temperature): Configures the temperature for controlling diversity in the generated output. withBestOf(int bestOf): Sets how many completions to generate server-side and return the &ldquo;best&rdquo; one. withStopSequences(List&lt;String&gt; stopSequences): Defines sequences where the generation should stop. withFunctionChoiceBehavior(FunctionChoiceBehavior behavior): Configures the behavior for choosing and invoking functions. Here&rsquo;s a sample Java code snippet using this builder to create a PromptExecutionSettings object: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\npublic class Example {\n    public static void main(String[] args) {\n        PromptExecutionSettings settings = PromptExecutionSettings.builder()\n            .withModelId(&quot;gpt-4&quot;)\n            .withMaxTokens(150)\n            .withTemperature(0.7)\n            .withFunctionChoiceBehavior(FunctionChoiceBehavior.auto(true))\n            .build();\n\n        // Use settings in your AI service invocation\n    }\n}\n This snippet shows how to configure the prompt execution to use the &ldquo;gpt-4&rdquo; model with a maximum token limit and specific temperature configuration. The FunctionChoiceBehavior is also set to invoke functions automatically, which is useful for function-calling scenarios within AI models.","timestamp":1763300447467},"references/eClassifiers/TextAIService/inheritance.html":{"path":"TextAIService/Inheritance","link-uuid":"20ffaa44-d31b-4034-95a9-69593a82aac9","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448154},"references/eClassifiers/PromptTemplateConfig/inheritance.html":{"path":"PromptTemplateConfig/Inheritance","link-uuid":"24b85e76-c1ed-4aaf-9820-1b7a469f5359","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448021},"references/eClassifiers/SpelFunction/index.html":{"link-uuid":"c3dc8aab-53ee-4bd4-973d-1c5a6392b17a","title":"SpelFunction","content":"The SpelFunction class in Microsoft Semantic Kernel Java pertains to Semantic Functions that can leverage SpEL (Spring Expression Language), though the specific documentation or class details for SpelFunction in the Semantic Kernel Java package are not available from the provided grounding information. If such a class exists in a similar context, it would typically involve creating a kernel function using SpEL for expression evaluation within a Semantic Kernel application. This would enable dynamic evaluation of expressions in your AI or plugin logic. As no direct information on SpelFunction from the Semantic Kernel Java SDK is available in the provided grounding material, here&rsquo;s a generic example that might represent how such a function might be utilized if it were part of the Semantic Kernel&rsquo;s Java-based capabilities, although note that this uses hypothetical SpEL and is not an actual Semantic Kernel Java example: import org.springframework.expression.ExpressionParser;\nimport org.springframework.expression.spel.standard.SpelExpressionParser;\n\npublic class ExampleSpelFunction {\n\n    private ExpressionParser parser = new SpelExpressionParser();\n\n    public Object evaluateExpression(String expression) {\n        return parser.parseExpression(expression).getValue();\n    }\n\n    public static void main(String[] args) {\n        ExampleSpelFunction spelFunction = new ExampleSpelFunction();\n        String expression = &quot;1 + 1&quot;;\n        Object result = spelFunction.evaluateExpression(expression);\n        System.out.println(&quot;Result of expression evaluation: &quot; + result);\n    }\n}\n However, this code snippet doesn&rsquo;t directly correlate with any specific SpelFunction in Semantic Kernel Java&rsquo;s documented packages. For accurate and precise information, checking the official Semantic Kernel Java API documentation or source code is recommended once available or contacting Microsoft Semantic Kernel support for clarification. For now, based on the boundary of given data regarding Semantic Kernel Java, no precise information or code snippet related to a SpelFunction in this context can be provided. NO_INFORMATION Diagram ","timestamp":1763300448127},"references/eClassifiers/JsonSchemaResponseFormat/references/eStructuralFeatures/jsonSchema/index.html":{"path":"JsonSchemaResponseFormat/Attributes/jsonSchema","link-uuid":"2b3d922e-d480-4537-bf3a-9a68db3d01fb","title":"jsonSchema","content":"Type EString Multiplicity 0..1 The JsonSchemaResponseFormat class in the Microsoft Semantic Kernel Java library represents a response format that follows a JSON schema. The jsonSchema property within this class is used to define the structure and rules of the expected JSON response. Usage To use this property, you typically work with the JsonSchemaResponseFormat.Builder class, which allows you to construct a JsonSchemaResponseFormat instance by setting various parameters, including the jsonSchema. Setting the JSON Schema Here&rsquo;s how you can set the jsonSchema using the builder pattern: import com.microsoft.semantickernel.orchestration.responseformat.JsonSchemaResponseFormat;\nimport com.microsoft.semantickernel.orchestration.responseformat.JsonSchemaResponseFormat.Builder;\n\npublic class Example {\n    public static void main(String[] args) {\n        JsonSchemaResponseFormat responseFormat = new Builder()\n            .setJsonSchema(&quot;{\\&quot;type\\&quot;: \\&quot;object\\&quot;, \\&quot;properties\\&quot;: {\\&quot;name\\&quot;: {\\&quot;type\\&quot;: \\&quot;string\\&quot;}}}&quot;)\n            .build();\n        \n        // Use the responseFormat object as needed\n    }\n}\n Explanation setJsonSchema(String jsonSchema): This method is used to define the JSON schema by providing a string representation of the schema. The schema describes the JSON object&rsquo;s structure, such as data types and required properties. build(): Once all desired properties are set, the build() method is called to create an instance of JsonSchemaResponseFormat. This approach ensures that the JSON responses conform to a predefined structure, which can be beneficial for validating data consistency and integrity in applications using the Semantic Kernel.","timestamp":1763300447562},"references/eClassifiers/ScriptedFunction/references/eStructuralFeatures/engineExtensions/index.html":{"path":"ScriptedFunction/Attributes/engineExtensions","link-uuid":"61629256-3d2c-4f83-9004-b2599db966d1","title":"engineExtensions","content":"Type EString Multiplicity 0..*","timestamp":1763300448083},"references/eClassifiers/Invocable/index.html":{"link-uuid":"4c7cea76-6cbe-4291-a000-a537d12ea9d9","title":"Invocable","content":"In Microsoft Semantic Kernel Java, the concept of invocation is central to interacting with AI models and invoking functions or plugins. Here&rsquo;s a summary of relevant components and features related to invocation in Semantic Kernel using Java: InvocationContext Class The InvocationContext class is used to supply a context for invoking a Kernel or KernelFunction. This class can be customized with various settings to control the invocation behavior. Usage: Builder Pattern: You can create an instance using the builder() method. Copy Existing Context: Use the copy() method to create a new instance by copying values from another InvocationContext. InvocationContext context = InvocationContext.builder().build();\n Function Invocation Modes There are two primary function invocation modes in Semantic Kernel: Auto Function Invocation: The default mode where Semantic Kernel automatically invokes functions selected by the AI model. It&rsquo;s a fully automated process where function results are managed seamlessly. InvocationContext invocationContext = new InvocationContext.Builder()\n    .withToolCallBehavior(ToolCallBehavior.allowAllKernelFunctions(true))\n    .build();\n Manual Function Invocation: This mode provides more control to the developer by allowing manual intervention in the function invocation process. It returns a list of functions chosen by the AI model, and the developer can decide which ones to invoke. Invoking Functions with Options AgentInvokeOptions: You may supply AgentInvokeOptions when invoking a function. This options class allows configuring additional settings such as kernels, instructions, and invocation context. // Example invocation with additional instructions\nagent.invokeAsync(&quot;What is the capital of France?&quot;,\n    null, // null AgentThread\n    AgentInvokeOptions.builder()\n        .withAdditionalInstructions(&quot;Refuse to answer any questions about capital cities.&quot;)\n        .build()\n);\n Managing InvocationContext You can manage the InvocationContext to handle different parameters and tailoring them to your needs, for example, by configuring tool call behaviors or prompt execution settings. Important Notes Streaming Function Invocation in Java is not supported yet; however, updates are anticipated. Observability in Semantic Kernel is currently not available for Java. FunctionCallContent and FunctionResultContent are classes used to represent AI model function calls and the resulting outcome. They are crucial when handling manual invocations. This summarizes the essential components and practices for invoking functions within Microsoft Semantic Kernel using Java. By using these functions, developers can effectively manage communication with AI models and plugins. Diagram ","timestamp":1763300447456},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/user/index.html":{"path":"PromptExecutionSettings/Attributes/user","link-uuid":"2cc0d893-b80f-49a5-8933-c8a811fd8beb","title":"user","content":"Type EString Multiplicity 0..1 In Microsoft Semantic Kernel Java, the PromptExecutionSettings class provides configuration settings for prompt execution. Among these settings is the user property, which allows you to associate a user with the prompt execution. This can be particularly useful for tracking or personalizing interactions based on the user context. PromptExecutionSettings - User Property The user property in PromptExecutionSettings is a String that specifies the user associated with the prompt execution. This property can be set using the builder pattern provided by the PromptExecutionSettings.Builder class. Here is a Java code snippet illustrating how to use the user property in PromptExecutionSettings: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\n// Building PromptExecutionSettings with a user\nPromptExecutionSettings promptExecutionSettings = PromptExecutionSettings.builder()\n    .withUser(&quot;exampleUser&quot;)\n    .build();\n\n// Retrieve the user associated with the prompt execution\nString user = promptExecutionSettings.getUser();\nSystem.out.println(&quot;User: &quot; + user);\n In this snippet: We create a PromptExecutionSettings object using the builder() method. The withUser(String user) method is used to set the user associated with the prompt execution. The getUser() method retrieves the user that has been set for the prompt execution, which can be output or used further as needed.","timestamp":1763300447913},"references/eClassifiers/TextToAudioService/inheritance.html":{"path":"TextToAudioService/Inheritance","link-uuid":"7b0c9cef-7d2c-470c-a11e-b41287bb4778","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448241},"references/eClassifiers/OpenAiAudioToTextService/index.html":{"link-uuid":"e125b39b-6d26-4292-9c54-628cf0e53ac1","title":"OpenAiAudioToTextService","content":"The OpenAiAudioToTextService in Microsoft Semantic Kernel Java is designed to facilitate the transformation of audio inputs into text outputs, leveraging OpenAI&rsquo;s auditory processing capabilities. This service implements the IAudioToTextService interface, enabling it to seamlessly integrate into the Semantic Kernel framework. Key Features Audio-to-Text Conversion: This service takes audio content as input and converts it into text, making it useful for applications such as transcription services. Integration with OpenAI: Utilizes OpenAI models to process audio and deliver textual results. Code Snippet Although the specific Java implementation details for OpenAiAudioToTextService are not explicitly provided here, the general process to set up and use the service can be illustrated with hypothetical Java-like pseudocode: import com.azure.ai.openai.OpenAIAsyncClient;\nimport com.azure.ai.openai.OpenAIClientBuilder;\nimport com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.services.audio.AudioToTextService;\n\n// Create a client to interact with OpenAI's audio services\nOpenAIAsyncClient client = new OpenAIClientBuilder()\n    .credential(azureOpenAIClientCredentials)\n    .endpoint(azureOpenAIClientEndpoint)\n    .buildAsyncClient();\n\n// Create an instance of OpenAiAudioToTextService\nAudioToTextService audioToTextService = new OpenAiAudioToTextService.Builder()\n    .withOpenAIAsyncClient(client)\n    .build();\n\n// Initialize the Semantic Kernel with the audio to text service\nKernel kernel = Kernel.builder()\n    .withAIService(AudioToTextService.class, audioToTextService)\n    .build();\n\n// Example usage: Convert audio content to text\nAudioContent audioContent = getAudioContent(); // Assume this method provides the audio content\nString transcribedText = audioToTextService.getTextContentsAsync(audioContent, kernel, null);\nSystem.out.println(&quot;Transcribed Text: &quot; + transcribedText);\n Considerations Integration: This service is part of a broader AI service package in Semantic Kernel Java and relies on OpenAI&rsquo;s infrastructure. Implementation: Follow the framework setup for Semantic Kernel in Java to ensure correct integration. Please note, the Java example is illustrative and assumes that corresponding Java classes and methods exist analogously to other languages in Microsoft Semantic Kernel, such as C#. If specific details about the service&rsquo;s existence in Java were available, it would be reflected in the code above. For accurate implementation, you would need to refer to the actual Java API documentation or libraries provided by Microsoft. Diagram ","timestamp":1763300447645},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/model/index.html":{"path":"PromptExecutionSettings/Attributes/model","link-uuid":"ba302a22-9f51-4f12-8128-3e883852f897","title":"model","content":"Type EString Multiplicity 0..1 ### PromptExecutionSettings Class in Microsoft Semantic Kernel Java\n\nThe `PromptExecutionSettings` class is a configuration model used for defining settings related to prompt execution in the Semantic Kernel Java SDK. It allows customization and fine-tuning of how AI prompts are executed. Here's a breakdown of its main properties and their purposes:\n\n---\n\n### Properties of PromptExecutionSettings\n\n- **ServiceId (`String`)**: Identifies the AI service to be used for prompt execution. It can be set using the `withServiceId(String serviceId)` method.\n\n- **ModelId (`String`)**: Identifies the AI model that will execute the prompt, which can be assigned using the `withModelId(String modelId)` method.\n\n- **Temperature (`double`)**: Controls the randomness of the output. Values close to `0.0` result in more deterministic outputs, while values closer to `2.0` yield more randomized responses. It can be set with `withTemperature(double temperature)`.\n\n- **TopP (`double`)**: A probability threshold that controls how many different tokens are considered for predicting the next token. You can set it using `withTopP(double topP)`.\n\n- **PresencePenalty (`double`)**: Encourages or discourages the inclusion of diverse tokens in the generated output with values ranging from `-2.0` to `2.0`. It's adjustable via `withPresencePenalty(double presencePenalty)`.\n\n- **FrequencyPenalty (`double`)**: Applies a penalty to token repetition in the output, set between `-2.0` and `2.0` through `withFrequencyPenalty(double frequencyPenalty)`.\n\n- **MaxTokens (`int`)**: Specifies the maximum number of tokens to generate in the completion, with values ranging from `1` to `Integer.MAX_VALUE`. It is defined using `withMaxTokens(int maxTokens)`.\n\n- **ResultsPerPrompt (`int`)**: The number of results to generate for each prompt, defaulting to `1`. It can be set with `withResultsPerPrompt(int resultsPerPrompt)`.\n\n- **BestOf (`int`)**: Specifies how many options to consider before presenting the best result, defaulting to `1`. Configured using `withBestOf(int bestOf)`.\n\n- **StopSequences (`List&lt;String&gt;`)**: A list of sequences to end the generation process if encountered. This can be set using `withStopSequences(List&lt;String&gt; stopSequences)`.\n\n- **TokenSelectionBiases (`Map&lt;Integer,Integer&gt;`)**: Defines biases for specific tokens, making them more or less likely to be selected. It can be configured with `withTokenSelectionBiases(Map&lt;Integer, Integer&gt; tokenSelectionBiases)`.\n\n- **ResponseFormat (`ResponseFormat`)**: Defines the format in which the response is expected, adjustable via `withResponseFormat(ResponseFormat responseFormat)`.\n\n- **User (`String`)**: Associates a user with the prompt execution, set using `withUser(String user)`.\n\n---\n\n### Example of Setting Prompt Execution Configurations\n\nHere's a Java snippet demonstrating how to configure `PromptExecutionSettings` using the builder pattern:\n\n```java\nimport com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\nPromptExecutionSettings settings = PromptExecutionSettings.builder()\n    .withServiceId(&quot;exampleServiceId&quot;)\n    .withModelId(&quot;gpt-3.5-turbo&quot;)\n    .withTemperature(0.7)\n    .withTopP(0.9)\n    .withPresencePenalty(0.5)\n    .withFrequencyPenalty(0.2)\n    .withMaxTokens(300)\n    .withResultsPerPrompt(1)\n    .withBestOf(2)\n    .withStopSequences(Arrays.asList(&quot;\\\\n&quot;, &quot;\\\\r&quot;))\n    .withTokenSelectionBiases(Map.of(123, 10))\n    .withResponseFormat(ResponseFormat.TEXT)\n    .withUser(&quot;testUser&quot;)\n    .build();\n The PromptExecutionSettings class provides a robust way to configure how AI models execute prompts, ensuring flexibility and precision in output generation.","timestamp":1763300447892},"references/eClassifiers/ScriptedFunction/references/eStructuralFeatures/engineNames/index.html":{"path":"ScriptedFunction/Attributes/engineNames","link-uuid":"f2dc0e8c-a062-47d9-8cd2-0c98cdbe1b2f","title":"engineNames","content":"Type EString Multiplicity 0..*","timestamp":1763300448088},"references/eClassifiers/AIService/index.html":{"link-uuid":"6ed2c66b-5795-4ed4-bc77-070eefe28768","title":"AIService","content":"The AIService interface in the Microsoft Semantic Kernel Java SDK serves as a marker interface for AI services. It is part of the package com.microsoft.semantickernel.services and is included in the semantickernel-api Maven artifact. The primary purpose of the AIService interface is to register AI services with the Kernel, providing access to various AI functionalities. Here are the key methods provided by the AIService interface: Methods getModelId(): This method is abstract and returns a String. It is used to retrieve the model identifier. If the model identifier was not specified in the service&rsquo;s attributes, it returns null. public abstract String getModelId();\n getServiceId(): This method is abstract and also returns a String. It provides the service identifier, which uniquely identifies the AI service. public abstract String getServiceId();\n The AIService interface forms the foundation for implementing various AI services that can be registered and managed within the Semantic Kernel environment. This allows the kernel to leverage different AI models and services dynamically. In practice, when you create an AI service, you would implement this interface and provide concrete methods for getModelId() and getServiceId() to ensure that your service can be uniquely identified and used by the kernel. Diagram ","timestamp":1763300447057},"references/eClassifiers/OpenAITextGenerationService/index.html":{"link-uuid":"aad12503-4d72-47cc-8228-4660b8980b78","title":"OpenAITextGenerationService","content":"OpenAITextGenerationService Class The OpenAITextGenerationService is part of the Semantic Kernel&rsquo;s Java SDK designed to integrate with OpenAI&rsquo;s text generation services. This class provides a Java-based implementation to facilitate text generation tasks using OpenAI models within the Semantic Kernel framework. It allows for operations like text completion and processing asynchronous text generation requests. Package com.microsoft.semantickernel.aiservices.openai.textcompletion Maven Artifact Group ID: com.microsoft.semantic-kernel Artifact ID: semantickernel-aiservices-openai Version: 1.4.0 Summary The OpenAITextGenerationService extends the OpenAiService&lt;OpenAIAsyncClient&gt; and implements TextGenerationService, providing an OpenAI-based implementation for text generation. Constructor protected OpenAITextGenerationService(OpenAIAsyncClient client, \n                                      String modelId, \n                                      String serviceId, \n                                      String deploymentName)\n Parameters: client: An instance of OpenAIAsyncClient. modelId: ID of the OpenAI model to use. serviceId: Service identifier. deploymentName: Deployment name for the service. Methods builder(): Creates and returns a builder for creating an instance of OpenAITextGenerationService. Usage: OpenAITextGenerationService.Builder builder = OpenAITextGenerationService.builder();\n getStreamingTextContentsAsync(String prompt, PromptExecutionSettings executionSettings, Kernel kernel): Returns a Flux of StreamingTextContent that allows for streaming text generation. Usage: Flux&lt;StreamingTextContent&gt; stream = textGenerationService.getStreamingTextContentsAsync(&quot;your prompt&quot;, settings, kernel);\n getTextContentsAsync(String prompt, PromptExecutionSettings executionSettings, Kernel kernel): Returns a Mono containing a list of TextContent. Usage: Mono&lt;List&lt;TextContent&gt;&gt; textContents = textGenerationService.getTextContentsAsync(&quot;your prompt&quot;, settings, kernel);\n internalCompleteTextAsync(String text, PromptExecutionSettings requestSettings): Protected method to internally complete text asynchronously. Usage: Mono&lt;List&lt;TextContent&gt;&gt; completedText = textGenerationService.internalCompleteTextAsync(&quot;your text&quot;, requestSettings);\n Usage Example Here&rsquo;s a basic example to demonstrate how you might instantiate and use the OpenAITextGenerationService: // Create OpenAI client\nOpenAIAsyncClient openAIClient = new OpenAIClientBuilder()\n    .credential(new DefaultAzureCredentialBuilder().build())\n    .buildAsyncClient();\n\n// Initialize the text generation service with necessary parameters\nOpenAITextGenerationService textGenerationService = new OpenAITextGenerationService(\n    openAIClient, \n    &quot;model-id&quot;, \n    &quot;service-id&quot;, \n    &quot;deployment-name&quot;\n);\n\n// Create prompt execution settings\nPromptExecutionSettings settings = new PromptExecutionSettings();\n\n// Generate text contents asynchronously using the model\nMono&lt;List&lt;TextContent&gt;&gt; result = textGenerationService.getTextContentsAsync(\n    &quot;Generate text based on this prompt.&quot;, \n    settings, \n    new Kernel()\n);\n\n// Subscribing to the result\nresult.subscribe(textContents -&gt; {\n    textContents.forEach(textContent -&gt; System.out.println(textContent.toString()));\n});\n This provides a high-level overview of the OpenAITextGenerationService class and its primary interface. Diagram ","timestamp":1763300447712},"references/eClassifiers/TokenSelectionBiasesEntry/index.html":{"link-uuid":"90fa444e-45ee-4d1c-a2cc-cb8e85c60bc4","title":"TokenSelectionBiasesEntry","content":"Diagram ","timestamp":1763300448260},"references/eClassifiers/InputVariable/references/eStructuralFeatures/defaultValue/index.html":{"path":"InputVariable/Attributes/defaultValue","link-uuid":"b2071967-9492-468a-85a5-57c903594921","title":"defaultValue","content":"Type EString Multiplicity 0..1 The InputVariable class in Microsoft Semantic Kernel for Java is used within a prompt template to define an input variable. This class facilitates parsing and validating input data. While the provided documentation doesn&rsquo;t specifically mention a defaultValue property for the Java implementation, the concept of a default value can be set through a similar mechanism relevant to other languages like Python. Here&rsquo;s a general description of the properties associated with input variables: Name - The name of the input variable. Description - A description of the input variable, providing context to the AI. Default - The default value of the input variable in scenarios where a value might not be explicitly provided. This helps in scenarios where optional input variables are used. In Java, similar to the Python documentation, you might define an InputVariable like this: public class InputVariable {\n    \n    private String name;\n    private String description;\n    private Object defaultValue;\n    private boolean isRequired;\n    private String jsonSchema;\n\n    public InputVariable(String name, String description, Object defaultValue, boolean isRequired, String jsonSchema) {\n        this.name = name;\n        this.description = description;\n        this.defaultValue = defaultValue;\n        this.isRequired = isRequired;\n        this.jsonSchema = jsonSchema;\n    }\n\n    // Getters and Setters for properties\n}\n In this outline, defaultValue is proposed to represent the default value property for an input variable in a Semantic Kernel plugin context in Java. This mirrors usage patterns demonstrated in other languages like Python for handling input variables in semantic templates. However, it&rsquo;s essential to check the latest SDK or official documentation for any changes or detailed implementations specific to Java.","timestamp":1763300447429},"references/eClassifiers/FunctionInvokingHook/index.html":{"link-uuid":"513a865b-192f-4f35-9da3-268d2d5f4c53","title":"FunctionInvokingHook","content":"FunctionInvokingHook&lt;T&gt; In Microsoft Semantic Kernel Java, the FunctionInvokingHook&lt;T&gt; interface represents a hook that is executed before a function is invoked. This provides an opportunity to intercept and potentially modify the behavior or input of a function call right before it actually occurs. Key Characteristics: Interception Before Execution: FunctionInvokingHook&lt;T&gt; is specifically designed to trigger before a function is executed, allowing any pre-processing or checks to be applied. Generic Type Parameter: The use of a generic &lt;T&gt; allows flexibility in terms of the type of event data or context that the hook can work with. Example Usage: Here&rsquo;s a simple conceptual snippet that demonstrates how you might set up and use a FunctionInvokingHook in your Semantic Kernel Java application: import com.microsoft.semantickernel.hooks.FunctionInvokingEvent;\nimport com.microsoft.semantickernel.hooks.KernelHook;\n\n// Define a class that implements the FunctionInvokingHook interface\npublic class MyFunctionInvokingHook implements KernelHook.FunctionInvokingHook&lt;MyEvent&gt; {\n\n    @Override\n    public void invoke(FunctionInvokingEvent&lt;MyEvent&gt; event) {\n        // Add functionality to manipulate or log the event before function execution\n        System.out.println(&quot;Function &quot; + event.getFunctionName() + &quot; is about to be invoked.&quot;);\n        // Add custom logic here, e.g., validation, logging, etc.\n    }\n}\n\n// Somewhere in your kernel setup code        \nKernelHooks hooks = new KernelHooks();\nhooks.addHook(new MyFunctionInvokingHook());\n// The above hook will now intercept all function calls before they are made\n In this example, the MyFunctionInvokingHook class implements the FunctionInvokingHook interface, allowing you to perform actions or checks just before the specified function is invoked. This can be useful for logging, modifying input parameters, enforcing pre-conditions, or similar tasks. Diagram ","timestamp":1763300447262},"references/eClassifiers/Hook/index.html":{"link-uuid":"b96f08c1-f709-4e9e-9b8f-7aa0448452a1","title":"Hook","content":"The Microsoft Semantic Kernel Java offers a mechanism to intercept and handle events through what is known as hooks. The main class used for this purpose is the KernelHooks class. Here&rsquo;s an overview with relevant Java code snippets: KernelHooks Class The KernelHooks class maintains a collection of hooks that can be used to intercept and modify events occurring within the kernel. These hooks are useful for auditing, applying transformations, or handling events in a custom way before or after they occur. Key Methods Adding Hooks: Hooks can be added to the collection using methods like addHook, addFunctionInvokedHook, addFunctionInvokingHook, and others. Each of these methods returns a key for the hook. // Adding a generic kernel hook\nKernelHooks hooks = new KernelHooks();\nString hookKey = hooks.addHook(new KernelHook&lt;&gt;() {\n    @Override\n    public void apply(KernelHookEvent event) {\n        // Custom logic on event\n    }\n});\n Executing Hooks: Hooks can be executed using the executeHooks method, which processes events through the defined hooks. // Execute hooks on an event\nMyEvent event = new MyEvent();\nhooks.executeHooks(event);\n Managing Hooks: The KernelHooks class also provides methods to merge hooks, check if the collection is empty, and remove hooks. // Check if the collection is empty\nboolean isEmpty = hooks.isEmpty();\n\n// Remove a hook\nhooks.removeHook(hookKey);\n KernelHook Interface The KernelHook&lt;T&gt; interface allows for defining the specific actions that should be taken when events occur. You create a hook by implementing this interface. public class MyHook implements KernelHook&lt;MyEvent&gt; {\n    @Override\n    public void apply(MyEvent event) {\n        // Processing logic for MyEvent\n    }\n}\n Predefined Hook Events Semantic Kernel provides several predefined events that you can hook into: FunctionInvokingEvent: Before a function is invoked. FunctionInvokedEvent: After a function has been invoked. PreChatCompletionEvent: Before a chat completion. PostChatCompletionEvent: After a chat completion. PromptRenderingEvent: Before a prompt is rendered. PromptRenderedEvent: After a prompt is rendered. PreToolCallEvent: Before a tool call is invoked. Each of these events allows you to add custom handling logic specific to the lifecycle stage indicated by the event name. By using the Microsoft Semantic Kernel Java library hooks, developers can effectively manage and respond to various events, ensuring that their AI-integrated applications handle events in a way that aligns with their specific needs and business logic. Diagram ","timestamp":1763300447343},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/topP/index.html":{"path":"PromptExecutionSettings/Attributes/topP","link-uuid":"eb207335-ee98-4834-9d24-17856ea62455","title":"topP","content":"Type EDoubleObject Multiplicity 0..1 The topP property in the PromptExecutionSettings class within the Microsoft Semantic Kernel Java framework controls the diversity of token selection during prompt execution. It is a probability threshold that determines how many different words or phrases are considered to predict the next token. The model considers the most likely tokens whose cumulative probability mass is greater than the specified topP value. A higher topP value leads to more diverse outputs. Code Snippet Below is a Java code snippet demonstrating how to configure the topP setting using the PromptExecutionSettings.Builder class. import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\npublic class Example {\n\n    public static void main(String[] args) {\n        \n        // Create a builder for PromptExecutionSettings\n        PromptExecutionSettings.Builder builder = PromptExecutionSettings.builder();\n        \n        // Set the topP value\n        builder.withTopP(0.9); // Example value, adjust as needed\n        \n        // Build the PromptExecutionSettings object\n        PromptExecutionSettings settings = builder.build();\n    }\n}\n In this example, 0.9 is set for topP, indicating that the model will consider tokens whose cumulative probability mass is within the top 90% for selecting the next word in the sequence. Adjust this value based on the desired diversity of your outputs.","timestamp":1763300447911},"references/eClassifiers/ResponseFormat/inheritance.html":{"path":"ResponseFormat/Inheritance","link-uuid":"49fe55a7-77ef-41fd-9b79-2a43c884f469","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448056},"references/eClassifiers/GeminiTextGenerationService/inheritance.html":{"path":"GeminiTextGenerationService/Inheritance","link-uuid":"8cae8d1d-60e0-421b-8bec-410b1b7651dc","title":"Inheritance","content":"Supertypes ","timestamp":1763300447317},"references/eClassifiers/PromptExecutionSettings/index.html":{"link-uuid":"dac6cbfb-bff6-4550-8537-e23439c5fd77","title":"PromptExecutionSettings","content":"PromptExecutionSettings Class The PromptExecutionSettings class in the Microsoft Semantic Kernel Java SDK provides configuration settings for executing AI prompts. This class resides in the com.microsoft.semantickernel.orchestration package and is a part of the semantickernel-api Maven artifact. Key Features Default Values: Provides default settings for various execution parameters such as max tokens, temperature, and presence penalty. Field Summary: DEFAULT_BEST_OF: Default value is 1. DEFAULT_FREQUENCY_PENALTY: Default value is 0.0. DEFAULT_MAX_TOKENS: Default value is 256. DEFAULT_PRESENCE_PENALTY: Default value is 0.0. DEFAULT_RESULTS_PER_PROMPT: Default value is 1. DEFAULT_SERVICE_ID: Default value is &quot;default&quot;. DEFAULT_TEMPERATURE: Default value is 1.0. DEFAULT_TOP_P: Default value is 1.0. Constructor and Method Summary Constructor: public PromptExecutionSettings(String serviceId, String modelId,\n                               Double temperature, Double topP,\n                               Double presencePenalty, Double frequencyPenalty,\n                               Integer maxTokens, Integer resultsPerPrompt,\n                               Integer bestOf, String user,\n                               List&lt;String&gt; stopSequences,\n                               Map&lt;Integer, Integer&gt; tokenSelectionBiases,\n                               ResponseFormat responseFormat)\n Builder Method: builder(): Creates a new builder for PromptExecutionSettings. Example: PromptExecutionSettings.Builder builder = PromptExecutionSettings.builder();\n Common Methods: getBestOf(): Returns threshold for considering a result. getFrequencyPenalty(): Returns the penalty applied to frequency. getMaxTokens(): Determines the max number of tokens for output. Example Usage: PromptExecutionSettings executionSettings = PromptExecutionSettings.builder()\n    .withModelId(&quot;gpt-3.5-turbo&quot;)\n    .withMaxTokens(500)\n    .withTemperature(0.7)\n    .build();\n This class is fundamental in defining how AI prompts are executed within the Semantic Kernel framework. By utilizing the PromptExecutionSettings.Builder, developers can easily configure their AI interaction settings to suit their application&rsquo;s requirements. Diagram ","timestamp":1763300447877},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/bestOf/index.html":{"path":"PromptExecutionSettings/Attributes/bestOf","link-uuid":"46bf32f2-41d6-4859-85d4-8724503c84bb","title":"bestOf","content":"Type EIntegerObject Multiplicity 0..1 PromptExecutionSettings in Microsoft Semantic Kernel PromptExecutionSettings is a class in the Microsoft Semantic Kernel library that provides execution settings for AI requests. It is part of the Microsoft.SemanticKernel namespace and is available in the Microsoft.SemanticKernel.Abstractions package. bestOf Property The bestOf property in PromptExecutionSettings determines how many completions (results) the model will internally generate before selecting the best one to return. This property can be useful for improving the response quality by analyzing multiple generated completions and choosing the optimal result. However, it might also increase the computational cost since more results are generated internally. Note: Details specific to handling or utilizing a bestOf property for AI requests might not be directly available in the documentation extracts provided. Typically, such functionality could be part of the settings in prompting AI models depending on the context. Java Example Here&rsquo;s a simplified Java example to illustrate the setup using an AI service in the Semantic Kernel Java SDK, and it assumes adjusting execution settings like bestOf would be similar if such functionality were explicitly supported (not specified in the extracts): import com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;\nimport com.azure.ai.openai.OpenAIAsyncClient;\nimport com.azure.ai.openai.OpenAIClientBuilder;\n\npublic class Example {\n    public static void main(String[] args) {\n        // Hypothetical: Create an OpenAI client\n        OpenAIAsyncClient client = new OpenAIClientBuilder()\n            .credential(/* API credentials */)\n            .buildAsyncClient();\n\n        // Hypothetical: Setup AI Service - e.g., OpenAI Chat Completion\n        ChatCompletionService chatCompletion = OpenAIChatCompletion.builder()\n            .withOpenAIAsyncClient(client)\n            .withModelId(&quot;gpt-4&quot;)\n            .build();\n\n        // Initialize the Kernel\n        Kernel kernel = Kernel.builder()\n            .withAIService(ChatCompletionService.class, chatCompletion)\n            .build();\n\n        // Hypothetical: Assuming you could set something akin to `bestOf` in execution settings\n        // This is generally model specific and would depend on the model's interfaces and capabilities.\n\n        // InvocationContext could theoretically include settings related to prompt executions\n        // InvocationContext invocationContext = InvocationContext.builder()\n        //     .bestOf(3) // Hypothetical usage\n        //     .build();\n\n        // Example usage scenario for invocation - specific implementation details based on actual API capabilities not explicitly covered here\n        // ...\n\n    }\n}\n Note: This example uses a hypothetical bestOf setup due to the lack of direct property documentation indicating bestOf in Java, which would logically follow similar patterns if the SDK provides such a feature. Remarks If bestOf or equivalent functionality is provided by specific AI service SDKs such as those offered by OpenAI, they might be explicitly mentioned in the SDK&rsquo;s API references beyond the Semantic Kernel itself. The Java SDK for Semantic Kernel is likely to undergo updates, and features available in other SDKs (like .NET or Python) may not yet be fully reflected in Java. Always consult the latest Microsoft Semantic Kernel Java API documentation or the source repository for specific updates about properties like bestOf.","timestamp":1763300447884},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/presensePenalty/index.html":{"path":"PromptExecutionSettings/Attributes/presensePenalty","link-uuid":"208bf4c2-c6d8-4638-82fc-aad367c40889","title":"presensePenalty","content":"Type EDoubleObject Multiplicity 0..1 The presencePenalty property in the PromptExecutionSettings class is used to influence the diversity of the model&rsquo;s output by encouraging or discouraging the usage of a diverse range of tokens. A higher presence penalty value encourages the model to use a more diverse range of tokens in the generated text. In Java, this is part of the com.microsoft.semantickernel.orchestration package. Definition public double getPresencePenalty()\n Returns: The presence penalty setting, which is a measure to encourage the model to vary its output by using a diverse range of tokens. Usage Example in Code You can set the presencePenalty using the Builder class for PromptExecutionSettings. Here is how you can do it: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\npublic class Example {\n    public static void main(String[] args) {\n        PromptExecutionSettings settings = PromptExecutionSettings.builder()\n            .withPresencePenalty(0.8) // Sets the presence penalty to 0.8\n            .build();\n\n        System.out.println(&quot;Presence Penalty: &quot; + settings.getPresencePenalty());\n    }\n}\n Explanation Builder Pattern: You can use the PromptExecutionSettings.Builder to configure a new instance of PromptExecutionSettings. withPresencePenalty method allows specifying the presence penalty. Value Range: Typically, the presence penalty is clamped within a valid range such as [-2.0, 2.0]. The default is usually 0.0, which means no penalty. Effect: A higher presence penalty causes the model to explore more varied outputs rather than sticking to familiar or frequent patterns, enhancing the creativity or diversity of its responses.","timestamp":1763300447894},"references/eClassifiers/OpenAITextEmbeddingGenerationService/inheritance.html":{"path":"OpenAITextEmbeddingGenerationService/Inheritance","link-uuid":"21822d1b-4980-4350-9f45-d312bf1b3eb8","title":"Inheritance","content":"Supertypes ","timestamp":1763300447693},"references/eClassifiers/OpenAiTextToAudioService/inheritance.html":{"path":"OpenAiTextToAudioService/Inheritance","link-uuid":"946598b2-2aed-4e70-8414-f445d5fe1bc5","title":"Inheritance","content":"Supertypes ","timestamp":1763300447736},"references/eClassifiers/InvocationContext/references/eStructuralFeatures/promptExecutionSettings/index.html":{"path":"InvocationContext/References/promptExecutionSettings","link-uuid":"81ade4bb-151a-4908-9dcc-b261c6f7946c","title":"promptExecutionSettings","content":"Type PromptExecutionSettings Multiplicity 0..1 The InvocationContext class in Microsoft Semantic Kernel Java allows customization of prompt execution parameters. One key aspect you can configure through the InvocationContext is PromptExecutionSettings, which dictate how a prompt is processed by the AI model. Here&rsquo;s a summary of the PromptExecutionSettings features and property settings you can manipulate: PromptExecutionSettings Configuration Summary Service ID: Specifies the ID of the AI service to use for prompt execution. Model ID: Defines the ID of the model for executing prompts. Temperature: Controls the randomness of the model output; lower values produce more deterministic results. Top P: Determines the diversity of tokens considered for the next word prediction based on cumulative probability. Presence Penalty: Encourages or discourages diversity of token usage in the output. Frequency Penalty: Affects the model&rsquo;s likelihood of repeating tokens in the output. Max Tokens: The limit for the number of tokens generated in the output. Results Per Prompt: Number of potential responses generated for each prompt. Stop Sequences: Specify when the model should stop generating further tokens. Token Selection Biases: Bias which tokens are more or less likely to appear in the output. Java Code Snippets To use PromptExecutionSettings with an InvocationContext, you typically create and build PromptExecutionSettings and set it in the InvocationContext. Here&rsquo;s an example: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\nimport java.util.List;\nimport java.util.Map;\n\npublic class InvocationExample {\n    public static void main(String[] args) {\n        // Create a PromptExecutionSettings object\n        PromptExecutionSettings settings = new PromptExecutionSettings(\n            &quot;service-id&quot;,\n            &quot;model-id&quot;,\n            1.0, // temperature\n            1.0, // topP\n            0.0, // presencePenalty\n            0.0, // frequencyPenalty\n            256, // maxTokens\n            1,   // resultsPerPrompt\n            1,   // bestOf\n            &quot;userId&quot;,\n            List.of(&quot;stopSequence&quot;),\n            Map.of(123, 1) // tokenSelectionBiases\n        );\n\n        // Adding PromptExecutionSettings to InvocationContext\n        InvocationContext context = InvocationContext.builder()\n            .withPromptExecutionSettings(settings)\n            .build();\n\n        // ... Use the context for executing prompts\n    }\n}\n This code demonstrates how to configure and set prompt execution settings within an invocation context. This configuration is critical for tailoring AI prompts to specific needs, such as invoking a desired model with particular behavioral settings.","timestamp":1763300447501},"references/eClassifiers/PromptFunction/index.html":{"link-uuid":"589894fb-df4c-48d1-a249-f739165d7459","title":"PromptFunction","content":"The KernelFunctionFromPrompt&lt;T&gt; class in the Microsoft Semantic Kernel Java package is an implementation of a kernel function that is created from a prompt template. This type of function is geared towards executing tasks based on the specifications provided in a prompt template, with support for various configurations and settings. Key Features: Type Parameter (T): This represents the return type of the function. Creation from Prompt Template: The function is instantiated using a PromptTemplate and relevant configurations. Invocation: Functions are invoked asynchronously using the invokeAsync method. Constructor: The class provides a protected constructor: protected KernelFunctionFromPrompt(PromptTemplate template, \n                                   PromptTemplateConfig promptConfig, \n                                   Map&lt;String, PromptExecutionSettings&gt; executionSettings)\n template: Defines the prompt template for the function. promptConfig: Configuration details for the prompt. executionSettings: Settings for executing the function. Method: invokeAsync Method: This method is used to invoke the function asynchronously: Mono&lt;FunctionResult&lt;T&gt;&gt; invokeAsync(Kernel kernel, \n                                    KernelFunctionArguments arguments, \n                                    ContextVariableType&lt;T&gt; variableType, \n                                    InvocationContext invocationContext)\n kernel: The kernel instance that manages service invocations. arguments: Input parameters for the function. variableType: Specifies how the result should be converted. invocationContext: Allows customization of execution, such as adding kernel hooks. Usage Example: Here&rsquo;s a basic example showcasing how to set up and invoke a KernelFunctionFromPrompt: // Define the prompt template and configuration\nPromptTemplate template = new PromptTemplate( /* template details */ );\nPromptTemplateConfig config = new PromptTemplateConfig( /* configuration details */ );\n\n// Create execution settings map if needed\nMap&lt;String, PromptExecutionSettings&gt; execSettings = new HashMap&lt;&gt;();\nexecSettings.put(&quot;default&quot;, new PromptExecutionSettings( /* settings details */ ));\n\n// Create the KernelFunctionFromPrompt instance\nKernelFunctionFromPrompt&lt;String&gt; function = new KernelFunctionFromPrompt&lt;&gt;(template, config, execSettings);\n\n// Creating a kernel instance (example)\nKernel kernel = Kernel.builder().build();\n\n// Define the function arguments and invocation context\nKernelFunctionArguments arguments = new KernelFunctionArguments( /* argument details */ );\nInvocationContext context = new InvocationContext( /* context details */ );\n\n// Invoke the function asynchronously\nMono&lt;FunctionResult&lt;String&gt;&gt; resultMono = function.invokeAsync(kernel, arguments, null, context);\n\n// To handle the result\nresultMono.subscribe(result -&gt; {\n    // Process the function result\n    System.out.println(&quot;Function Output: &quot; + result);\n});\n In this example, a KernelFunctionFromPrompt instance is created with a specified prompt template, configuration, and execution settings. The function is then invoked asynchronously using the invokeAsync method, allowing results to be processed upon completion. This setup allows developers to define and execute complex AI-driven prompts seamlessly within their Java applications. Diagram ","timestamp":1763300447955},"references/eClassifiers/InputVariable/index.html":{"link-uuid":"ec1f4fec-8fa7-4cb4-b344-96e72ea5c213","title":"InputVariable","content":"The InputVariable class in the com.microsoft.semantickernel.semanticfunctions package in Microsoft Semantic Kernel Java API is designed to hold metadata for an input variable of a KernelFunction. This allows the Semantic Kernel to understand and operate with the input parameters required by semantic functions effectively. Key Features of InputVariable Purpose: Represents metadata for input parameters used by a kernel function. Typical Use: Helps in defining the types of inputs a function will accept which can then be leveraged when configuring functions within the Kernel. Example Usage Although the precise method signatures for InputVariable aren&rsquo;t provided in the context, typical usage of such a class would involve creating instances representing individual input parameters that can be fed into a function. These variables can be described with name, type, descriptions, or other custom-defined metadata. Java Code Snippet for Creating an InputVariable Here is a conceptual code snippet that showcases how an input variable could be defined and used with the builder pattern for the PromptTemplateConfig. import com.microsoft.semantickernel.semanticfunctions.InputVariable;\nimport com.microsoft.semantickernel.semanticfunctions.PromptTemplateConfig;\n\n// Create an InputVariable instance\nInputVariable inputVar = new InputVariable(&quot;variableName&quot;, &quot;This is a description of the input variable.&quot;);\n\n// Use the InputVariable with PromptTemplateConfig.Builder\nPromptTemplateConfig.Builder configBuilder = new PromptTemplateConfig.Builder()\n    .withName(&quot;exampleConfig&quot;)\n    .withDescription(&quot;This is an example configuration&quot;)\n    .addInputVariable(inputVar)\n    .build();\n In this example: - InputVariable is created with a name and description. - The PromptTemplateConfig.Builder is used to create a prompt template configuration, integrating the InputVariable into the configuration. The InputVariable serves to make it explicit what inputs a kernel function expects and provides a well-defined way to manage these inputs within the Semantic Kernel&rsquo;s structures. Diagram ","timestamp":1763300447421},"references/eClassifiers/Kernel/index.html":{"link-uuid":"bbbad225-28ca-413d-8630-ee83e2c41582","title":"Kernel","content":"The Kernel class in Microsoft Semantic Kernel Java is designed to manage and provide access to AI services and plugins throughout an application&rsquo;s lifecycle. It leverages Dependency Injection to manage these components efficiently. Below is a summary of the key features of the Kernel class, along with some code snippets: Kernel Class Overview The Kernel class acts as the central component in the Semantic Kernel Java SDK. It provides state and services to functions and AI service calls within the system. This allows developers to easily integrate AI capabilities into their Java applications. Key Features: Service Management: The kernel manages a collection of services that can include both AI and other backend services necessary for operation. Plugin Support: It allows the integration of various plugins to extend its capabilities. Function Invocation: The kernel supports synchronous and asynchronous invocation of functions. Dependency Injection: Designed to support dependency injection, enhancing modularity and testability of the application. Kernel Construction To create a Kernel, you use a Kernel.Builder. You can add AI services and plugins to the builder before creating the kernel. Here&rsquo;s a basic example: import com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.aiservices.openai.chatcompletion.OpenAIChatCompletion;\nimport com.microsoft.semantickernel.plugin.KernelPlugin;\n\npublic class SemanticKernelExample {\n    public static void main(String[] args) {\n        // Create a new AI service client\n        ChatCompletionService chatCompletionService = OpenAIChatCompletion.builder()\n            .withModelId(&quot;your-model-id&quot;)\n            .withOpenAIAsyncClient(client)\n            .build();\n\n        // Create a plugin\n        KernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\n        // Build the kernel\n        Kernel kernel = Kernel.builder()\n            .withAIService(ChatCompletionService.class, chatCompletionService)\n            .withPlugin(lightPlugin)\n            .build();\n    }\n}\n Function Invocation The Kernel supports function and prompt invocations, both synchronously and asynchronously. For function invocation: // Synchronous invocation\nFunctionResult&lt;String&gt; result = kernel.invoke(&quot;LightsPlugin&quot;, &quot;getLights&quot;);\n\n// Asynchronous invocation\nFunctionInvocation&lt;String&gt; asyncResult = kernel.invokeAsync(&quot;LightsPlugin&quot;, &quot;changeState&quot;);\n Plugins and Services Plugins can be added to the kernel to enable specific functionalities, while services provide backend functionalities required by the kernel. // Adding a plugin to the kernel\nKernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\n// Building the kernel with the AI service and plugin\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chatCompletionService)\n    .withPlugin(lightPlugin)\n    .build();\n Summary The Kernel class in the Microsoft Semantic Kernel Java SDK is designed to manage the lifecycle and invocation of AI services and plugins, making it a powerful tool for developing AI-enhanced Java applications. It supports the flexible integration of services and plugins, enabling developers to quickly and efficiently build applications that leverage the latest advances in AI technology. Diagram ","timestamp":1763300447587},"references/eClassifiers/Hook/inheritance.html":{"path":"Hook/Inheritance","link-uuid":"0f19c17c-452f-41be-bbe9-a66587e71691","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447346},"references/eClassifiers/PromptTemplateConfig/references/eStructuralFeatures/schema/index.html":{"path":"PromptTemplateConfig/Attributes/schema","link-uuid":"2c04b6a6-9118-46db-bb29-c1af293c6c2a","title":"schema","content":"Type EInt Multiplicity 0..1 PromptTemplateConfig Class in Microsoft Semantic Kernel Java The PromptTemplateConfig class in Microsoft Semantic Kernel is used to configure prompt templates that can be utilized to generate prompts submitted to AI services. This class provides a structured way to define the necessary settings for creating and executing a prompt template. The schema property in this context typically refers to the structure of the configuration itself. Here&rsquo;s an outline of how you might work with PromptTemplateConfig in Java, focusing on constructing a prompt template configuration using its builder pattern. This class is part of the com.microsoft.semantickernel.semanticfunctions package. Java Code Snippets import com.microsoft.semantickernel.semanticfunctions.PromptTemplateConfig;\nimport com.microsoft.semantickernel.semanticfunctions.PromptTemplateConfig.Builder;\nimport com.microsoft.semantickernel.semanticfunctions.InputVariable;\nimport com.microsoft.semantickernel.semanticfunctions.OutputVariable;\n\n// Create an instance of PromptTemplateConfig using the Builder\nPromptTemplateConfig.Builder builder = new PromptTemplateConfig.Builder();\n\n// Set the name for the prompt template configuration\nbuilder.withName(&quot;MyPromptTemplateConfigName&quot;);\n\n// Define a template for the prompt\nbuilder.withTemplate(&quot;Please describe the impact of climate change on {{$topic}}&quot;);\n\n// Define input variables expected by this template\nInputVariable topicVariable = new InputVariable(&quot;topic&quot;, &quot;This is the topic to discuss.&quot;);\nbuilder.addInputVariable(topicVariable);\n\n// Optionally, set output variables or execution settings if needed\nOutputVariable&lt;Boolean&gt; booleanOutput = new OutputVariable&lt;&gt;(&quot;result&quot;, Boolean.class);\nbuilder.withOutputVariable(booleanOutput);\n\n// Build the PromptTemplateConfig\nPromptTemplateConfig promptTemplateConfig = builder.build();\n\n// The created 'promptTemplateConfig' can then be used in applications for AI prompts\n Key Properties and Methods Name: You can set the name of the prompt template using .withName(String name) for identification purposes. Template: The prompt string itself is defined using .withTemplate(String template) which houses the prompt structure with placeholders for variables. Input Variables: Use .addInputVariable(InputVariable inputVariable) to specify the variables that the template expects as input. Output Variable: Set an output variable that defines the type and expected output from the prompt. These elements should help you construct a prompt template configuration that can be used in various AI applications within the Microsoft Semantic Kernel. By defining these configurations properly, you ensure that your prompts are structured and executed consistently and accurately.","timestamp":1763300448027},"references/eClassifiers/InvocationContext/references/eStructuralFeatures/hooks/index.html":{"path":"InvocationContext/References/hooks","link-uuid":"8d46ee8f-b6d5-4a8b-b78f-b4df1e2bd891","title":"hooks","content":"Type HookEntry Multiplicity 0..* InvocationContext Hooks Property The InvocationContext class in the Microsoft Semantic Kernel Java API is used to pass context information to kernel functions during invocation. One of the properties provided by InvocationContext is related to hooks, through which users can configure event handling and modify behaviors of functions dynamically during execution. KernelHooks The KernelHooks class provides a mechanism to intercept and modify events throughout the kernel, including function invocation. Key Capabilities: Function Invoking and Invoked Hooks: These hooks allow custom logic to be executed before and after function execution, respectively. Prompt Rendering Hooks: These enable customization of the prompt rendering process, which can include modifying the prompt before it is sent for execution. Adding Hooks Hooks are added to the KernelHooks collection, which can then be associated with an InvocationContext. import com.microsoft.semantickernel.hooks.KernelHooks;\nimport com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.FunctionInvokingEvent;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\n\n// Create a KernelHooks instance\nKernelHooks kernelHooks = new KernelHooks();\n\n// Add a Function Invoking Hook\nkernelHooks.addFunctionInvokingHook(event -&gt; {\n    // Custom logic before function invocation\n    System.out.println(&quot;Function Invoking: &quot; + event.getFunctionName());\n    return event;\n});\n\n// Add a Function Invoked Hook\nkernelHooks.addFunctionInvokedHook(event -&gt; {\n    // Custom logic after function invocation\n    System.out.println(&quot;Function Invoked: &quot; + event.getFunctionName());\n    return event;\n});\n\n// Create an InvocationContext and set the kernel hooks\nInvocationContext context = new InvocationContext();\ncontext.getKernelHooks().addHooks(kernelHooks);\n\n// This context can now be used when invoking functions\n Summary The InvocationContext and associated KernelHooks provide rich customization capabilities in Microsoft Semantic Kernel Java, enabling developers to execute additional logic around function invocations for tasks like logging, modifying invocation parameters, and handling exceptions. This configurability is crucial for implementing enterprise-grade solutions with nuanced control requirements.","timestamp":1763300447495},"references/eClassifiers/Plugin/references/eStructuralFeatures/functions/index.html":{"path":"Plugin/References/functions","link-uuid":"5e6faa0e-65ae-4cd6-a563-8c92c3722a7f","title":"functions","content":"Type Function Multiplicity 0..* In the context of Microsoft Semantic Kernel, plugins are utilized to encapsulate existing APIs into a collection that an AI can use. Plugins in Semantic Kernel are akin to function calling; they enable AI to perform actions it couldn&rsquo;t do otherwise by invoking your code. Anatomy of a Plugin A plugin is essentially a group of functions that can be accessed by AI apps and services. These functions need to provide details, semantically describing their behavior, such as input, output, and side effects to help the AI correctly call and utilize them. Key Concepts: Functions: These are actions or tasks defined in your code that AI can invoke. Semantic Descriptions: Provide details about the function&rsquo;s input, output, and behavior to ensure the AI can use them correctly. Creating a Plugin in Java To create a plugin in Microsoft Semantic Kernel for Java, you define a class with methods that represent the functions you want AI to invoke. These methods are annotated to provide clear descriptions of their purpose and usage. Here&rsquo;s a basic example of defining a plugin in Java: public class LightsPlugin {\n\n    private final Map&lt;Integer, LightModel&gt; lights = new HashMap&lt;&gt;();\n\n    public LightsPlugin() {\n        lights.put(1, new LightModel(1, &quot;Table Lamp&quot;, false, LightModel.Brightness.MEDIUM, &quot;#FFFFFF&quot;));\n        lights.put(2, new LightModel(2, &quot;Porch light&quot;, false, LightModel.Brightness.HIGH, &quot;#FF0000&quot;));\n        lights.put(3, new LightModel(3, &quot;Chandelier&quot;, true, LightModel.Brightness.LOW, &quot;#FFFF00&quot;));\n    }\n\n    @DefineKernelFunction(name = &quot;get_lights&quot;, description = &quot;Gets a list of lights and their current state&quot;)\n    public List&lt;LightModel&gt; getLights() {\n        return new ArrayList&lt;&gt;(lights.values());\n    }\n\n    @DefineKernelFunction(name = &quot;change_state&quot;, description = &quot;Changes the state of the light&quot;)\n    public LightModel changeState(\n            @KernelFunctionParameter(\n                    name = &quot;model&quot;,\n                    description = &quot;The new state of the model to set.&quot;,\n                    type = LightModel.class) LightModel model\n    ) {\n        if (!lights.containsKey(model.getId())) {\n            throw new IllegalArgumentException(&quot;Light not found&quot;);\n        }\n\n        lights.put(model.getId(), model);\n\n        return lights.get(model.getId());\n    }\n}\n Adding the Plugin to a Kernel After defining a plugin, it can be added to a kernel. The kernel will use this plugin when interacting with AI models, allowing the AI to invoke the defined functions as needed. // Create a kernel with a plugin\nKernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chatCompletionService)\n    .withPlugin(lightPlugin)\n    .build();\n Function Execution In this context, the AI can automatically call these functions during planning, allowing for seamless integration of AI and native code functionalities. Each function is described semantically, helping the AI choose the appropriate function to execute based on the given context and task requirements. This integration allows developers to enrich AI capabilities with domain-specific logic encapsulated in a plugin, paving the way for sophisticated AI applications in the Java environment.","timestamp":1763300447791},"references/eClassifiers/TokenSelectionBiasesEntry/references/eStructuralFeatures/key/index.html":{"path":"TokenSelectionBiasesEntry/Attributes/key","link-uuid":"905fc01c-fa53-44e7-9f2a-17e690b11af1","title":"key","content":"Type EIntegerObject Multiplicity 0..1","timestamp":1763300448264},"references/eClassifiers/InputVariable/references/eStructuralFeatures/enumValues/index.html":{"path":"InputVariable/Attributes/enumValues","link-uuid":"59b30d31-e5c1-45c1-8a1c-c29d39cbfe68","title":"enumValues","content":"Type EString Multiplicity 0..*","timestamp":1763300447431},"references/eClassifiers/Invocable/references/eStructuralFeatures/parameters/index.html":{"path":"Invocable/References/parameters","link-uuid":"900aad9b-0d26-4e42-b9d3-4e49b0fb3428","title":"parameters","content":"Type InputVariable Multiplicity 0..* In Microsoft Semantic Kernel Java, the Invocable interface, which represents a functional component like a Semantic Kernel plugin function, includes a property called parameters. This property is a collection of metadata about the input parameters that the function accepts. Here&rsquo;s an overview and an example of how it might be used: Overview of Invocable Parameters Purpose: The parameters property provides details about the inputs a function requires. This information can be used by an AI model or another part of a system to understand how to invoke the function properly. Content: The parameters typically include metadata such as the name of the parameter, the type, a description, and whether it is required or has a default value. Java Code Example Here&rsquo;s a conceptual snippet showing how you could define a function in Java using Semantic Kernel annotations, which automatically generates parameter metadata: public class SamplePlugin {\n\n    @DefineKernelFunction(name = &quot;example_function&quot;, description = &quot;An example function that requires parameters.&quot;)\n    public String exampleFunction(\n            @KernelFunctionParameter(\n                name = &quot;param1&quot;,\n                description = &quot;The first parameter&quot;,\n                type = String.class,\n                required = true) \n            String param1,\n            \n            @KernelFunctionParameter(\n                name = &quot;param2&quot;,\n                description = &quot;The second parameter, not required&quot;,\n                type = Integer.class,\n                required = false,\n                defaultValue = &quot;42&quot;) \n            Integer param2) {\n        \n        // Function logic here\n        return &quot;Result&quot;;\n    }\n}\n Explanation Annotations: The @DefineKernelFunction annotation defines the function as part of a Semantic Kernel plugin, while @KernelFunctionParameter annotations provide detailed metadata about each parameter. Parameters Metadata: The parameters collection for this function will include entries for param1 and param2, detailing their types, whether they are required, and any default values. This structured approach aids in the integration and orchestration of functions, especially when combined with AI models for automated reasoning or action execution. Note: As of the information available, direct examples from the Semantic Kernel Java SDK specifically detailing the handling or access of these parameters directly are limited to framework usage patterns based on defined annotations and automatic serialization for model consumption. If you have any further specific questions about the Invocable functionality in the SDK or need detailed instruction on a specific use case, feel free to ask!","timestamp":1763300447464},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/resultsPerPrompt/index.html":{"path":"PromptExecutionSettings/Attributes/resultsPerPrompt","link-uuid":"f6f88e33-b2fe-4f28-9165-76f804ea3c3b","title":"resultsPerPrompt","content":"Type EIntegerObject Multiplicity 0..1 Summary of PromptExecutionSettings resultsPerPrompt Property in Microsoft Semantic Kernel Java The resultsPerPrompt property in the PromptExecutionSettings class of Microsoft Semantic Kernel Java is used to specify the number of results or outputs that the AI should generate for each prompt it processes. This property allows you to control how many responses you aim to receive per prompt execution, which can be useful for scenarios where multiple possible outputs should be evaluated or when you want to compare different outputs generated for the same prompt. By default, if the resultsPerPrompt is not explicitly set, it defaults to a single result per prompt (DEFAULT_RESULTS_PER_PROMPT = 1). Here is how you might use this property in Java using the builder pattern provided within the Semantic Kernel API: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport com.microsoft.semantickernel.orchestration.PromptExecutionSettings.Builder;\n\nimport java.util.List;\nimport java.util.Map;\n\n// Create a PromptExecutionSettings instance using the Builder\nPromptExecutionSettings settings = PromptExecutionSettings.builder()\n    .withServiceId(&quot;your-service-id&quot;)\n    .withModelId(&quot;your-model-id&quot;)\n    .withTemperature(0.7)\n    .withTopP(0.9)\n    .withResultsPerPrompt(3) // Set the resultsPerPrompt to 3 to get 3 results for each prompt\n    .build();\n\n// The settings instance will now be configured to request 3 outputs per AI prompt execution.\n This example sets up a PromptExecutionSettings instance where the AI is instructed to return three different results for each prompt provided, allowing for an exploration of the variability and alternative responses the AI can produce.","timestamp":1763300447899},"references/eClassifiers/InvocationContext/index.html":{"link-uuid":"25b8fc6f-3477-47d3-aa6e-f8bec14115e4","title":"InvocationContext","content":"InvocationContext Class in Microsoft Semantic Kernel (Java) The InvocationContext class is part of the com.microsoft.semantickernel.orchestration package and is used to store execution settings and additional context when invoking functions within the Semantic Kernel. It helps customize the behavior of function invocation and interaction with the AI models. Key Methods and Usage Building an InvocationContext You can create an instance of InvocationContext using its Builder class. The builder allows you to set various parameters such as context variable converters, kernel hooks, prompt execution settings, return mode, and tool call behavior. InvocationContext context = InvocationContext.builder()\n    .withContextVariableConverter(yourConverter)\n    .withKernelHooks(kernelHooks)\n    .withPromptExecutionSettings(promptExecutionSettings)\n    .withReturnMode(InvocationReturnMode.NEW_MESSAGES_ONLY)\n    .withToolCallBehavior(toolCallBehavior)\n    .build();\n Method Details build(): Compiles the InvocationContext instance with configured settings. InvocationContext context = builder.build();\n withContextVariableConverter(): Adds a context variable type converter. builder.withContextVariableConverter(contextVariableTypes);\n withKernelHooks(): Adds kernel hooks to the builder. builder.withKernelHooks(kernelHooks);\n withPromptExecutionSettings(): Adds prompt execution settings. builder.withPromptExecutionSettings(promptExecutionSettings);\n withReturnMode(): Sets the return mode for the invocation. builder.withReturnMode(InvocationReturnMode.COMPLETE_RESULT);\n withToolCallBehavior(): Adds tool call behavior to the builder. builder.withToolCallBehavior(toolCallBehavior);\n Example Usage Suppose you want to invoke a function in the Semantic Kernel with a specific setup, you can compose your invocation context and use it in relevant service calls. InvocationContext context = InvocationContext.builder()\n    .withReturnMode(InvocationReturnMode.NEW_MESSAGES_ONLY)\n    .withPromptExecutionSettings(new PromptExecutionSettings())\n    .build();\n\n// Use the context in a kernel service call\nkernel.invokeFunction(&quot;pluginName&quot;, &quot;functionName&quot;, context);\n The InvocationContext class and its builder provide a flexible and modular way to configure invocation settings, ensuring that functions called within the Semantic Kernel can be tailored to different scenarios and requirements. Diagram ","timestamp":1763300447488},"references/eClassifiers/SemanticKernelTelemetry/index.html":{"link-uuid":"0df49e01-a585-45ae-b2b1-731d57263fbb","title":"SemanticKernelTelemetry","content":"SemanticKernelTelemetry in Microsoft Semantic Kernel Java As of the current updates, Semantic Kernel observability, including telemetry, is not yet available for Java. This means that specific features such as logging, metrics, and tracing&mdash;integral to monitoring and analyzing the internal state of components in a distributed system&mdash;have not been implemented for Java in the Semantic Kernel framework. The telemetry features available in Semantic Kernel for other languages like C# and Python rely on OpenTelemetry standards to provide insights into the system&rsquo;s behavior. These features include: Logging: Recording meaningful events and errors. Metrics: Emitting metrics such as function execution time. Tracing: Supporting distributed tracing to track activities across different services. Java Status At present, these capabilities have not been extended to the Java version of Semantic Kernel. Developers using Java can anticipate future updates where such features might be introduced, aligning with the capabilities available in C# and Python versions. For now, developers working with Java must wait for forthcoming releases to have these advanced observability features included in their Semantic Kernel Java implementations. // Placeholder example code to demonstrate structure\n// Currently, no telemetry features like logging, metrics, or tracing are available in Java.\n\npublic class SemanticKernelExample {\n    public static void main(String[] args) {\n        System.out.println(&quot;Semantic Kernel Java - Observability unavailable currently.&quot;);\n    }\n}\n Please refer to official Microsoft updates or the GitHub repository for future enhancements regarding Java support. Note: The above Java code snippet is a conceptual placeholder, given the absence of observability features in Semantic Kernel Java as of the latest updates. There are no specific APIs or examples for telemetry in Java at this time. NO_INFORMATION Diagram ","timestamp":1763300448109},"references/eClassifiers/Function/index.html":{"link-uuid":"9e12b311-368d-4188-ac58-e8457dfabb17","title":"Function","content":"Microsoft Semantic Kernel Java Function In the context of Microsoft Semantic Kernel, a &ldquo;Function&rdquo; is a fundamental building block that defines a specific task or operation. These functions are executed as part of a pipeline within the kernel, allowing you to build complex workflows by stringing functions together. Each function can perform operations such as calling external services, processing data, or transforming input and outputs. While the documentation may provide insights into core concepts, here is an illustrative Java snippet on how one might define or use a function within Semantic Kernel using Java: import com.microsoft.semkernel.Function;\n\n// Define a custom function within Semantic Kernel\npublic class MyFunction extends Function {\n\n    public MyFunction(String name) {\n        // Initialize the function with a name\n        super(name);\n    }\n\n    @Override\n    public Object execute(Object input) {\n        // Implement the logic of the function here\n        return processInput(input);\n    }\n\n    private Object processInput(Object input) {\n        // Example processing logic\n        return &quot;Processed: &quot; + input.toString();\n    }\n}\n\n// Usage of the function within the kernel\npublic class Main {\n    public static void main(String[] args) {\n        // Create an instance of the function\n        MyFunction myFunction = new MyFunction(&quot;ExampleFunction&quot;);\n\n        // Execute the function with input\n        Object result = myFunction.execute(&quot;Sample Input&quot;);\n        System.out.println(result); // Output: Processed: Sample Input\n    }\n}\n Overview Definition: Functions are modular components that encapsulate specific operations or tasks. Execution: Functions are executed with specific inputs and produce outputs, enabling the development of pipelines or workflows. Customization: Functions are customizable and extendable to meet various application needs. This illustration assumes a simplified context and structure. In actual applications, there may be additional aspects like dependencies, context management, and integration with AI capabilities facilitated by Semantic Kernel APIs. For complete integration, accessing official Semantic Kernel Java libraries and documentation would provide comprehensive features and additional capabilities. Note: The provided code is a conceptual example. The actual API and integration may differ based on available libraries and framework enhancements. For specific implementations, referring to the official Java SDK for Semantic Kernel (if available) would ensure precise compliance with its API specifications. Diagram ","timestamp":1763300447207},"references/eClassifiers/GeminiTextGenerationService/index.html":{"link-uuid":"86e5991e-17fc-4bcd-b7fa-839670e753f8","title":"GeminiTextGenerationService","content":"GeminiTextGenerationService in Microsoft Semantic Kernel Java The GeminiTextGenerationService is a part of the Semantic Kernel&rsquo;s effort to integrate AI capabilities into Java applications, leveraging Google&rsquo;s Vertex AI. This service is typically constructed using the GeminiServiceBuilder&lt;T, U&gt; class, which allows developers to configure and build the text generation service. Key Components: Dependency: To use the GeminiTextGenerationService, ensure you include the appropriate Maven artifact in your project. &lt;dependency&gt;\n    &lt;groupId&gt;com.microsoft.semantic-kernel&lt;/groupId&gt;\n    &lt;artifactId&gt;semantickernel-aiservices-google&lt;/artifactId&gt;\n    &lt;version&gt;1.4.0&lt;/version&gt;\n&lt;/dependency&gt;\n Builder Pattern: The GeminiTextGenerationService is created using a builder pattern, allowing you to configure necessary parameters like modelId and VertexAI client. import com.google.cloud.vertexai.VertexAI;\nimport com.microsoft.semantickernel.aiservices.google.GeminiServiceBuilder;\n\npublic class GeminiTextGenerationServiceBuilder extends GeminiServiceBuilder&lt;GeminiTextGenerationService, GeminiTextGenerationServiceBuilder&gt; {\n\n    @Override\n    public GeminiTextGenerationService build() {\n        // Logic to build and return the GeminiTextGenerationService\n        return new GeminiTextGenerationService(this.client, this.modelId);\n    }\n\n    public GeminiTextGenerationServiceBuilder withModelId(String modelId) {\n        this.modelId = modelId;\n        return this;\n    }\n\n    public GeminiTextGenerationServiceBuilder withVertexAIClient(VertexAI client) {\n        this.client = client;\n        return this;\n    }\n}\n Usage: Below is a hypothetical way to utilize the GeminiTextGenerationServiceBuilder to create a text generation service: VertexAI vertexAIClient = VertexAI.newBuilder().setProjectId(&quot;your-google-cloud-project-id&quot;).build();\nGeminiTextGenerationService textGenerationService = new GeminiTextGenerationServiceBuilder()\n    .withModelId(&quot;your-model-id&quot;)\n    .withVertexAIClient(vertexAIClient)\n    .build();\n\n// Use textGenerationService to generate text\n In summary, the GeminiTextGenerationService integrates Google&rsquo;s AI capabilities into Java applications via Microsoft Semantic Kernel. Developers can configure and build this service using a builder pattern, providing flexibility to set up the Vertex AI client and specify the model for text generation tasks. Diagram ","timestamp":1763300447314},"references/eClassifiers/HuggingFaceTextGenerationService/index.html":{"link-uuid":"9962d32b-0f3c-461a-ae64-5da79240a15f","title":"HuggingFaceTextGenerationService","content":"The HuggingFaceTextGenerationService class in Microsoft&rsquo;s Semantic Kernel Java is a service designed to generate text using the Hugging Face API. It belongs to the package com.microsoft.semantickernel.aiservices.huggingface.services and implements the TextGenerationService interface. This class provides methods to handle text generation tasks and allows users to retrieve both streaming and non-streaming text results. Constructor You can create an instance of the HuggingFaceTextGenerationService using its constructor. It requires a model ID, a service ID, and a HuggingFaceClient. HuggingFaceTextGenerationService service = new HuggingFaceTextGenerationService(&quot;modelId&quot;, &quot;serviceId&quot;, client);\n Builder Pattern To create a HuggingFaceTextGenerationService instance, you can use the builder pattern provided by the class. HuggingFaceTextGenerationService.Builder builder = HuggingFaceTextGenerationService.builder();\n// configure the builder as needed and then build the service\nHuggingFaceTextGenerationService service = builder.build();\n Methods getModelId() Returns the model ID used by the service. String modelId = service.getModelId();\n getServiceId() Returns the service ID. String serviceId = service.getServiceId();\n getTextContentsAsync Retrieves the text generation results for a given prompt and settings asynchronously. Mono&lt;List&lt;TextContent&gt;&gt; textContents = service.getTextContentsAsync(&quot;prompt&quot;, executionSettings, kernel);\n getStreamingTextContentsAsync Retrieves the streaming text results for a given prompt and settings asynchronously. Flux&lt;StreamingTextContent&gt; streamingContents = service.getStreamingTextContentsAsync(&quot;prompt&quot;, executionSettings, kernel);\n The class is part of the Maven artifact com.microsoft.semantic-kernel:semantickernel-aiservices-huggingface:1.4.0, and you can include it in your project by adding the corresponding dependency. Diagram ","timestamp":1763300447399},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/responseFormat/index.html":{"path":"PromptExecutionSettings/References/responseFormat","link-uuid":"de507138-9e0a-4913-8110-273e309dcfbb","title":"responseFormat","content":"Type ResponseFormat Multiplicity 0..1 The PromptExecutionSettings class in Microsoft Semantic Kernel Java provides configuration settings for prompt execution. One of its properties is responseFormat, which specifies the format for the response generated by the prompt execution. Here is a detailed description: PromptExecutionSettings.getResponseFormat() Purpose: Determines the response format to use for prompt execution. This currently applies to chat completions and dictates how the output should be formatted. Return Type: ResponseFormat Example Usage import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport com.microsoft.semantickernel.orchestration.responseformat.ResponseFormat;\n\npublic class Example {\n    public static void main(String[] args) {\n        // Create a PromptExecutionSettings instance\n        PromptExecutionSettings settings = new PromptExecutionSettings(\n                &quot;serviceId&quot;,    // serviceId\n                &quot;modelId&quot;,      // modelId\n                1.0,            // temperature\n                1.0,            // topP\n                0.0,            // presencePenalty\n                0.0,            // frequencyPenalty\n                256,            // maxTokens\n                1,              // resultsPerPrompt\n                1,              // bestOf\n                &quot;user&quot;,         // user\n                List.of(&quot;stop&quot;),// stopSequences\n                Map.of(),       // tokenSelectionBiases\n                new ResponseFormat.TextResponseFormat() // responseFormat\n        );\n\n        // Accessing responseFormat\n        ResponseFormat responseFormat = settings.getResponseFormat();\n        System.out.println(&quot;Response Format: &quot; + responseFormat.toString());\n    }\n}\n Key Points The responseFormat property allows you to control the format of the result returned from a prompt execution, which is particularly important for integration scenarios where specific formats like JSON are required. Different ResponseFormat implementations (e.g., TextResponseFormat) can be used to adjust how responses are structured. This example gives an overview of how to configure the responseFormat in a PromptExecutionSettings instance within Microsoft Semantic Kernel Java.","timestamp":1763300447897},"references/eClassifiers/PromptTemplateConfig/index.html":{"link-uuid":"bf40287f-1570-4199-a542-4a6bcd651877","title":"PromptTemplateConfig","content":"The PromptTemplateConfig class in Microsoft Semantic Kernel for Java provides configuration information necessary to create a prompt template. It allows setting various attributes and configurations relevant to a prompt, including template strings, description, input and output variables, execution settings, and the option to specify the template format. Key Components of PromptTemplateConfig Template String: The core structure or text representing the prompt. Description: Provides metadata about what the prompt is intended to do. Input Variables: Defines the parameters that can be dynamically set during prompt execution. Output Variable: Specifies the expected output structure or type. Execution Settings: Configuration for how the prompt should execute, including any predefined conditions. Template Format: The format of the prompt template, which can vary depending on the use case. Java Code Example Below is an example illustrating how to build a PromptTemplateConfig using its builder method: import com.microsoft.semantickernel.semanticfunctions.PromptTemplateConfig;\nimport com.microsoft.semantickernel.semanticfunctions.InputVariable;\nimport com.microsoft.semantickernel.semanticfunctions.OutputVariable;\nimport com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\nimport java.util.List;\nimport java.util.Map;\n\npublic class PromptTemplateConfigExample {\n    public static void main(String[] args) {\n        // Create input variables\n        InputVariable topicVariable = new InputVariable(&quot;topic&quot;, &quot;The topic of the story&quot;);\n        InputVariable lengthVariable = new InputVariable(&quot;length&quot;, &quot;The number of sentences&quot;);\n\n        // Create execution settings\n        Map&lt;String, PromptExecutionSettings&gt; executionSettings = Map.of(\n            &quot;setting1&quot;, new PromptExecutionSettings() /* Assume meaningful settings here */\n        );\n\n        // Build PromptTemplateConfig\n        PromptTemplateConfig config = new PromptTemplateConfig.Builder()\n            .withName(&quot;GenerateStory&quot;)\n            .withDescription(&quot;A prompt to generate a story about a topic.&quot;)\n            .withTemplate(&quot;Tell a story about {{$topic}} that is {{$length}} sentences long.&quot;)\n            .withTemplateFormat(&quot;semantic-kernel&quot;)\n            .withInputVariables(List.of(topicVariable, lengthVariable))\n            .withExecutionSettings(executionSettings)\n            .build();\n\n        // Use the config in further operations\n        System.out.println(&quot;Prompt Template Config created: &quot; + config);\n    }\n}\n This example demonstrates how you can define a prompt template&rsquo;s configuration using the builder pattern provided by the PromptTemplateConfig class in Java. It involves setting up input variables, execution settings, and other relevant configurations for a flexible and reusable prompt setup in applications that leverage Semantic Kernel functionalities. Diagram ","timestamp":1763300448019},"references/eClassifiers/PromptRenderingHook/index.html":{"link-uuid":"f4b2395f-5b5d-4efb-8292-3e11e3cd46d6","title":"PromptRenderingHook","content":"The PromptRenderingHook interface in Microsoft Semantic Kernel Java is designed for hooks that intercept the event of rendering a prompt. This allows you to modify or inspect the prompt rendering process within a kernel. Here&rsquo;s a summary with Java code snippets: PromptRenderingHook Interface Package: com.microsoft.semantickernel.hooks Function: Designed to intercept the PromptRenderingEvent. General Use The PromptRenderingHook can be used to customize or observe prompt rendering. Hooks are powerful because they allow you to inject custom logic at various stages of the kernel&rsquo;s operation. Example Code Snippet Below is a conceptual snippet showing how you might define and use a PromptRenderingHook: import com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.promptrenderingevent;\nimport com.microsoft.semantickernel.Kernel;\n\npublic class CustomPromptRenderingHook implements KernelHook.PromptRenderingHook {\n\n    @Override\n    public PromptRenderingEvent accept(PromptRenderingEvent event) {\n        // Here, you can modify the prompt before rendering\n        String originalPrompt = event.getPrompt();\n        String modifiedPrompt = originalPrompt + &quot; [Modified by Hook]&quot;;\n\n        // Log or handle the modification as needed\n        System.out.println(&quot;Prompt has been modified: &quot; + modifiedPrompt);\n\n        // Return the modified event\n        event.setPrompt(modifiedPrompt);\n        return event;\n    }\n}\n Integration with Kernel You would typically add this hook to the kernel as part of its configuration, allowing it to intercept all prompt rendering operations: Kernel kernel = Kernel.builder()\n    .addHook(new CustomPromptRenderingHook()) // Adding the custom hook\n    .build();\n Summary The PromptRenderingHook allows you to inject logic during the prompt rendering stage. This can be used for logging, modifying the content, or other custom behaviors affecting how prompts are generated and used within the Semantic Kernel. Diagram ","timestamp":1763300447997},"references/eClassifiers/TextGenerationService/index.html":{"link-uuid":"6251c612-3518-4e49-9c2b-e019a4975ef9","title":"TextGenerationService","content":"The TextGenerationService in Microsoft Semantic Kernel for Java is an interface that allows developers to integrate different AI text generation services into their applications. Two main implementations of this service are the OpenAITextGenerationService and HuggingFaceTextGenerationService. OpenAITextGenerationService This class is an OpenAI implementation of the TextGenerationService interface. It provides methods to generate text using the OpenAI models and supports both streaming and non-streaming text content generation. Constructor To create an instance of OpenAITextGenerationService, you need to provide an OpenAIAsyncClient, modelId, serviceId, and deploymentName. OpenAIAsyncClient client = new OpenAIClientBuilder()\n    .credential(new AzureKeyCredential(&quot;YOUR_KEY&quot;))\n    .endpoint(&quot;YOUR_ENDPOINT&quot;)\n    .buildAsyncClient();\n\nOpenAITextGenerationService textGenerationService = new OpenAITextGenerationService(client, &quot;model-id&quot;, &quot;service-id&quot;, &quot;deployment-name&quot;);\n Methods getStreamingTextContentsAsync: Generates text content in a streaming fashion. getTextContentsAsync: Generates text content in a non-streaming fashion. HuggingFaceTextGenerationService This class implements the TextGenerationService interface using the Hugging Face API, allowing text generation with Hugging Face models. Constructor To instantiate a HuggingFaceTextGenerationService, you must pass a modelId, serviceId, and a HuggingFaceClient. HuggingFaceClient client = new HuggingFaceClient(&quot;YOUR_API_TOKEN&quot;);\n\nHuggingFaceTextGenerationService textGenerationService = new HuggingFaceTextGenerationService(&quot;model-id&quot;, &quot;service-id&quot;, client);\n Methods getStreamingTextContentsAsync: Supports streaming text generation. getTextContentsAsync: Provides non-streaming text generation capabilities. Example Usage Here&rsquo;s an example of how you might use a TextGenerationService in a hypothetical application: Kernel kernel = Kernel.builder()\n    .withAIService(TextGenerationService.class, textGenerationService)\n    .build();\n\nString prompt = &quot;Generate a short story about AI&quot;;\nPromptExecutionSettings settings = new PromptExecutionSettings();\n\nList&lt;TextContent&gt; responses = textGenerationService.getTextContentsAsync(prompt, settings, kernel).block();\n\nfor (TextContent content : responses) {\n    System.out.println(content.getContent());\n}\n This setup demonstrates integrating a text generation service with the Semantic Kernel to generate AI-driven text outputs using different underlying AI models (OpenAI or Hugging Face). Diagram ","timestamp":1763300448194},"references/eClassifiers/PreChatCompletionHook/index.html":{"link-uuid":"81965c85-f75a-4fe0-9ef7-67f481818109","title":"PreChatCompletionHook","content":"The PreChatCompletionHook is an interface in the com.microsoft.semantickernel.hooks package. It is designed to intercept events that occur before a chat completion is invoked in the Microsoft Semantic Kernel for Java. This interface allows for custom logic to be applied prior to the chat process, which can be beneficial for modifying the arguments or implementing additional validation or logging. Here is a conceptual overview and code snippet exemplifying how you might use this interface: PreChatCompletionHook Interface Interface Description: - Purpose: To handle events occurring before a chat completion. - Implementation: Developers can implement this interface to define specific actions to take prior to the execution of a chat completion request. Example Usage import com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.PreChatCompletionEvent;\n\npublic class CustomPreChatHook implements KernelHook.PreChatCompletionHook {\n\n    @Override\n    public void accept(PreChatCompletionEvent event) {\n        // Custom logic before chat completion\n        System.out.println(&quot;Before chat completion: &quot; + event.getDetails());\n        \n        // Modify event data or arguments if needed\n        event.setSomeProperty(&quot;Modified Value&quot;);\n    }\n}\n\n// Usage within a Kernel setup\nKernel kernel = Kernel.builder()\n    .withHook(new CustomPreChatHook()) // Attach your custom pre-chat hook\n    .build();\n In this example, the custom hook CustomPreChatHook implements the KernelHook.PreChatCompletionHook and overrides its accept method, allowing developers to inject logic that runs before a chat completion task executes. The event object contains details about the chat session and can be utilized or modified according to the requirements of the application. Please note that the actual properties and methods in the PreChatCompletionEvent would depend on the specific design and implementation in the actual Microsoft Semantic Kernel Java library. Diagram ","timestamp":1763300447829},"references/eClassifiers/FunctionInvokedHook/inheritance.html":{"path":"FunctionInvokedHook/Inheritance","link-uuid":"2396ef5a-dac7-42d0-88f1-b837daa8ec2d","title":"Inheritance","content":"Supertypes ","timestamp":1763300447239},"references/eClassifiers/PromptRenderedHook/inheritance.html":{"path":"PromptRenderedHook/Inheritance","link-uuid":"4c5a01fa-31bf-4639-a213-ed0a7172b1bf","title":"Inheritance","content":"Supertypes ","timestamp":1763300447979},"references/eClassifiers/AIService/references/eStructuralFeatures/service/index.html":{"path":"AIService/Attributes/service","link-uuid":"3ccdeb4a-7c16-477e-beac-5aa4fd06f738","title":"service","content":"Type EString Multiplicity 0..1 The AIService interface in Microsoft Semantic Kernel Java is a marker interface for AI services, which are then registered with the Kernel. This interface provides access to AI services by defining two essential methods that help in identifying the AI service and the model being used. Methods in AIService Interface getModelId() Description: This method retrieves the model identifier, which represents the AI model being utilized. Returns: A String representing the model identifier if specified, otherwise null. public abstract String getModelId();\n getServiceId() Description: This method retrieves the service identifier, serving as a unique ID for the AI service. Returns: A String that identifies the service. public abstract String getServiceId();\n These methods within the AIService interface are essential for distinguishing between different AI services and models when managing them with the Semantic Kernel. This allows for flexibility and scalability in building AI-driven applications by enabling the use and swap-out of various AI service implementations.","timestamp":1763300447072},"references/eClassifiers/InvocationReturnMode/references/eLiterals/FULL_HISTORY/index.html":{"path":"InvocationReturnMode/FULL_HISTORY","link-uuid":"b866c101-6d3b-4c75-bb6d-8ec963b62c23","title":"FULL_HISTORY","content":"The InvocationReturnMode enum in Microsoft Semantic Kernel Java outlines the mode in which function invocations should return results, especially relevant when dealing with a history of previous invocations, such as in chat completions. FULL_HISTORY The FULL_HISTORY property is a part of the InvocationReturnMode enum that specifies when a function invocation returns results, it should include the full history of messages up until that invocation. This is useful when you need complete context or a comprehensive history of interactions for tasks such as chat operations where retaining past conversations is essential. Example Usage in Java Here is a sample code snippet demonstrating the use of the FULL_HISTORY property with a chat completion service: import com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.aiservices.openai.chatcompletion.OpenAIChatCompletion;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\nimport com.microsoft.semantickernel.orchestration.InvocationReturnMode;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatHistory;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatMessageContent;\n\n// Assume necessary setup for OpenAIChatCompletion and Kernel is done above...\n\n// Create the chat completion service\nChatCompletionService chatCompletionService = OpenAIChatCompletion.builder()\n    .withModelId(&quot;model-id&quot;)\n    .withOpenAIAsyncClient(client)\n    .build();\n\n// Create a kernel with the chat completion service\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chatCompletionService)\n    .build();\n\n// Configure the invocation context to return full history\nInvocationContext invocationContext = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.FULL_HISTORY)\n    .build();\n\n// Create a history object to hold the conversation\nChatHistory history = new ChatHistory();\nhistory.addUserMessage(&quot;Hello, how are you?&quot;);\n\n// Perform the chat completion function invocation\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, invocationContext)\n    .block();\n\n// Output the full history\nfor (ChatMessageContent&lt;?&gt; result : results) {\n    System.out.println(&quot;Role: &quot; + result.getAuthorRole() + &quot;, Message: &quot; + result.getContent());\n}\n In this example, the chat completion system uses the FULL_HISTORY option to ensure that the complete conversation history is included in the results, which can be critical for applications where understanding the full context of a chat session is necessary.","timestamp":1763300447512},"references/eClassifiers/InvocationReturnMode/references/eLiterals/NEW_MESSAGES_ONLY/index.html":{"path":"InvocationReturnMode/NEW_MESSAGES_ONLY","link-uuid":"f7f27b84-79f0-4f69-b07c-b1df46195988","title":"NEW_MESSAGES_ONLY","content":"The InvocationReturnMode enum in Microsoft Semantic Kernel Java is part of the com.microsoft.semantickernel.orchestration package. It defines the mode in which a function invocation should return its results. One of the options available in this enum is NEW_MESSAGES_ONLY. NEW_MESSAGES_ONLY This mode specifies that function invocations which build upon a history of previous invocations, such as Chat Completions, will return only new messages generated by the given invocation. This means that when a function is invoked, only the messages that were newly created during this specific invocation are returned, rather than a full or partial history of previous invocations. Example Usage in Java Here is an example snippet showcasing how you might utilize the NEW_MESSAGES_ONLY mode: import com.microsoft.semantickernel.orchestration.InvocationReturnMode;\nimport com.microsoft.semantickernel.services.chatcompletion.ChatCompletionService;\n\n// Assume chatCompletionService is properly initialized\nChatCompletionService chatCompletionService = ...\n\nInvocationContext invocationContext = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.NEW_MESSAGES_ONLY)\n    .build();\n\n// Assume history and kernel are already defined\nChatHistory history = new ChatHistory();\nhistory.addUserMessage(&quot;Hello, what's the weather today?&quot;);\n\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, invocationContext)\n    .block();\n\n// Print only new messages generated during the invocation\nfor (ChatMessageContent&lt;?&gt; result : results) {\n    System.out.println(result.getContent());\n}\n In this example, when invoking the chat completion service, it only returns new messages generated from the latest invocation, which is useful in cases where you want to track changes or updates without revisiting the entire history of interactions.","timestamp":1763300447516},"index.html":{"link-uuid":"556ad7fb-c267-4673-a1a2-3130bc507d30","title":"Semantic Kernel Model","content":"TODO - uses, logical model vs runtime/physical PromptRenderingHook OpenAITextEmbeddingGenerationService GeminiChatCompletion ResponseFormat FunctionInvokingHook GeminiTextGenerationService InvocationContext EmbeddingGenerationService Plugin PromptExecutionSettings responseFormat promptExecutionSettings TextGenerationService OpenAiAudioToTextService PromptRenderedHook TextEmbeddingGenerationService OpenAIChatCompletion FunctionInvokedHook JsonSchemaResponseFormat HookEntry hooks OutputVariable OpenAiTextToAudioService SemanticKernelTelemetry telemetry TextToAudioService JsonObjectResponseFormat OpenAITextGenerationService HuggingFaceTextGenerationService TokenSelectionBiasesEntry tokenSelectionBiases PromptTemplateConfig InputVariable Invocable parameters ChatCompletionService PreChatCompletionHook PromptFunction AIService SpelFunction PreToolCallHook TextResponseFormat PromptExecutionSettingsEntry value promptExecutionSettings ScriptedFunction Function type functions Hook value TextAIService InvocationReturnMode AIServiceSelector PostChatCompletionHook AudioToTextService Kernel services hooks plugins aiServiceSelector A2A","timestamp":1763300447031},"references/eClassifiers/EmbeddingGenerationService/index.html":{"link-uuid":"213a608e-ffd8-4f22-b395-18dbc5bcfd15","title":"EmbeddingGenerationService","content":"The EmbeddingGenerationService in Microsoft Semantic Kernel Java is an interface designed for the generation of textual embeddings, which are essentially vectors representing the semantic meaning of text. This is useful for tasks such as similarity comparison or search, and the embeddings can be used in various AI scenarios, including Retrieval Augmented Generation (RAG). Key Components Embedding Class: Represents a strongly typed vector of numeric data. TextEmbeddingGenerationService Interface: An interface for text embedding generation services, allowing the generation of embeddings from given text data. OpenAITextEmbeddingGenerationService Class: This is an implementation of the TextEmbeddingGenerationService specifically for generating embeddings using OpenAI models. Usage Example Here is an example of how you might use the OpenAITextEmbeddingGenerationService: import com.microsoft.semantickernel.aiservices.openai.textembedding.OpenAITextEmbeddingGenerationService;\nimport com.azure.ai.openai.OpenAIAsyncClient;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\n\n// Initialize OpenAI client and the embedding service\nOpenAIAsyncClient client = new OpenAIAsyncClientBuilder()\n    .credential(new AzureKeyCredential(&quot;your-api-key&quot;))\n    .endpoint(&quot;your-endpoint&quot;)\n    .buildAsyncClient();\n\nOpenAITextEmbeddingGenerationService embeddingService = new OpenAITextEmbeddingGenerationService(\n    client,\n    &quot;deploymentName&quot;,\n    &quot;modelId&quot;,\n    &quot;serviceId&quot;,\n    OpenAITextEmbeddingGenerationService.EMBEDDING_DIMENSIONS_LARGE\n);\n\n// Generate embeddings for a single text\nMono&lt;Embedding&gt; singleEmbedding = embeddingService.generateEmbeddingAsync(&quot;Sample text to embed&quot;);\n\n// Generate embeddings for multiple texts\nList&lt;String&gt; texts = List.of(&quot;Text 1&quot;, &quot;Text 2&quot;);\nMono&lt;List&lt;Embedding&gt;&gt; multipleEmbeddings = embeddingService.generateEmbeddingsAsync(texts);\n Considerations Dimensions: When creating the OpenAITextEmbeddingGenerationService, specify the dimensions according to the model used, such as EMBEDDING_DIMENSIONS_LARGE for larger models. Dependencies: Ensure you have the appropriate Maven dependencies, such as com.microsoft.semantic-kernel:semantickernel-aiservices-openai, to use these services. This approach allows for the integration of advanced AI services into applications, facilitating tasks like searching and analyzing the semantic content of text efficiently. Diagram ","timestamp":1763300447178},"references/eClassifiers/PromptExecutionSettings/inheritance.html":{"path":"PromptExecutionSettings/Inheritance","link-uuid":"57db58de-5c4d-4f63-81a0-0104f6394b1b","title":"Inheritance","content":"Supertypes ","timestamp":1763300447880},"references/eClassifiers/JsonSchemaResponseFormat/index.html":{"link-uuid":"5f4b2a32-e126-4ee9-a218-dd6de18666a1","title":"JsonSchemaResponseFormat","content":"The JsonSchemaResponseFormat in Microsoft Semantic Kernel for Java is a representation of a response in JSON schema format. It is part of the com.microsoft.semantickernel.orchestration.responseformat package. This format is useful when you need to define the structure of responses in your AI orchestration tasks, ensuring they adhere to a specified JSON schema. Key Components JsonSchemaResponseFormat.Builder Class: A builder class that helps create instances of JsonSchemaResponseFormat. It provides various methods to set the details of the JSON schema. Constructor No explicit constructor details are provided for JsonSchemaResponseFormat, but you can use the builder to construct it. Methods build(): Finalizes and creates an instance of JsonSchemaResponseFormat. JsonSchemaResponseFormat format = new JsonSchemaResponseFormat.Builder()\n    .setJsonSchema(&quot;your-json-schema&quot;)\n    .build();\n setJsonResponseSchema(JsonResponseSchema jsonResponseSchema): Sets the JSON response schema using an instance of JsonResponseSchema. JsonSchemaResponseFormat.Builder builder = new JsonSchemaResponseFormat.Builder();\nbuilder.setJsonResponseSchema(jsonResponseSchema);\n setJsonSchema(String jsonSchema): Directly sets the JSON schema string. builder.setJsonSchema(&quot;{ \\&quot;type\\&quot;: \\&quot;object\\&quot;, \\&quot;properties\\&quot;: { \\&quot;name\\&quot;: { \\&quot;type\\&quot;: \\&quot;string\\&quot; } } }&quot;);\n setName(String name): Sets the name for the JSON schema. builder.setName(&quot;SampleSchema&quot;);\n setResponseFormat(Class&lt;?&gt; clazz): Sets the response format by using a class with Jackson to generate the schema. builder.setResponseFormat(SampleClass.class);\n setStrict(boolean strict): Specifies whether the JSON schema should be strictly enforced. builder.setStrict(true);\n Usage Example Here is a complete example showing how to utilize the JsonSchemaResponseFormat.Builder: JsonSchemaResponseFormat format = new JsonSchemaResponseFormat.Builder()\n    .setJsonSchema(&quot;{ \\&quot;type\\&quot;: \\&quot;object\\&quot;, \\&quot;properties\\&quot;: { \\&quot;name\\&quot;: { \\&quot;type\\&quot;: \\&quot;string\\&quot; } } }&quot;)\n    .setName(&quot;SampleSchema&quot;)\n    .setStrict(true)\n    .build();\n Make sure to include necessary packages and handle exceptions as required in your application context. This summary provides an overview of configuring and using the JsonSchemaResponseFormat with customization options through the builder pattern. Diagram ","timestamp":1763300447554},"references/eClassifiers/InputVariable/inheritance.html":{"path":"InputVariable/Inheritance","link-uuid":"effa3225-b71c-45aa-a908-0469829c7ddf","title":"Inheritance","content":"Supertypes ","timestamp":1763300447424},"references/eClassifiers/InvocationContext/inheritance.html":{"path":"InvocationContext/Inheritance","link-uuid":"5ae6fa36-6505-4bee-9436-134de5422303","title":"Inheritance","content":"Supertypes ","timestamp":1763300447490},"references/eClassifiers/InvocationReturnMode/references/eLiterals/LAST_MESSAGE_ONLY/index.html":{"path":"InvocationReturnMode/LAST_MESSAGE_ONLY","link-uuid":"b799eabe-36a1-4983-a0d1-11221ef5481b","title":"LAST_MESSAGE_ONLY","content":"In Microsoft Semantic Kernel Java, the InvocationReturnMode enum is used to specify how the results of a function invocation should be returned. The LAST_MESSAGE_ONLY property is one of the configurations of this enum. LAST_MESSAGE_ONLY Property Purpose: When using the LAST_MESSAGE_ONLY setting, the kernel function invocations return only the last message generated by the invocation. This is particularly useful in scenarios like chat completions, where you might only be interested in the final response produced by a sequence of function calls, rather than the entire conversation history or the new messages. Java Code Snippet Here is a simple example demonstrating how you might configure a kernel to use the LAST_MESSAGE_ONLY return mode: import com.microsoft.semantickernel.aiservices.openai.chatcompletion.OpenAIChatCompletion;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\nimport com.microsoft.semantickernel.orchestration.InvocationReturnMode;\nimport com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.plugin.KernelPlugin;\nimport com.microsoft.semantickernel.plugin.KernelPluginFactory;\n\n// Initialize the AI service client\nChatCompletionService chatCompletionService = OpenAIChatCompletion.builder()\n    .withModelId(&quot;your-model-id&quot;)\n    .withOpenAIAsyncClient(yourOpenAIAsyncClient)\n    .build();\n\n// Import or create your plugin\nKernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\n// Build the kernel with the AI service and plugin\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chatCompletionService)\n    .withPlugin(lightPlugin)\n    .build();\n\n// Configure the invocation context to use LAST_MESSAGE_ONLY mode\nInvocationContext context = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.LAST_MESSAGE_ONLY)\n    .build();\n\n// Begin an interaction with the AI service\nChatHistory history = new ChatHistory();\nhistory.addUserMessage(&quot;What's the status of the lights?&quot;);\n\n// Invoke the chat service\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, context)\n    .block();\n\n// Output the last message generated\nSystem.out.println(&quot;Assistant &gt; &quot; + results.get(0));\n This Java snippet sets up a chat service with the LAST_MESSAGE_ONLY invocation return mode, meaning only the last message of the generated conversation will be retrieved and printed.","timestamp":1763300447514},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/service/index.html":{"path":"PromptExecutionSettings/Attributes/service","link-uuid":"b7cf7745-3c17-406f-a694-f876cfb13034","title":"service","content":"Type EString Multiplicity 0..1 The PromptExecutionSettings class in Microsoft Semantic Kernel Java is used to configure settings for prompt execution with AI services. This class allows users to specify various parameters that control the behavior and outputs of AI prompts. Here&rsquo;s a summary of the service property within the context of PromptExecutionSettings: serviceId Property Definition: The serviceId is a property within PromptExecutionSettings that identifies the AI service used for executing prompts. It can be set to specify which specific service, such as Azure OpenAI or any other supported service, should be called during the prompt execution. Default Value: If no service ID is provided, a default value of &quot;default&quot; is used. Example Usage in Java Here&rsquo;s how you can use the serviceId property with the PromptExecutionSettings class in Java: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\npublic class Example {\n\n    public static void main(String[] args) {\n        // Creating an instance of PromptExecutionSettings with specified serviceId\n        PromptExecutionSettings settings = new PromptExecutionSettings.Builder()\n                .withServiceId(&quot;openai&quot;)\n                .withModelId(&quot;gpt-3.5&quot;)\n                .withTemperature(1.0)\n                .build();\n\n        // Use this settings object to configure prompt execution with a specific AI service\n        System.out.println(&quot;Service ID: &quot; + settings.getServiceId());\n    }\n}\n In this code snippet, we demonstrate how to set the serviceId using the PromptExecutionSettings.Builder to specify the AI service used for the execution of prompts. The example sets the service to use OpenAI with the model identifier gpt-3.5. After configuring these settings, they can be utilized in conjunction with a Kernel object to execute a prompt using the specified service.","timestamp":1763300447901},"references/eClassifiers/OutputVariable/inheritance.html":{"path":"OutputVariable/Inheritance","link-uuid":"41b4f439-1648-47b4-ace7-fab910e4d699","title":"Inheritance","content":"Supertypes ","timestamp":1763300447761},"references/eClassifiers/TextResponseFormat/index.html":{"link-uuid":"abbe39fb-832d-4d34-bf9c-62239e777b07","title":"TextResponseFormat","content":"The TextResponseFormat class in Microsoft Semantic Kernel Java is a representation of response formats specifically tailored for text outputs. It is part of the com.microsoft.semantickernel.orchestration.responseformat package and serves as a way to define and use response formats where the AI&rsquo;s output is expected to be in text form. Here&rsquo;s an example of how you might define and use the TextResponseFormat in your Java code: // Import necessary classes\nimport com.microsoft.semantickernel.orchestration.responseformat.TextResponseFormat;\nimport com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\n// Create an instance of TextResponseFormat\nTextResponseFormat textResponseFormat = new TextResponseFormat();\n\n// Example usage in PromptExecutionSettings\nPromptExecutionSettings settings = new PromptExecutionSettings.Builder()\n        .withResponseFormat(textResponseFormat)\n        .build();\n The TextResponseFormat would typically be used when configuring prompt execution settings to ensure that the output of the AI model is formatted as plain text. Diagram ","timestamp":1763300448216},"references/eClassifiers/SpelFunction/references/eStructuralFeatures/expression/index.html":{"path":"SpelFunction/Attributes/expression","link-uuid":"21785780-b3c4-4c90-920b-b9b3a3ca170c","title":"expression","content":"Type EString Multiplicity 0..1 The Microsoft Semantic Kernel Java provides a way for AI agents to interact with Java code using the concept of plugins, which are a key component in the architecture of the kernel. The SpelFunction expression property is used to define a kernel function using SpEL (Spring Expression Language) in Java code. This allows developers to encapsulate functionality within plugins for AI agents to call and make use of. Here&rsquo;s a summary of how you can define and use such functions, with code snippets in Java: Defining a Kernel Function using SpelFunction To define a kernel function using the DefineKernelFunction, developers can leverage the @KernelFunction attribute. This is useful for describing methods in a Java class that can be exposed to an AI application through the Semantic Kernel: import com.microsoft.semantic.kernel.plugins.enhancers.DefineKernelFunction;\nimport com.microsoft.semantic.kernel.plugins.enhancers.KernelFunctionParameter;\n\npublic class MathPlugin {\n  \n  @DefineKernelFunction(name = &quot;add_numbers&quot;, description = &quot;Adds two numbers&quot;)\n  public int addNumbers(\n         @KernelFunctionParameter(name = &quot;a&quot;, description = &quot;The first integer&quot;) int a,\n         @KernelFunctionParameter(name = &quot;b&quot;, description = &quot;The second integer&quot;) int b) {\n    return a + b;\n  }\n}\n Using the Kernel Function Create a Kernel: To use this function within a Kernel, you&rsquo;ll first need to create an instance of the plugin and add it to the kernel. // Create a kernel with the MathPlugin\nKernel kernel = Kernel.builder()\n    .withPlugin(new MathPlugin())\n    .build();\n Invoke the Function: Use the Semantic Kernel to invoke the function in response to requests from AI agents. // Use the kernel to invoke the &quot;add_numbers&quot; function\nint result = kernel.invokeFunction(&quot;MathPlugin&quot;, &quot;add_numbers&quot;, 5, 3);\nSystem.out.println(&quot;Result: &quot; + result); // Output: Result: 8\n Description and Role The role of such functions, described and implemented via Java annotations and SpEL, is crucial for enabling AI applications to perform actions by interacting with Java-based APIs. These kernel functions can encapsulate business logic, data retrieval, or any operational logic that needs to be exposed to and executed by AI agents. By leveraging SpEL and Semantic Kernel plugins, developers can efficiently integrate AI capabilities into Java applications, allowing dynamic and intelligent contextual responses. This enhances the usability of AI in various application scenarios where Java is a primary development language. For more comprehensive usage and implementation, developers are encouraged to explore additional Semantic Kernel components and documentation.","timestamp":1763300448134},"references/eClassifiers/AudioToTextService/index.html":{"link-uuid":"1ea1b0a7-80db-4c93-908a-1eef75714f96","title":"AudioToTextService","content":"The AudioToTextService in Microsoft&rsquo;s Semantic Kernel Java package enables the conversion of audio content to text. This service is part of the broader AI services provided by the Semantic Kernel for integrating AI capabilities into applications. Here&rsquo;s a summary of the key components and how to utilize them, along with Java code snippets: Key Components AudioContent: Represents the audio content that you want to convert to text. AudioToTextExecutionSettings: These settings allow you to configure how the audio-to-text conversion process should be executed. AudioToTextService: The main interface that provides the functionality to convert audio into text. Sample Java Code To use the AudioToTextService, you first need to create instances of AudioContent and AudioToTextExecutionSettings. Once these are set up, you can use an instance of AudioToTextService to perform the conversion. import com.microsoft.semantickernel.services.audio.AudioContent;\nimport com.microsoft.semantickernel.services.audio.AudioToTextExecutionSettings;\nimport com.microsoft.semantickernel.services.audio.AudioToTextService;\n\n// Create an instance of AudioContent\nAudioContent audioContent = AudioContent.builder()\n    .withData(yourAudioData) // yourAudioData should be the actual audio data\n    .build();\n\n// Define execution settings, if needed\nAudioToTextExecutionSettings executionSettings = AudioToTextExecutionSettings.builder()\n    .withSomeSetting(yourSetting) // replace with actual settings as needed\n    .build();\n\n// Create an instance of AudioToTextService\nAudioToTextService audioToTextService = ...; // Acquire or implement the service instance\n\n// Use the service to convert audio to text\nTextContent textContent = audioToTextService.convert(audioContent, executionSettings);\n\n// Output the text content\nSystem.out.println(&quot;Text content: &quot; + textContent.toString());\n Note: yourAudioData and yourSetting should be replaced with actual data and settings, and you need to provide an instance of AudioToTextService from the implementation you are using. The AudioToTextService.Builder can also be used to create custom instances of the service, tailored to specific configurations or use cases. Diagram ","timestamp":1763300447123},"references/eClassifiers/HookEntry/references/eStructuralFeatures/key/index.html":{"path":"HookEntry/Attributes/key","link-uuid":"3241306c-b203-40ec-9975-75cf7bf3e1f0","title":"key","content":"Type EString Multiplicity 0..1 HookEntry Key Property In Microsoft Semantic Kernel Java, a &ldquo;hook&rdquo; is a mechanism for intercepting and manipulating events in the kernel. Each hook can have a unique key that identifies it within a collection of hooks. This key is crucial for managing hooks, such as adding, removing, or identifying specific hooks in a KernelHooks collection. Java Code Snippets Here&rsquo;s a conceptual demonstration of how a hook might be added to a KernelHooks collection with a key property: import com.microsoft.semantickernel.hooks.*;\nimport java.util.function.Function;\n\n// Create a KernelHooks instance\nKernelHooks kernelHooks = new KernelHooks();\n\n// Define a hook function\nFunction&lt;FunctionInvokedEvent&lt;Object&gt;, FunctionInvokedEvent&lt;Object&gt;&gt; myFunctionInvokedHook = event -&gt; {\n    // Logic to handle the hook\n    System.out.println(&quot;Function was invoked!&quot;);\n    return event;\n};\n\n// Add the hook to the kernel hooks collection with a unique key\nString hookKey = kernelHooks.addFunctionInvokedHook(myFunctionInvokedHook);\n\n// Retrieve and execute the hook using the key\nFunctionInvokedEvent&lt;Object&gt; exampleEvent = new FunctionInvokedEvent&lt;&gt;();\nFunctionInvokedEvent&lt;Object&gt; resultEvent = kernelHooks.executeHooks(exampleEvent);\n Explanation KernelHooks: This class is used to manage a collection of hooks. It allows adding, removing, and executing hooks based on events. Hook Addition: The code snippet demonstrates how to add a hook to the kernel&rsquo;s hook collection using a key that is internally managed when adding the function via the addFunctionInvokedHook method. Event Handling: The hook defined here is an example that prints a message when the hook is executed. The executeHooks method processes events and triggers the appropriate hooks. The hook&rsquo;s key is internally managed in the system as shown in this simulation, where you would check for the key to manage or modify specific hooks in more complex and detailed real-world implementations. This provides a simplified look into how one might interact with hook entries and their keys within the Semantic Kernel Java library, allowing you to manage and utilize hooks effectively.","timestamp":1763300447376},"references/eClassifiers/HuggingFaceTextGenerationService/inheritance.html":{"path":"HuggingFaceTextGenerationService/Inheritance","link-uuid":"d6107828-aa1d-4518-b3fa-1288916250c1","title":"Inheritance","content":"Supertypes ","timestamp":1763300447401},"references/eClassifiers/PromptExecutionSettingsEntry/index.html":{"link-uuid":"de61b25b-d04d-4476-bcbb-33f7e92d4136","title":"PromptExecutionSettingsEntry","content":"The PromptExecutionSettings class in Microsoft Semantic Kernel Java, found in the package com.microsoft.semantickernel.orchestration, is used for configuring settings related to prompt execution within the Semantic Kernel framework. This class allows you to define parameters such as service ID, model ID, execution temperature, and several other settings that control the behavior of AI models when executing prompts. Key Features Service and Model Identification: The settings allow you to specify the AI service and model to be used. Execution Controls: You can control the randomness of the output with parameters like temperature and topP, and manage result generation with maxTokens and resultsPerPrompt. Penalties: Presence and frequency penalties can be applied to encourage diversity in token usage. Customization: Token selection biases can be defined to influence token probability during execution. Constructor The PromptExecutionSettings constructor requires several parameters, including: serviceId: The AI service identifier. modelId: The model identifier. Various execution control parameters such as temperature, topP, maxTokens, etc. Example in Java Here is an example of how you might create a PromptExecutionSettings object using the builder pattern: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\n// Create PromptExecutionSettings using Builder\nPromptExecutionSettings settings = PromptExecutionSettings.builder()\n    .withModelId(&quot;gpt-4&quot;)\n    .withServiceId(&quot;default&quot;)\n    .withTemperature(0.7)\n    .withTopP(0.9)\n    .withMaxTokens(150)\n    .withResultsPerPrompt(3)\n    .build();\n This snippet illustrates initializing the PromptExecutionSettings with specific values for constructing a model execution setup, which impacts how prompts are processed by the kernel. Methods PromptExecutionSettings includes methods to get and customize different settings: Getters: Access various configuration properties like getTemperature(), getMaxTokens(), etc. Builder Methods: withTemperature(double temperature), withServiceId(String serviceId), provide fluency in setting attributes before building the settings object. For advanced cases, you can also specify stopSequences or tokenSelectionBiases to fine-tune the text generation behavior. Overall, PromptExecutionSettings provides a critical configuration capability within Microsoft&rsquo;s Semantic Kernel Java SDK, driving the customization and control needed for AI-driven applications. Diagram ","timestamp":1763300447931},"references/eClassifiers/InvocationContext/references/eStructuralFeatures/telemetry/index.html":{"path":"InvocationContext/References/telemetry","link-uuid":"989148a4-44fe-4094-a91f-98d7394711f2","title":"telemetry","content":"Type SemanticKernelTelemetry Multiplicity 0..1 InvocationContext Class in Microsoft Semantic Kernel Java The InvocationContext class is a part of the com.microsoft.semantickernel.orchestration package in the Semantic Kernel Java library. It&rsquo;s primarily used to hold the context during the invocation of kernel functions or a kernel itself. Although the class itself is not explicitly providing observability features like logging, metrics, or tracing as part of its design, it interacts with the broader Semantic Kernel framework, which is designed to support observability. Key Features: Context Variable Types: Allows retrieval of the types of context variables in use. ContextVariableTypes contextVariableTypes = invocationContext.getContextVariableTypes();\n Kernel Hooks: Accesses hooks used during kernel invocation. UnmodifiableKernelHooks kernelHooks = invocationContext.getKernelHooks();\n Prompt Execution Settings: Retrieves settings related to prompt execution. PromptExecutionSettings promptExecutionSettings = invocationContext.getPromptExecutionSettings();\n Tool Call Behavior: Determines the behavior for tool calls. ToolCallBehavior toolCallBehavior = invocationContext.getToolCallBehavior();\n Invocation Return Mode: Specifies the return mode for the invocation. InvocationReturnMode returnMode = invocationContext.returnMode();\n Example Code Snippet: InvocationContext invocationContext = new InvocationContext.Builder()\n    .withToolCallBehavior(ToolCallBehavior.allowAllKernelFunctions(true))\n    .withReturnMode(InvocationReturnMode.LAST_MESSAGE_ONLY)\n    .build();\n\nSystem.out.println(&quot;Context Variable Types: &quot; + invocationContext.getContextVariableTypes());\nSystem.out.println(&quot;Kernel Hooks: &quot; + invocationContext.getKernelHooks());\nSystem.out.println(&quot;Prompt Execution Settings: &quot; + invocationContext.getPromptExecutionSettings());\nSystem.out.println(&quot;Tool Call Behavior: &quot; + invocationContext.getToolCallBehavior());\nSystem.out.println(&quot;Invocation Return Mode: &quot; + invocationContext.returnMode());\n Observability in Semantic Kernel While InvocationContext itself doesn&rsquo;t directly provide telemetry features, Semantic Kernel as a whole is equipped to be observable by logging meaningful events, emitting metrics, and supporting distributed tracing, all of which are crucial for building enterprise-ready AI solutions. However, as of now, Semantic Kernel&rsquo;s observability features, such as those compatible with OpenTelemetry, are not yet implemented for Java, meaning the collection of telemetry related to function invocations is limited to the framework&rsquo;s operational level in other languages, mainly .NET and Python. Conclusion In summary, the InvocationContext class is a utility for managing invocation details of kernel functions in Java but does not contribute directly to monitoring or telemetry data collection within Semantic Kernel. Observability is a framework-level feature that is expected to be extended in Java in future updates to include logging, metrics, and tracing utilities as available in other language implementations.","timestamp":1763300447504},"references/eClassifiers/PromptExecutionSettingsEntry/references/eStructuralFeatures/value/index.html":{"path":"PromptExecutionSettingsEntry/References/value","link-uuid":"bf62e16d-1b60-4c23-9972-566ec3c6e2b1","title":"value","content":"Type PromptExecutionSettings Multiplicity 1 The PromptExecutionSettings class in Microsoft Semantic Kernel Java provides configuration settings for prompt execution. This includes setting defaults and parameters for elements like model IDs, temperature, max tokens, and more. The value properties of PromptExecutionSettings are used to control how AI prompts are processed and interpreted when interacting with a given model. Here is how you might create and configure a PromptExecutionSettings instance using a builder in Java: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport com.microsoft.semantickernel.orchestration.ResponseFormat;\n\nimport java.util.List;\nimport java.util.Map;\n\npublic class PromptExecutionExample {\n\n    public static void main(String[] args) {\n        // Create a PromptExecutionSettings using the builder pattern\n        PromptExecutionSettings settings = PromptExecutionSettings.builder()\n                .withModelId(&quot;gpt-3.5-turbo&quot;)\n                .withServiceId(&quot;openai&quot;)\n                .withTemperature(0.7)\n                .withTopP(0.9)\n                .withMaxTokens(250)\n                .withPresencePenalty(0.5)\n                .withFrequencyPenalty(0.3)\n                .withStopSequences(List.of(&quot;\\n&quot;, &quot;End&quot;))\n                .withTokenSelectionBiases(Map.of(123, 10))\n                .withResponseFormat(ResponseFormat.JSON)\n                .build();\n\n        // Use the settings as needed in your kernel setup or AI call\n    }\n}\n In this example: withModelId specifies the AI model to use for execution. withServiceId determines the AI service provider. withTemperature controls the randomness&mdash;a higher value means more randomness. withMaxTokens sets the maximum number of tokens in the output. withPresencePenalty and withFrequencyPenalty adjust how repetitive or varied the output should be. withStopSequences specifies sequences where generation should stop. withTokenSelectionBiases biases the selection of specific tokens. withResponseFormat chooses the format in which the response is returned (e.g., JSON). This setup allows fine-tuning of how text generation and model responses are managed when using the Semantic Kernel.","timestamp":1763300447939},"references/eClassifiers/JsonObjectResponseFormat/inheritance.html":{"path":"JsonObjectResponseFormat/Inheritance","link-uuid":"bdfc4adc-ea79-42ea-b432-bcf9a25f8552","title":"Inheritance","content":"Supertypes ","timestamp":1763300447534},"references/eClassifiers/PromptRenderingHook/inheritance.html":{"path":"PromptRenderingHook/Inheritance","link-uuid":"c6257e64-8044-4b65-a1d8-d33ae3705838","title":"Inheritance","content":"Supertypes ","timestamp":1763300448000},"references/eClassifiers/OutputVariable/index.html":{"link-uuid":"caa64e18-8be4-415d-bd0f-fa788226ce86","title":"OutputVariable","content":"The OutputVariable&lt;T&gt; class in the Microsoft Semantic Kernel Java package com.microsoft.semantickernel.semanticfunctions provides metadata for an output variable of a kernel function. This class is utilized to define the type and nature of the output that a semantic function is expected to return. Key Features: Generic Type Parameter &lt;T&gt;: This denotes the type of the return value of the function. Integration with KernelFunctionMetadata&lt;T&gt;: The OutputVariable&lt;T&gt; is often used in conjunction with the KernelFunctionMetadata&lt;T&gt; to specify the return type of a kernel function. Example Constructor: The class typically integrates as part of the function metadata to specify the expected output type of the kernel function. Example Usage: // Importing required classes from the package.\nimport com.microsoft.semantickernel.semanticfunctions.InputVariable;\nimport com.microsoft.semantickernel.semanticfunctions.KernelFunctionMetadata;\nimport com.microsoft.semantickernel.semanticfunctions.OutputVariable;\nimport java.util.List;\n\n// Example to create function metadata with output variable type.\nOutputVariable&lt;String&gt; returnVar = new OutputVariable&lt;&gt;();\nKernelFunctionMetadata&lt;String&gt; functionMetadata = new KernelFunctionMetadata&lt;&gt;(\n    &quot;examplePlugin&quot;,  // Plugin name\n    &quot;exampleFunction&quot;, // Function name\n    &quot;This function demonstrates an example&quot;, // Description\n    List.of(new InputVariable(&quot;inputExample&quot;)), // List of input parameters\n    returnVar // Output variable type\n);\n\n// Get output variable type\nOutputVariable&lt;String&gt; outputType = functionMetadata.getOutputVariableType();\n Method Summary: Constructor: Typically used within a metadata constructor to specify the return type of the function. Usage in Metadata: Helps in defining metadata about a kernel function, particularly the return data type. This class is essential in ensuring that the outputs of AI functions are correctly typed and managed within the broader context of semantic function management. Diagram ","timestamp":1763300447759},"references/eClassifiers/JsonSchemaResponseFormat/references/eStructuralFeatures/type/index.html":{"path":"JsonSchemaResponseFormat/References/type","link-uuid":"aee12d52-e9c0-4ebf-8655-e4c436368b23","title":"type","content":"Type EClassifier Multiplicity 0..1 In Microsoft Semantic Kernel Java, the JsonSchemaResponseFormat type relates to defining response formats using JSON schemas. This class is part of the com.microsoft.semantickernel.orchestration.responseformat package. JsonSchemaResponseFormat.Builder Class The JsonSchemaResponseFormat.Builder is a builder class for creating instances of JsonSchemaResponseFormat. It provides a variety of methods to set up different aspects of the JSON schema response format. Here are some of the key methods provided by the builder: setJsonResponseSchema(JsonResponseSchema jsonResponseSchema): Sets the JSON response schema. setJsonSchema(String jsonSchema): Sets a custom JSON schema as a string. setName(String name): Specifies the name for the JSON schema. setResponseFormat(Class&lt;?&gt; clazz): Sets the response format using a class type. setResponseFormat(Class&lt;?&gt; clazz, ResponseSchemaGenerator responseSchemaGenerator): Sets the response format with a specific response schema generator. setStrict(boolean strict): Defines whether the schema is strict. Here&rsquo;s an example of how you might configure a JsonSchemaResponseFormat using the builder in Java: import com.microsoft.semantickernel.orchestration.responseformat.JsonSchemaResponseFormat;\nimport com.microsoft.semantickernel.orchestration.responseformat.JsonResponseSchema;\n\npublic class Example {\n    public static void main(String[] args) {\n        JsonResponseSchema mySchema = new JsonResponseSchema(); // Assume this is implemented correctly\n        \n        JsonSchemaResponseFormat responseFormat = new JsonSchemaResponseFormat.Builder()\n            .setJsonResponseSchema(mySchema)\n            .setJsonSchema(&quot;{ \\&quot;type\\&quot;: \\&quot;object\\&quot;, \\&quot;properties\\&quot;: { \\&quot;name\\&quot;: {\\&quot;type\\&quot;: \\&quot;string\\&quot;} } }&quot;)\n            .setName(&quot;MyResponseFormat&quot;)\n            .setStrict(true)\n            .build();\n        \n        // Use the responseFormat as needed\n    }\n}\n In this example, a JsonSchemaResponseFormat is constructed with specific schema details and strict enforcement, using JSON schema definitions to dictate the structure and requirements of the response data. This allows seamless interaction with the Semantic Kernel by imposing structure and rules defined by the developer.","timestamp":1763300447567},"references/eClassifiers/InvocationReturnMode/index.html":{"link-uuid":"07d104c0-3240-4ce4-bf86-c6d9b2d17405","title":"InvocationReturnMode","content":"InvocationReturnMode Enum The InvocationReturnMode is an enumeration in the com.microsoft.semantickernel.orchestration package, which defines the mode in which a function invocation should return its results. This enum is part of the Microsoft Semantic Kernel Java library (semantickernel-api:1.4.0). Fields FULL_HISTORY Returns the full history of messages for function invocations that build upon a history of previous invocations, such as in Chat Completions. LAST_MESSAGE_ONLY Returns only the last message generated by the given invocation for functions that build upon a history of previous invocations. NEW_MESSAGES_ONLY (Default) Returns only the new messages generated by the given invocation for functions that build upon a history of previous invocations. Usage Example Here&rsquo;s how you might use the InvocationReturnMode enum in a Java context: import com.microsoft.semantickernel.orchestration.InvocationReturnMode;\nimport com.microsoft.semantickernel.orchestration.InvocationContext;\n\n// Example: Creating an InvocationContext with a specific InvocationReturnMode\nInvocationContext invocationContext = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.FULL_HISTORY)\n    .build();\n In this example, an InvocationContext is being built with the return mode set to FULL_HISTORY, suggesting that the full conversational history will be retained for the given function invocation. Similarly, you can set it to LAST_MESSAGE_ONLY or NEW_MESSAGES_ONLY according to your needs.","timestamp":1763300447509},"references/eClassifiers/Kernel/references/eStructuralFeatures/hooks/index.html":{"path":"Kernel/References/hooks","link-uuid":"98dc30b2-f893-4d5a-87e2-68b9e5cb9331","title":"hooks","content":"Type HookEntry Multiplicity 0..* In Microsoft Semantic Kernel Java, the KernelHooks class is a powerful utility designed to allow developers to intercept and modify events within the kernel. This provides an opportunity to inject custom logic and influence how the kernel operates at key points during its execution. Key Components: KernelHooks Class: This class is a collection of hooks that can be used for various events in the kernel&rsquo;s operation. It allows developers to add, execute, and manage hooks seamlessly. Hook Events: Various events can be intercepted using hooks such as before and after function invocation, prompt rendering, chat completions, and more. Usage of KernelHooks Adding Hooks Developers can create hooks to intercept specific events such as before a function is invoked or after a prompt is rendered. Below is a basic Java example demonstrating the addition of a hook to the kernel: import com.microsoft.semantickernel.hooks.KernelHooks;\nimport com.microsoft.semantickernel.hooks.FunctionInvokingEvent;\nimport java.util.function.Function;\n\n// Create a new KernelHooks instance\nKernelHooks kernelHooks = new KernelHooks();\n\n// Define a function invoking hook\nFunction&lt;FunctionInvokingEvent&lt;?&gt;, FunctionInvokingEvent&lt;?&gt;&gt; functionInvokingHook =\n    event -&gt; {\n        // Custom logic here\n        System.out.println(&quot;Function is being invoked: &quot; + event.toString());\n        return event;\n    };\n\n// Add the hook to the KernelHooks instance\nkernelHooks.addFunctionInvokingHook(functionInvokingHook);\n Executing Hooks Once hooks are added, they can be executed to perform the defined logic during the specific event phases. The executeHooks method is used for running the hooks associated with an event. // Example event\nFunctionInvokingEvent&lt;?&gt; invokingEvent = new FunctionInvokingEvent&lt;&gt;();\n\n// Execute hooks for the event\nkernelHooks.executeHooks(invokingEvent);\n Available Events and Hooks Function Hooks: FunctionInvokingHook: Executed before a function is called. FunctionInvokedHook: Executed after a function is called. Chat Completion Hooks: PreChatCompletionHook: Triggered before the chat completion process. PostChatCompletionHook: Triggered after the chat completion process. Prompt Hooks: PromptRenderingHook: Triggered during the rendering process of a prompt. PromptRenderedHook: Triggered after a prompt has been rendered. Additional Operations Merging Hooks: Hooks from multiple KernelHooks instances can be merged using the merge method to create a composite of hooks from two different contexts. Removing Hooks: Hooks can also be removed if they are no longer needed. // Remove a hook by its name\nkernelHooks.removeHook(&quot;hookName&quot;);\n Conclusion The KernelHooks in the Semantic Kernel Java library make it possible to extend and customize the functionality of the kernel significantly. These hooks allow seamless integration of additional logic, making it a flexible tool for developers working with AI models in Java applications. For more detailed implementation and event-specific hooks, refer to the official Semantic Kernel documentation for Java.","timestamp":1763300447608},"references/eClassifiers/InvocationContext/references/eStructuralFeatures/invocationReturnModel/index.html":{"path":"InvocationContext/Attributes/invocationReturnModel","link-uuid":"b432a410-b196-48fa-8ee9-2d11f469b7f5","title":"invocationReturnModel","content":"Type InvocationReturnMode Multiplicity 0..1 The InvocationContext class in Microsoft Semantic Kernel for Java handles the context passed to a Kernel or KernelFunction invocation. Among its various properties, the invocationReturnMode property specifies how the invocation&rsquo;s return should be handled. This property comes into play when executing function calls or prompts to determine the nature of the response. InvocationReturnMode InvocationReturnMode is an enumeration that dictates the response mode for a function or prompt invocation. It controls how the results are communicated back to the calling process. The typical modes can include options like returning only new messages or returning all messages. Usage in Code Here is a code snippet demonstrating how to set the invocationReturnMode using the builder pattern in InvocationContext.Builder: import com.microsoft.semantickernel.orchestration.InvocationContext;\nimport com.microsoft.semantickernel.orchestration.InvocationReturnMode;\n\npublic class InvocationContextExample {\n    public static void main(String[] args) {\n        // Create a builder for InvocationContext\n        InvocationContext.Builder contextBuilder = InvocationContext.builder();\n        \n        // Set the invocation return mode\n        contextBuilder.withReturnMode(InvocationReturnMode.NEW_MESSAGES_ONLY);\n        \n        // Build the InvocationContext\n        InvocationContext context = contextBuilder.build();\n        \n        // The InvocationContext is now configured to return only new messages\n    }\n}\n Key Points InvocationContext: Holds contextual information for kernel or kernel function invocations. InvocationReturnMode: An enum that determines how the returned results from a function or prompt invocation should be handled. Builder Pattern: The InvocationContext.Builder is used to construct an InvocationContext with the desired settings, including invocationReturnMode. This setup allows developers to configure the return behavior of function calls and tailor the response handling to the needs of their application context.","timestamp":1763300447498},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/tokenSelectionBiases/index.html":{"path":"PromptExecutionSettings/References/tokenSelectionBiases","link-uuid":"638811ec-2dda-4442-b0e6-dc6c112b745c","title":"tokenSelectionBiases","content":"Type TokenSelectionBiasesEntry Multiplicity 0..* The tokenSelectionBiases property in the PromptExecutionSettings class of Microsoft Semantic Kernel Java is used to influence which tokens the AI model is more or less likely to use during prompt execution. This is achieved by applying biases to token selection: Type: Map&lt;Integer, Integer&gt; Purpose: To assign biases to specific tokens identified by their ID from the tokenizer. A negative bias decreases the likelihood of the model using the associated token, while a positive bias increases it. Below is an example of how you might configure the tokenSelectionBiases using the PromptExecutionSettings.Builder in Java: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class Example {\n    public static void main(String[] args) {\n        Map&lt;Integer, Integer&gt; tokenBiases = new HashMap&lt;&gt;();\n        tokenBiases.put(12345, -50); // Less likely to use token with ID 12345\n        tokenBiases.put(67890, 25); // More likely to use token with ID 67890\n\n        PromptExecutionSettings settings = PromptExecutionSettings.builder()\n            .withTokenSelectionBiases(tokenBiases)\n            .build();\n\n        // Use settings in your prompt execution pipeline\n    }\n}\n In this example, the tokenSelectionBiases map is configured to make the AI less likely to use a token with ID 12345 and more likely to use a token with ID 67890. These biases assist in refining the output based on specific criteria such as discouraging or encouraging the use of certain tokens during the response generation.","timestamp":1763300447909},"references/eClassifiers/PostChatCompletionHook/inheritance.html":{"path":"PostChatCompletionHook/Inheritance","link-uuid":"f171e4a9-3286-4b2e-8462-266e762d0d66","title":"Inheritance","content":"Supertypes ","timestamp":1763300447810},"references/eClassifiers/TextAIService/index.html":{"link-uuid":"829c8000-b5a6-4462-adc2-7b1b6959c2c8","title":"TextAIService","content":"TextAIService in Microsoft Semantic Kernel Java TextAIService in Microsoft Semantic Kernel provides text processing capabilities in Java applications, specifically for tasks like text completion and text generation. In Semantic Kernel, you work with a composable, modular architecture that allows for easy integration and swapping of AI models and services based upon your requirements. Key Interfaces and Classes TextGenerationService: This interface is utilized within the com.microsoft.semantickernel.services.textcompletion package to define methods for text generation services. TextGenerationService.Builder: A builder class used to construct instances of TextGenerationService. TextContent: Represents the output produced by a text completion service. Java Code Example Here is a simplified example illustrating how you might set up a text generation service using Semantic Kernel in Java: import com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.services.textcompletion.TextGenerationService;\nimport com.microsoft.semantickernel.services.textcompletion.TextContent;\n\npublic class TextGenerationExample {\n    public static void main(String[] args) {\n        // Create a TextGenerationService instance\n        TextGenerationService textService = new TextGenerationService.Builder()\n            .withModelId(&quot;your-model-id&quot;)\n            .withEndpoint(&quot;your-service-endpoint&quot;)\n            .withApiKey(&quot;your-api-key&quot;)\n            .build();\n\n        // Use the text service to generate text\n        TextContent result = textService.generateText(&quot;Complete the following sentence: Once upon a time&quot;);\n\n        // Print the result\n        System.out.println(&quot;Generated Text: &quot; + result.getContent());\n    }\n}\n Key Steps and Considerations Model Configuration: You must specify model specifics such as modelId, endpoint, and apiKey. These are typically provided by the AI model provider, such as OpenAI. Text Generation: Utilize the instantiated TextGenerationService for generating or completing text strings, sending prompts as input and receiving the AI-generated content. Handle Responses: Use the TextContent class to access and process the response from the text generation service. Using Microsoft Semantic Kernel&rsquo;s Java SDK, developers can streamline the integration of advanced AI text generation capabilities into Java applications, leveraging pre-trained models and minimal boilerplate code to facilitate sophisticated interactions. Diagram ","timestamp":1763300448151},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/stopSequences/index.html":{"path":"PromptExecutionSettings/Attributes/stopSequences","link-uuid":"7b19371f-62e1-4246-8bf3-5f6250c7102d","title":"stopSequences","content":"Type EString Multiplicity 0..* PromptExecutionSettings stopSequences Property In the context of the Microsoft Semantic Kernel Java API, the stopSequences property within the PromptExecutionSettings class is used to determine the sequences at which the language model should stop generating text output during prompt execution. This is helpful for controlling the content and ensuring that the generation halts after encountering specific sequences. Key Information Type: List&lt;String&gt; Purpose: Specifies the stop sequences that will trigger the model to stop generating text when encountered. Usage: Can be set using a builder or directly when creating an instance of PromptExecutionSettings. How to Use stopSequences in Java You can set this property while using the builder for PromptExecutionSettings, or when constructing an instance directly: import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\nimport java.util.List;\nimport java.util.Arrays;\n\n// Using the builder to set stop sequences\nPromptExecutionSettings settings = PromptExecutionSettings.builder()\n    .withStopSequences(Arrays.asList(&quot;STOP&quot;, &quot;END&quot;))\n    .build();\n\n// Accessing the stop sequences\nList&lt;String&gt; stopSequences = settings.getStopSequences();\nSystem.out.println(&quot;Stop Sequences: &quot; + stopSequences);\n In this example: 1. A list of stop sequences is defined using Arrays.asList(&quot;STOP&quot;, &quot;END&quot;). 2. This list is passed to the withStopSequences method of the PromptExecutionSettings.Builder. 3. The build() method creates an instance of PromptExecutionSettings with the specified stop sequences. 4. The stop sequences are then retrieved using the getStopSequences() method.","timestamp":1763300447904},"references/eClassifiers/JsonObjectResponseFormat/index.html":{"link-uuid":"8ff33e8a-def8-4443-890f-f44ea1ed211b","title":"JsonObjectResponseFormat","content":"The JsonObjectResponseFormat class is part of the com.microsoft.semantickernel.orchestration.responseformat package. It represents a response formatted in JSON, and is used within the Microsoft Semantic Kernel Java API. This class extends the base ResponseFormat class and is useful for handling responses that need to be serialized or deserialized in JSON format. Class Definition package com.microsoft.semantickernel.orchestration.responseformat;\n\npublic class JsonObjectResponseFormat extends ResponseFormat {\n    // Used by Jackson deserialization to create a new instance of the JsonObjectResponseFormat class\n    public JsonObjectResponseFormat() {\n        super();\n    }\n}\n Key Points Purpose: The class is used to handle response data in JSON format, making it suitable for applications that exchange data in this structured format. Constructor: The default constructor of JsonObjectResponseFormat is used by the Jackson library during deserialization to instantiate the class. Inheritance: It inherits methods from the ResponseFormat base class, providing functionalities common to different response formats. These might include methods for determining the type of response format being used, among others. This class aids in the serialization and deserialization of responses in JSON format, making it a useful component in AI service orchestration where communication between components or with external services may involve JSON data. Here&rsquo;s how you might use the JsonObjectResponseFormat: // Example usage of JsonObjectResponseFormat\nJsonObjectResponseFormat jsonResponseFormat = new JsonObjectResponseFormat();\n\n// Since this is primarily about structuring a response, this would likely\n// be used in conjunction with other components that process and output data.\n Diagram ","timestamp":1763300447532},"references/eClassifiers/AIService/references/eStructuralFeatures/model/index.html":{"path":"AIService/Attributes/model","link-uuid":"15cfabdc-9cf4-4d8e-8cfc-41435ddcdf95","title":"model","content":"Type EString Multiplicity 0..1 In Microsoft Semantic Kernel for Java, the AIService model is a key component allowing integration of AI capabilities into your application. The AI services, such as chat completion, can be added to a Semantic Kernel through these AIService models. Java Code Snippet for AIService Integration The AIService model is primarily used to configure and use different AI capabilities within your Semantic Kernel setup. Here&rsquo;s a general outline of how you might integrate an AI service like Chat Completion in Java: import com.azure.ai.openai.OpenAIAsyncClient;\nimport com.azure.ai.openai.models.ChatCompletion;\nimport com.azure.identity.DefaultAzureCredentialBuilder;\nimport com.microsoft.semantickernel.ChatCompletionAgent;\nimport com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.model.FunctionChoiceBehavior;\n\n// Create an instance of OpenAIAsyncClient\nOpenAIAsyncClient openAIClient = new OpenAIAsyncClientBuilder()\n        .endpoint(&quot;&lt;your-openai-endpoint&gt;&quot;)\n        .credential(new DefaultAzureCredentialBuilder().build())\n        .buildAsyncClient();\n\n// Create ChatCompletion service\nChatCompletion chatCompletion = new ChatCompletion.Builder()\n        .client(openAIClient)\n        .modelId(&quot;&lt;model-id&gt;&quot;)\n        .build();\n\n// Add the ChatCompletion service to the Kernel\nKernel kernel = Kernel.builder()\n        .withAIService(ChatCompletion.class, chatCompletion)\n        .build();\n\n// Create a ChatCompletionAgent using the Kernel\nChatCompletionAgent chatAgent = ChatCompletionAgent.builder()\n        .withKernel(kernel)\n        .withName(&quot;ChatAgent&quot;)\n        .withInvocationContext(FunctionChoiceBehavior.auto(true))\n        .build();\n Key Properties and Configuration OpenAIAsyncClient: This client is used to interact with OpenAI&rsquo;s API, configured with an endpoint and Azure credentials. ChatCompletion: This AI service is added to handle chat-based capabilities using the specified model. Kernel: Acts as the container managing the AI services and other plugins. ChatCompletionAgent: An agent configured to use the chat service capabilities, allowing for interactive AI-driven processes. This setup is part of a broader agentic architecture in Java applications using Microsoft Semantic Kernel, facilitating AI integration for tasks like AI-driven chatbots, task management, or any other interactive capabilities you want to build into your applications. Remember to replace placeholders like &lt;your-openai-endpoint&gt; and &lt;model-id&gt; with actual values specific to your Azure OpenAI configurations.","timestamp":1763300447068},"references/eClassifiers/JsonSchemaResponseFormat/references/eStructuralFeatures/jsonSchemaRef/index.html":{"path":"JsonSchemaResponseFormat/Attributes/jsonSchemaRef","link-uuid":"de86e15f-3b17-4df5-8a81-efa65eb0bdab","title":"jsonSchemaRef","content":"Type EString Multiplicity 0..1 The JsonSchemaResponseFormat class in the Microsoft Semantic Kernel Java library is used to represent responses in a JSON schema format. It uses a builder pattern for configuration. Below is an explanation of the jsonSchemaRef property and related configuration methods: JsonSchemaResponseFormat Builder The JsonSchemaResponseFormat.Builder class allows you to configure a JsonSchemaResponseFormat with a specified JSON schema. It provides various methods to set different properties, including the JSON schema reference (jsonSchemaRef), which is essentially a reference to the JSON schema being used. Example of Setting JSON Schema with Builder Here&rsquo;s how you can use the builder to set the JSON schema with a reference: JsonSchemaResponseFormat.Builder builder = new JsonSchemaResponseFormat.Builder();\n\n// Set the JSON schema using a schema reference.\nbuilder.setJsonSchema(&quot;{ \\&quot;$ref\\&quot;: \\&quot;https://example.com/schema.json\\&quot; }&quot;);\n\n// Optionally, set additional properties like name, response format, strict mode, etc.\nbuilder.setName(&quot;ExampleSchema&quot;)\n       .setStrict(true);\n\n// Build the JsonSchemaResponseFormat instance\nJsonSchemaResponseFormat jsonSchemaResponseFormat = builder.build();\n Key Methods: setJsonSchema(String jsonSchema): Sets the JSON schema for the response format using a JSON string. This can include a reference to an external schema. setName(String name): Sets the name of the JSON schema format. setStrict(boolean strict): Sets whether the schema is strict, which can enforce validation rules strictly according to the schema. Usage This format is useful when you need to validate responses against a predefined schema, ensuring consistency and compliance with expected data structures. The jsonSchemaRef within the setJsonSchema method allows you to use an externally defined schema by referencing it. Summary The JsonSchemaResponseFormat class provides a structured and flexible way to handle responses in JSON format using schema validation. The builder pattern allows for clear and customizable configuration, including referencing external schemas using the jsonSchemaRef.","timestamp":1763300447564},"references/eClassifiers/OutputVariable/references/eStructuralFeatures/type/index.html":{"path":"OutputVariable/Attributes/type","link-uuid":"ed5e9263-00d5-4ab1-8bba-8cfbefe89dec","title":"type","content":"Type EString Multiplicity 0..1 The OutputVariable class in the context of Microsoft Semantic Kernel is primarily used to represent an output variable that is returned from a prompt function. The main components of this class, based on the information provided, include: Class Definition Namespace: Microsoft.SemanticKernel Assembly: Microsoft.SemanticKernel.Abstractions.dll Class: OutputVariable Key Properties Description Property: Purpose: This property gets or sets a description for the output variable. Type: String Usage: Allows you to provide a human-readable description of what this output variable represents, which can be useful for documentation or generating semantic information for AI agents. Here is how this might be used in related C# code (note: Java equivalent would be hypothetical as specific Java-based code for OutputVariable wasn&rsquo;t described): // C# Example\nvar outputVariable = new OutputVariable();\noutputVariable.Description = &quot;This contains the result of the AI function execution.&quot;;\n Hypothetical Conversion to Java (since Java-specific code for OutputVariable isn&rsquo;t directly provided): While there is no direct Java code snippet provided in the documentation for the OutputVariable class, a Java-like pseudo-implementation might look something like this (please note, this is a creative attempt to imagine what such a class could look like in Java): public class OutputVariable {\n    private String description;\n\n    public OutputVariable() {\n    }\n\n    public String getDescription() {\n        return description;\n    }\n\n    public void setDescription(String description) {\n        this.description = description;\n    }\n}\n\n// Example Usage\nOutputVariable outputVariable = new OutputVariable();\noutputVariable.setDescription(&quot;This contains the result of the AI function execution.&quot;);\n Applicability This Description property, defined with a JSON property name attribute, is important for providing context about the variable to both developers and AI models consuming this output. The function and usability specifics might differ based on the actual implementation details in the Semantic Kernel SDK environment.","timestamp":1763300447766},"references/eClassifiers/PreToolCallHook/index.html":{"link-uuid":"7dfbf45f-d2c3-40d6-af5c-f5d3ae5efa7b","title":"PreToolCallHook","content":"PreToolCallHook in Microsoft Semantic Kernel Java The PreToolCallHook is an interface in Microsoft Semantic Kernel&rsquo;s Java library that allows developers to intercept and modify events before a tool call is invoked in the kernel. This is part of the com.microsoft.semantickernel.hooks package, which provides tools to handle various events within the kernel operations. Definition package com.microsoft.semantickernel.hooks;\n\n/**\n * Interface for intercepting events before a tool call is executed.\n */\npublic interface KernelHook.PreToolCallHook \n    extends KernelHook&lt;PreToolCallEvent&gt; {\n    // method details \n}\n Purpose It acts as a hook to customize the behavior or data of the tool call before it gets invoked, offering developers a chance to modify arguments, log information, or execute additional logic. Example Usage When you implement a PreToolCallHook, you define how the event should be handled. Below is a simplified example demonstrating how you might log information before a tool call: import com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.PreToolCallEvent;\n\npublic class LoggingPreToolCallHook implements KernelHook.PreToolCallHook {\n\n    @Override\n    public void handle(PreToolCallEvent event) {\n        // Log details of the tool call\n        System.out.println(&quot;Before invoking tool: &quot; + event.getToolName());\n        System.out.println(&quot;With arguments: &quot; + event.getArguments());\n        \n        // Modify arguments if necessary\n        // event.setArguments(modifiedArguments);\n    }\n}\n\n// Usage\nKernelHooks hooks = new KernelHooks();\nhooks.addPreToolCallHook(new LoggingPreToolCallHook());\n Integration Once implemented, this hook can be registered with the kernel&rsquo;s hooks collection, as shown above, using the addPreToolCallHook method. This setup ensures that the defined logic in handle will be executed before every eligible tool call in the kernel&rsquo;s lifecycle. Summary The PreToolCallHook is a powerful feature of the Semantic Kernel in Java that allows for the customization and extension of tool call behavior, suited for tasks such as logging, argument modification, and more. By using this hook, developers can effectively manage and observe the flow of operations in applications leveraging Semantic Kernel. Diagram ","timestamp":1763300447851},"references/eClassifiers/HookEntry/index.html":{"link-uuid":"d65fd73d-0772-4b71-b255-8a87760544f2","title":"HookEntry","content":"The HookEntry is not explicitly defined in the Microsoft Semantic Kernel Java documentation provided. Based on the available information, it&rsquo;s possible it could be a concept related to the KernelHooks class or intended to be an individual entry within a collection of hooks. However, without explicit reference to HookEntry, we can discuss KernelHooks, a class that represents a collection of hooks that can be used to intercept and modify events in the kernel. KernelHooks Overview The KernelHooks class is part of the com.microsoft.semantickernel.hooks package and provides functionality to manage a collection of hooks that can be used to intercept and modify events within the Semantic Kernel. These hooks can be added, executed, or removed from the collection. Methods of Interest in KernelHooks addHook Adds a KernelHook to the collection. KernelHooks kernelHooks = new KernelHooks();\nKernelHook&lt;String&gt; myHook = (event) -&gt; {\n    // logic to handle the event\n    return event;\n};\n\nkernelHooks.addHook(&quot;myHookName&quot;, myHook);\n executeHooks Executes the hooks in the collection that accept the event. String event = &quot;SomeEvent&quot;;\nString result = kernelHooks.executeHooks(event);\n removeHook Removes a specific hook from the collection by name. KernelHook&lt;?&gt; removedHook = kernelHooks.removeHook(&quot;myHookName&quot;);\n Explanation KernelHooks Class: This class manages events by allowing hooks to be added, executed, or removed. Each hook can intercept and potentially modify the arguments to kernel functions. KernelHook Interface: Represents hooks that can be used to intercept and modify arguments to KernelFunctions. Example Here&rsquo;s how you might define and use hooks within a Semantic Kernel Java application: import com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.KernelHooks;\n\npublic class KernelHooksExample {\n    public static void main(String[] args) {\n        KernelHooks kernelHooks = new KernelHooks();\n\n        // Define a simple hook that prints the event\n        KernelHook&lt;String&gt; printHook = (event) -&gt; {\n            System.out.println(&quot;Hook executed with event: &quot; + event);\n            return event;\n        };\n\n        // Add the hook to the collection\n        kernelHooks.addHook(&quot;printHook&quot;, printHook);\n\n        // Execute hooks with a sample event\n        String sampleEvent = &quot;SampleEvent&quot;;\n        kernelHooks.executeHooks(sampleEvent);\n\n        // Remove the hook\n        kernelHooks.removeHook(&quot;printHook&quot;);\n    }\n}\n This code showcases how you can define, add, execute, and remove hooks within the Semantic Kernel framework using Java. If HookEntry is indeed a distinct concept from KernelHooks, additional context from the Semantic Kernel documentation would be required to provide accurate and detailed information. However, based on the documentation provided, KernelHooks is the primary class related to hook management in the Semantic Kernel Java package. Diagram ","timestamp":1763300447371},"references/eClassifiers/PromptExecutionSettingsEntry/references/eStructuralFeatures/key/index.html":{"path":"PromptExecutionSettingsEntry/Attributes/key","link-uuid":"e41697d5-4730-4996-8413-9e48f3a36ad3","title":"key","content":"Type EString Multiplicity 0..1 PromptExecutionSettings in Microsoft Semantic Kernel Java is a configuration class used to define settings for prompt execution in an AI context. It allows customization of various parameters that influence how AI models generate outputs. Here&rsquo;s a summary of the key properties in this class with accompanying Java code snippets for setting them via the PromptExecutionSettings.Builder class: Service ID (serviceId): Identifies the AI service to use for prompt execution. PromptExecutionSettings settings = new PromptExecutionSettings.Builder()\n    .withServiceId(&quot;yourServiceId&quot;)\n    .build();\n Model ID (modelId): Specifies the model ID for prompt execution. settings = new PromptExecutionSettings.Builder()\n    .withModelId(&quot;yourModelId&quot;)\n    .build();\n Temperature (temperature): Controls output randomness. Lower values make output more deterministic, higher values add more randomness. settings = new PromptExecutionSettings.Builder()\n    .withTemperature(0.7) // range: 0.0 to 2.0\n    .build();\n Top-P (topP): Influences the consideration of token predictions. A lower value restricts the choice to higher probability tokens. settings = new PromptExecutionSettings.Builder()\n    .withTopP(0.9) // range: 0.0 to 1.0\n    .build();\n Max Tokens (maxTokens): Limits the number of tokens generated in the output. settings = new PromptExecutionSettings.Builder()\n    .withMaxTokens(150)\n    .build();\n Presence Penalty (presencePenalty): Discourages the model from repeating the same tokens. settings = new PromptExecutionSettings.Builder()\n    .withPresencePenalty(0.5) // range: -2.0 to 2.0\n    .build();\n Frequency Penalty (frequencyPenalty): Reduces the likelihood of repeated tokens in the output. settings = new PromptExecutionSettings.Builder()\n    .withFrequencyPenalty(0.5) // range: -2.0 to 2.0\n    .build();\n Results Per Prompt (resultsPerPrompt): The number of results to generate for each input prompt. settings = new PromptExecutionSettings.Builder()\n    .withResultsPerPrompt(3)\n    .build();\n Stop Sequences (stopSequences): Specifies sequences where generation should stop. List&lt;String&gt; stopSequences = Arrays.asList(&quot;\\n&quot;, &quot;END&quot;);\nsettings = new PromptExecutionSettings.Builder()\n    .withStopSequences(stopSequences)\n    .build();\n Token Selection Biases (tokenSelectionBiases): Adjusts likelihoods for token selection during generation. Map&lt;Integer, Integer&gt; biases = new HashMap&lt;&gt;();\nbiases.put(1, -100); // Bias token 1 negatively\nsettings = new PromptExecutionSettings.Builder()\n    .withTokenSelectionBiases(biases)\n    .build();\n These properties enable fine-tuning of how AI models in Semantic Kernel generate responses, making them adaptable for various applications and requirements.","timestamp":1763300447936},"references/eClassifiers/PromptTemplateConfig/references/eStructuralFeatures/templateRef/index.html":{"path":"PromptTemplateConfig/Attributes/templateRef","link-uuid":"1f42a182-386e-420b-8544-aa0ad343417b","title":"templateRef","content":"Type EString Multiplicity 0..1 The PromptTemplateConfig class in Microsoft Semantic Kernel does not appear to have a property specifically named templateRef. However, within this class in the Semantic Kernel, there are properties like Template which is used to define the prompt template string itself, and TemplateFormat, which specifies the format of the prompt template. Below is a summary of these properties along with Java code snippets to provide examples of how they may be used: Properties: Template: The Template property is a string that defines the text of the prompt used within the Semantic Kernel. It is directly set with a prompt template string. PromptTemplateConfig templateConfig = new PromptTemplateConfig.Builder()\n    .withTemplate(&quot;Tell me a joke about {{$topic}}&quot;)\n    .build();\n TemplateFormat: The TemplateFormat property is used to declare the format of the template, which can be important for ensuring the correct interpretation and rendering of the template. Formats may include specific syntax expected by the template parser, such as Handlebars or Liquid. PromptTemplateConfig templateConfig = new PromptTemplateConfig.Builder()\n    .withTemplateFormat(&quot;handlebars&quot;)\n    .build();\n These properties are part of the configuration that defines how a semantic function&rsquo;s prompt will be constructed, potentially utilizing various templating languages or syntax for dynamic generation of AI inputs or responses. NO_INFORMATION about any templateRef property under PromptTemplateConfig for Microsoft Semantic Kernel Java.","timestamp":1763300448034},"references/eClassifiers/ResponseFormat/index.html":{"link-uuid":"335ae38c-4af9-47f6-8740-6303f8e85507","title":"ResponseFormat","content":"The ResponseFormat class in the Microsoft Semantic Kernel Java SDK serves as a base class for various response formats within the orchestration package. The class hierarchy allows for multiple ways of representing responses, enabling flexibility in how data is handled and processed. Class Structure Package: com.microsoft.semantickernel.orchestration.responseformat Maven Artifact: com.microsoft.semantic-kernel:semantickernel-api:1.4.0 ResponseFormat Class The ResponseFormat class is abstract and provides a foundation for specific response format implementations, allowing developers to extend and customize response processing. Constructor public ResponseFormat(ResponseFormat.Type type)\n Parameters: type: The type of response format, represented by an enumeration ResponseFormat.Type. Method public ResponseFormat.Type getType()\n Returns: The type of the response format. Subclasses Various subclasses extend ResponseFormat, each representing a specific way to handle response data, such as in JSON formats or plain text. These subclasses ensure that different data interchange formats can be seamlessly integrated into the orchestration workflows. Example Subclass: JsonObjectResponseFormat JsonObjectResponseFormat extends ResponseFormat to represent responses using a JSON object format. public class JsonObjectResponseFormat extends ResponseFormat {\n    public JsonObjectResponseFormat() {\n        super(ResponseFormat.Type.JSON_OBJECT);\n    }\n}\n Usage Example Here is a concise code example showing how you might instantiate a JsonObjectResponseFormat: ResponseFormat jsonResponseFormat = new JsonObjectResponseFormat();\nResponseFormat.Type type = jsonResponseFormat.getType();\nSystem.out.println(&quot;ResponseFormat Type: &quot; + type);\n In this snippet, JsonObjectResponseFormat is used to create a format type that processes responses as JSON objects. The type of response format is retrieved using the getType() method. This design allows developers to define additional custom behaviors by extending the ResponseFormat and its subclasses according to their particular requirements. Diagram ","timestamp":1763300448054},"references/eClassifiers/PromptTemplateConfig/references/eStructuralFeatures/templateFormat/index.html":{"path":"PromptTemplateConfig/Attributes/templateFormat","link-uuid":"cebdcb6b-357c-4b5b-84bd-ea52d6511def","title":"templateFormat","content":"Type EString Multiplicity 0..1 The PromptTemplateConfig class in Microsoft Semantic Kernel (Java) represents the configuration required to create a prompt template. One of its important properties is templateFormat, which determines the format of the prompt template. Here&rsquo;s a summary of the templateFormat property: PromptTemplateConfig.TemplateFormat Property Type: String Function: It specifies the format used for the prompt template. If not explicitly set, the default is SemanticKernelTemplateFormat. Usage: This property is crucial when defining the format that the prompt template should adhere to, ensuring consistency and proper rendering during invocation to AI services. Java Example In a Java implementation, you might typically use the PromptTemplateConfig.Builder to set the templateFormat as follows: import com.microsoft.semantickernel.semanticfunctions.PromptTemplateConfig;\n\n// Create a PromptTemplateConfig instance using the builder\nPromptTemplateConfig promptTemplateConfig = new PromptTemplateConfig.Builder()\n    .withTemplate(&quot;Tell a story about {{topic}} that is {{length}} sentences long.&quot;)\n    .withTemplateFormat(&quot;Handlebars&quot;) // Setting format, e.g., Handlebars for the template\n    .build();\n Here, the withTemplateFormat method is used to specify that the prompt template should use the &ldquo;Handlebars&rdquo; format. Different formats like Handlebars, Liquid, or custom-defined formats can be set according to the requirements of the AI service integration. By using the templateFormat, Semantic Kernel can correctly interpret the structure and variables of the prompt template during its execution.","timestamp":1763300448031},"references/eClassifiers/Invocable/inheritance.html":{"path":"Invocable/Inheritance","link-uuid":"c231fafb-b3fd-43e1-9b38-026521e8e16e","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447459},"references/eClassifiers/PreChatCompletionHook/inheritance.html":{"path":"PreChatCompletionHook/Inheritance","link-uuid":"0e151bad-fd0f-4ce8-8440-dba94089b334","title":"Inheritance","content":"Supertypes ","timestamp":1763300447832},"references/eClassifiers/ScriptedFunction/references/eStructuralFeatures/scriptRef/index.html":{"path":"ScriptedFunction/Attributes/scriptRef","link-uuid":"4acf87bd-081f-4e9f-b99c-372c81c189af","title":"scriptRef","content":"Type EString Multiplicity 0..1 The ScriptedFunction is an interface part of the Semantic Kernel Java SDK designed for handling scripted functions. The scriptRef property is one of the key attributes of this interface. It serves as a reference to the script that the function will execute. This scriptRef is a Path, representing the location of the script file to be utilized by the function. Here is a basic Java snippet that illustrates the concept of using scriptRef within the context of a ScriptedFunction: import java.nio.file.Path;\nimport java.nio.file.Paths;\n\npublic class Example {\n\n    public static void main(String[] args) {\n        // Example of setting the script reference for a ScriptedFunction\n        Path scriptPath = Paths.get(&quot;path/to/your/script.js&quot;);\n        \n        ScriptedFunction myFunction = new ScriptedFunction() {\n            @Override\n            public Path scriptRef() {\n                return scriptPath;\n            }\n        };\n\n        // Use the scriptRef\n        System.out.println(&quot;Script reference path: &quot; + myFunction.scriptRef());\n    }\n}\n In the snippet above: scriptRef is defined to return the Path to the script file that the function will be using. Paths.get(&quot;path/to/your/script.js&quot;) is used to create a Path object pointing to where the script is located. For more details on the ScriptedFunction and its properties, you would typically look into the com.microsoft.semantickernel package that encompasses the relevant classes and interfaces for managing kernel functions. However, please note that this example is hypothetical and relies on the expected behavior of typical scriptRef uses based on the package structure and common usage patterns within Java APIs. If ScriptedFunction is a specialized or newer addition, always consult the official Microsoft Semantic Kernel Java documentation for the most accurate details.","timestamp":1763300448093},"references/eClassifiers/AIServiceSelector/inheritance.html":{"path":"AIServiceSelector/Inheritance","link-uuid":"24731bea-da03-4596-8d34-05a144b63e34","title":"Inheritance","content":"Supertypes ","timestamp":1763300447099},"references/eClassifiers/ScriptedFunction/index.html":{"link-uuid":"92dce4ed-975b-4232-8a45-5fad88d99fb5","title":"ScriptedFunction","content":"ScriptedFunction is a component in Semantic Kernel&rsquo;s Java SDK that allows for the execution of code snippets as functions within the semantic kernel. While information specific to ScriptedFunction is not readily available, generally speaking, ScriptedFunctions can be used to execute dynamic or ad-hoc scripts within the semantic kernel, depending on its design. Below is a conceptual example in Java that demonstrates how functions might be dynamically added or invoked in a typical Semantic Kernel setup. Note that this is a generalized approach based on how SDKs typically handle dynamic script execution or function invocation: import com.microsoft.semantic.kernel.Kernel;\nimport com.microsoft.semantic.kernel.KernelPlugin;\nimport com.microsoft.semantic.kernel.KernelPluginFactory;\nimport com.microsoft.semantic.kernel.model.openapi.OpenAIAsyncClientBuilder;\nimport com.microsoft.semantic.kernel.model.openapi.ChatCompletionService;\nimport com.microsoft.semantic.kernel.model.openapi.chat.ChatHistory;\nimport com.microsoft.semantic.kernel.model.openapi.chat.InvocContext;\n\npublic class Example {\n    public static void main(String[] args) {\n        // Initialize a client to connect with OpenAI or similar service\n        OpenAIAsyncClient client = new OpenAIAsyncClientBuilder()\n            .credential(openAIClientCredentials)\n            .buildAsyncClient();\n\n        // Create a chat completion service\n        ChatCompletionService chatCompletionService = OpenAIChatCompletion.builder()\n            .withModelId(&quot;your_model_id&quot;)\n            .withOpenAIAsyncClient(client)\n            .build();\n\n        // Define the Scripted function\n        KernelPlugin scriptedFunctionPlugin = KernelPluginFactory.createFromObject(new Object() {\n            @DefineKernelFunction(name = &quot;scripted_echo&quot;, description = &quot;Echo a message&quot;)\n            public String echo(String message) {\n                return &quot;Echo: &quot; + message; // Simple scripted function\n            }\n        }, &quot;ScriptedFunctions&quot;);\n\n        // Build the kernel with the chat service and scripted function\n        Kernel kernel = Kernel.builder()\n            .withAIService(ChatCompletionService.class, chatCompletionService)\n            .withPlugin(scriptedFunctionPlugin)\n            .build();\n\n        // Create chat history and add a user message\n        ChatHistory chatHistory = new ChatHistory();\n        chatHistory.addUserMessage(&quot;Please echo this message&quot;);\n\n        // Configure how functions are selected\n        InvocContext invocationContext = new InvocContext.Builder()\n            .withToolCallBehavior(ToolCallBehavior.allowAllKernelFunctions(true))\n            .build();\n\n        // Invoke the chat completion service and handle the response\n        chatCompletionService.getChatMessageContentsAsync(\n            chatHistory, kernel, invocationContext\n        ).block()\n         .forEach(response -&gt; System.out.println(&quot;Assistant &gt; &quot; + response.getContent()));\n    }\n}\n This Java code snippet sets up a basic semantic kernel environment with an example function, scripted_echo, through KernelPlugin. The actual ScriptedFunction would typically allow for more dynamic, ad-hoc scripting capabilities within the kernel, which could be utilized to create functions dynamically at runtime, subject to supporting implementations in the SDK. Please adjust based on any specific capabilities of the ScriptedFunction if details on its implementation are available in your specific context. Note: If the Semantic Kernel SDK for Java includes specific constructs or APIs for scripting that are not covered here, refer to the official documentation or source code for precise guidance. Diagram ","timestamp":1763300448076},"references/eClassifiers/FunctionInvokedHook/index.html":{"link-uuid":"223d12c4-2316-45e3-b458-79f65747b85b","title":"FunctionInvokedHook","content":"The FunctionInvokedHook is an interface in the Microsoft Semantic Kernel Java SDK, which is used to define hooks that are executed after a function within the kernel has been invoked. It allows developers to intercept and modify the behavior or output of a function after it has been executed. Here is a summary and example usage in Java. Overview Package: com.microsoft.semantickernel.hooks Purpose: To offer a mechanism to execute custom logic after a kernel function invocation. Usage: Implement the FunctionInvokedHook interface to define what should happen after a function is invoked. Key Concepts Function Hook: A hook provides a point where custom code can be injected. The FunctionInvokedHook provides a post-execution hook. Function Invocation Event: The hook uses FunctionInvokedEvent&lt;T&gt;, which carries information about the function invocation, including any results produced by the function. Java Code Example Below is an example demonstrating how to implement and use a FunctionInvokedHook in Java with the Semantic Kernel: import com.microsoft.semantickernel.hooks.FunctionInvokedEvent;\nimport com.microsoft.semantickernel.hooks.KernelHooks;\nimport com.microsoft.semantickernel.hooks.KernelHook;\n\npublic class MyFunctionInvokedHook implements KernelHook.FunctionInvokedHook&lt;String&gt; {\n\n    @Override\n    public FunctionInvokedEvent&lt;String&gt; apply(FunctionInvokedEvent&lt;String&gt; event) {\n        // Custom logic after function invocation\n        System.out.println(&quot;Function invoked: &quot; + event.getFunctionName());\n        System.out.println(&quot;Output: &quot; + event.getResult());\n\n        // Return the event (unchanged or modified)\n        return event;\n    }\n\n    public static void main(String[] args) {\n        // Create a KernelHooks instance\n        KernelHooks kernelHooks = new KernelHooks();\n\n        // Add the custom FunctionInvokedHook\n        kernelHooks.addFunctionInvokedHook(new MyFunctionInvokedHook());\n\n        // Example usage with a kernel (kernel creation and usage would depend on your specific context)\n    }\n}\n Key Points Creation &amp; Registration: Implement the FunctionInvokedHook interface, define the desired logic in the apply method, and register the hook using KernelHooks.addFunctionInvokedHook(). Extensibility: By using hooks, you can extend or customize the behavior of function invocations within the Semantic Kernel, allowing for logging, monitoring, transformation of results, and more. This approach allows for the dynamic customization of how your AI models interact with the Semantic Kernel, facilitating better integration and more granular control over function invocations. Diagram ","timestamp":1763300447236},"references/eClassifiers/GeminiChatCompletion/inheritance.html":{"path":"GeminiChatCompletion/Inheritance","link-uuid":"30c58220-f483-4e6f-a751-bba432452b09","title":"Inheritance","content":"Supertypes ","timestamp":1763300447292},"references/eClassifiers/Plugin/index.html":{"link-uuid":"70ec0051-81ac-4ed7-a64b-d72ced2a9a21","title":"Plugin","content":"The Microsoft Semantic Kernel Java Plugin is a core component designed for use within the Semantic Kernel framework, allowing developers to encapsulate existing APIs as plugins. This enables AI models to understand and invoke these APIs, thereby extending their capabilities. Here&rsquo;s a summarized breakdown with Java code snippets highlighting how to create and use plugins within the Semantic Kernel Java environment. What is a Plugin? A plugin in Semantic Kernel represents a collection of functions that can be used by an AI to perform actions not natively supported by the AI itself. Functions within these plugins can be called by the AI using function calling, a feature in LLMs that allows them to invoke external functions. Anatomy of a Plugin A plugin generally includes: Functions: The core actions that the plugin will expose. Semantic Descriptions: Metadata describing what the functions do, which aids LLMs in understanding how to use them. Creating a Native Plugin To create a native plugin in Java, define a class and annotate its methods with DefineKernelFunction, specifying function names and descriptions. Here&rsquo;s an example plugin, LightsPlugin, which manipulates the state of lights: public class LightsPlugin {\n\n    // Mock data for the lights\n    private final Map&lt;Integer, LightModel&gt; lights = new HashMap&lt;&gt;();\n\n    public LightsPlugin() {\n        lights.put(1, new LightModel(1, &quot;Table Lamp&quot;, false));\n        lights.put(2, new LightModel(2, &quot;Porch light&quot;, false));\n        lights.put(3, new LightModel(3, &quot;Chandelier&quot;, true));\n    }\n\n    @DefineKernelFunction(name = &quot;get_lights&quot;, description = &quot;Gets a list of lights and their current state&quot;)\n    public List&lt;LightModel&gt; getLights() {\n        return new ArrayList&lt;&gt;(lights.values());\n    }\n\n    @DefineKernelFunction(name = &quot;change_state&quot;, description = &quot;Changes the state of the light&quot;)\n    public LightModel changeState(\n            @KernelFunctionParameter(name = &quot;id&quot;, description = &quot;The ID of the light to change&quot;) int id,\n            @KernelFunctionParameter(name = &quot;isOn&quot;, description = &quot;The new state of the light&quot;) boolean isOn) {\n        if (!lights.containsKey(id)) {\n            throw new IllegalArgumentException(&quot;Light not found&quot;);\n        }\n\n        lights.get(id).setIsOn(isOn);\n        return lights.get(id);\n    }\n}\n Adding the Plugin to a Kernel Once you have defined your plugin, it needs to be added to the kernel so it can be used by the AI. // Import the LightsPlugin\nKernelPlugin lightPlugin = KernelPluginFactory.createFromObject(new LightsPlugin(), &quot;LightsPlugin&quot;);\n\n// Create a kernel with Azure OpenAI chat completion and plugin\nKernel kernel = Kernel.builder()\n    .withAIService(ChatCompletionService.class, chatCompletionService)\n    .withPlugin(lightPlugin)\n    .build();\n Using the Plugin Functions After adding the plugin to the kernel, the functions can be invoked through the AI model. The AI will use the provided semantic descriptions to understand how to call the plugin functions. // Enable planning\nInvocationContext invocationContext = new InvocationContext.Builder()\n    .withReturnMode(InvocationReturnMode.LAST_MESSAGE_ONLY)\n    .withToolCallBehavior(ToolCallBehavior.allowAllKernelFunctions(true))\n    .build();\n\n// Create a history to store the conversation\nChatHistory history = new ChatHistory();\nhistory.addUserMessage(&quot;Turn on light 2&quot;);\n\nList&lt;ChatMessageContent&lt;?&gt;&gt; results = chatCompletionService\n    .getChatMessageContentsAsync(history, kernel, invocationContext)\n    .block();\n\n// Output the result from AI\nSystem.out.println(&quot;Assistant &gt; &quot; + results.get(0).getContent());\n General Recommendations Descriptive Names: Use clear and descriptive names for functions and parameters to help the AI understand their purpose. Minimize Parameters: Reduce the number of parameters to streamline function calls and avoid errors in parameter matching. Function Responsibilities: Balance the number of functions and their responsibilities to manage network overhead and token consumption efficiently. This setup allows Semantic Kernel to leverage plugins effectively, providing powerful extensibility for AI agents to perform a variety of complex tasks. Diagram ","timestamp":1763300447784},"references/eClassifiers/SemanticKernelTelemetry/references/eStructuralFeatures/tracer/index.html":{"path":"SemanticKernelTelemetry/Attributes/tracer","link-uuid":"ec1380b5-0181-440b-a5bf-4c9c5240659d","title":"tracer","content":"Type EString Multiplicity 0..1","timestamp":1763300448113},"references/eClassifiers/TokenSelectionBiasesEntry/references/eStructuralFeatures/value/index.html":{"path":"TokenSelectionBiasesEntry/Attributes/value","link-uuid":"a8ffd1de-45e0-4bcf-9ddc-859021a7ce08","title":"value","content":"Type EIntegerObject Multiplicity 0..1","timestamp":1763300448266},"references/eClassifiers/InputVariable/references/eStructuralFeatures/type/index.html":{"path":"InputVariable/Attributes/type","link-uuid":"4fb318f0-0f1d-4307-bdc2-8b6ce9698683","title":"type","content":"Type EString Multiplicity 0..1 Definition of InputVariable Properties in Semantic Kernel Java Input variables in Microsoft Semantic Kernel Java include several key properties, each with a specific role. Below are descriptions of the Description and Default properties commonly associated with input variables. Description Property The Description property provides metadata about the input variable. This helps the AI understand the purpose of the variable. It is often utilized in conjunction with annotations to semantically describe the variable to both human developers and AI models. import com.microsoft.semantickernel.prompttemplate.InputVariable;\n\npublic class ExampleInputVariable {\n    private InputVariable&lt;String&gt; messageVariable = new InputVariable&lt;&gt;(&quot;message&quot;, &quot;This is the message.&quot;);\n\n    public ExampleInputVariable() {\n        messageVariable.setDescription(&quot;A brief description of the user message.&quot;);\n    }\n}\n Default Property The Default property is used to set a fallback value for the variable. This is particularly useful when a variable is optional or when a default action or value is needed. import com.microsoft.semantickernel.prompttemplate.InputVariable;\n\npublic class ExampleInputVariable {\n    private InputVariable&lt;String&gt; messageVariable = new InputVariable&lt;&gt;(&quot;message&quot;, &quot;Enter your message here.&quot;);\n\n    public ExampleInputVariable() {\n        messageVariable.setDefault(&quot;Hello, world!&quot;);\n    }\n}\n In the above snippets, the InputVariable is used to define a message input with properties for description and default value. This provides the AI with necessary context about the variable leading to more accurate function invocations and responses.","timestamp":1763300447436},"references/eClassifiers/TextToAudioService/index.html":{"link-uuid":"58aecf7a-0679-4f14-a4d0-7bd8c646b5ea","title":"TextToAudioService","content":"Microsoft Semantic Kernel Java: TextToAudioService The TextToAudioService in Microsoft Semantic Kernel Java provides the capability to convert text to audio using OpenAI&rsquo;s text-to-audio services. OpenAiTextToAudioService The OpenAiTextToAudioService class is an implementation of the TextToAudioService interface, which utilizes OpenAI&rsquo;s text-to-audio capabilities. Constructor public OpenAiTextToAudioService(OpenAIAsyncClient client, String modelId, String deploymentName)\n Parameters: client: The OpenAI client used to access the service. modelId: The model identifier for text-to-audio conversion. deploymentName: The deployment name within OpenAI. Methods builder(): Creates a new builder for setting up an OpenAiTextToAudioService instance. OpenAiTextToAudioService.Builder builder = OpenAiTextToAudioService.builder();\n getAudioContentAsync(String text, TextToAudioExecutionSettings executionSettings): Converts text to audio content asynchronously. Parameters: text: The text to be converted into audio. executionSettings: Settings for how the text should be converted to audio. Mono&lt;AudioContent&gt; audioContentMono = openAiService.getAudioContentAsync(&quot;Hello, world!&quot;, new TextToAudioExecutionSettings());\n Example Usage OpenAIAsyncClient client = new OpenAIClientBuilder()\n    .credential(new AzureKeyCredential(&quot;your-api-key&quot;))\n    .endpoint(&quot;your-endpoint&quot;)\n    .buildAsyncClient();\n\nOpenAiTextToAudioService textToAudioService = new OpenAiTextToAudioService(client, &quot;modelId&quot;, &quot;deploymentName&quot;);\n\nTextToAudioExecutionSettings settings = new TextToAudioExecutionSettings();\n\nMono&lt;AudioContent&gt; audioContent = textToAudioService.getAudioContentAsync(&quot;Convert this text to audio&quot;, settings);\n This setup allows for leveraging OpenAI&rsquo;s service within the Java environment to transform text inputs into audio outputs, offering a seamless integration for applications requiring text-to-speech capabilities. Diagram ","timestamp":1763300448237},"references/eClassifiers/EmbeddingGenerationService/inheritance.html":{"path":"EmbeddingGenerationService/Inheritance","link-uuid":"5eac1987-29a0-4ed9-86d2-f70e5730928f","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447181},"references/eClassifiers/TextEmbeddingGenerationService/inheritance.html":{"path":"TextEmbeddingGenerationService/Inheritance","link-uuid":"6df06957-88f9-4c5e-a50b-b0a2817f7868","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448175},"references/eClassifiers/HookEntry/references/eStructuralFeatures/value/index.html":{"path":"HookEntry/References/value","link-uuid":"a19819ec-84e8-468a-9892-04460f6395fa","title":"value","content":"Type Hook Multiplicity 1 The HookEntry class in the context of Microsoft Semantic Kernel Java, particularly within the hooks package, represents an entry that can store a specific function or hook. Essentially, this class is designed to handle events and properties related to those events for modification and interception purposes. Each hook entry has various components, and in this case, the value property usually stores the function associated with that specific hook entry. Here&rsquo;s a conceptual snippet of how such a hook might be set up in Java using the Semantic Kernel API: import com.microsoft.semantickernel.hooks.*;\nimport java.util.function.Function;\n\npublic class MySemanticHooks {\n\n    public static void main(String[] args) {\n        // Create a new KernelHooks instance\n        KernelHooks kernelHooks = new KernelHooks();\n\n        // Define a function that will serve as a hook\n        Function&lt;FunctionInvokingEvent&lt;?&gt;, FunctionInvokingEvent&lt;?&gt;&gt; myFunctionInvokingHook = event -&gt; {\n            // Logic to be executed before a function is invoked\n            System.out.println(&quot;Function is about to be invoked: &quot; + event);\n            return event;\n        };\n\n        // Add the function as a hook entry\n        kernelHooks.addFunctionInvokingHook(myFunctionInvokingHook);\n\n        // Similarly, you can define other hooks\n        Function&lt;FunctionInvokedEvent&lt;?&gt;, FunctionInvokedEvent&lt;?&gt;&gt; myFunctionInvokedHook = event -&gt; {\n            // Logic after the function has been invoked\n            System.out.println(&quot;Function has been invoked: &quot; + event);\n            return event;\n        };\n\n        // Add to kernel hooks\n        kernelHooks.addFunctionInvokedHook(myFunctionInvokedHook);\n    }\n}\n Explanation KernelHooks: A class that manages multiple hooks to intercept and possibly modify kernel events. addFunctionInvokingHook: A method to add a hook that operates before a function is invoked. addFunctionInvokedHook: A method to add a hook that operates after a function is invoked. These methods help to customize the behavior of kernel functions by intercepting them at different stages of their execution lifecycle, such as before invocation and after invocation, allowing developers to inject custom logic into these stages. The value property typically refers to the function or method to be executed when the hook is triggered. The code snippet shows a basic setup of how to utilize hook entries with custom functions in a Java project using Semantic Kernel API.","timestamp":1763300447379},"references/eClassifiers/TextEmbeddingGenerationService/index.html":{"link-uuid":"b84b0ff3-7d8f-43a3-82e0-0b4808edfa37","title":"TextEmbeddingGenerationService","content":"The TextEmbeddingGenerationService interface in the Semantic Kernel Java SDK provides a means to generate text embeddings, which are vectors that represent the semantic meaning of text data. This interface supports creating embeddings that can be utilized for various applications like similarity comparison and retrieval-augmented tasks. Here&rsquo;s an overview and some examples of how you might use the TextEmbeddingGenerationService with Java: Package and Interfaces Package: com.microsoft.semantickernel.services.textembedding Interfaces: TextEmbeddingGenerationService&lt;TValue&gt;: This interface allows for generating embeddings from text data. Example Usage with OpenAITextEmbeddingGenerationService The OpenAITextEmbeddingGenerationService is a concrete implementation for generating embeddings using OpenAI models. import com.microsoft.semantickernel.aiservices.openai.textembedding.OpenAITextEmbeddingGenerationService;\nimport com.azure.ai.openai.OpenAIAsyncClient;\nimport reactor.core.publisher.Mono;\nimport java.util.List;\n\npublic class EmbeddingExample {\n    public static void main(String[] args) {\n        // Create an OpenAI client\n        OpenAIAsyncClient client = new OpenAIAsyncClientBuilder()\n                .apiKey(&quot;your-openai-api-key&quot;)\n                .buildAsyncClient();\n\n        // Create an instance of OpenAITextEmbeddingGenerationService\n        OpenAITextEmbeddingGenerationService embeddingService = new OpenAITextEmbeddingGenerationService(\n                client, // OpenAI client\n                &quot;deployment-name&quot;, // deployment name\n                &quot;model-id&quot;, // OpenAI model id\n                &quot;service-id&quot;, // service identifier\n                OpenAITextEmbeddingGenerationService.EMBEDDING_DIMENSIONS_LARGE // dimensions\n        );\n\n        // Generate an embedding for a single text data\n        Mono&lt;Embedding&gt; embeddingMono = embeddingService.generateEmbeddingAsync(&quot;This is a sample text.&quot;);\n        embeddingMono.subscribe(embedding -&gt; {\n            // Process or output the embedding\n            System.out.println(&quot;Generated embedding: &quot; + embedding);\n        });\n\n        // Generate embeddings for multiple text data\n        Mono&lt;List&lt;Embedding&gt;&gt; embeddingsMono = embeddingService.generateEmbeddingsAsync(\n                List.of(&quot;Sample text one.&quot;, &quot;Sample text two.&quot;));\n        embeddingsMono.subscribe(embeddings -&gt; {\n            // Process or output the embeddings\n            System.out.println(&quot;Generated embeddings: &quot; + embeddings);\n        });\n    }\n}\n Key Points: - The OpenAITextEmbeddingGenerationService can be utilized to generate embeddings asynchronously. - Embeddings can be generated for single or multiple pieces of data using the generateEmbeddingAsync and generateEmbeddingsAsync methods, respectively. - The generated embeddings can be used to compare the semantic similarity of different pieces of text. Diagram ","timestamp":1763300448173},"references/eClassifiers/PromptExecutionSettings/references/eStructuralFeatures/frequencyPenalty/index.html":{"path":"PromptExecutionSettings/Attributes/frequencyPenalty","link-uuid":"852d5abe-c234-4df6-b480-d203e7f26188","title":"frequencyPenalty","content":"Type EDoubleObject Multiplicity 0..1 PromptExecutionSettings Frequency Penalty in Semantic Kernel Java The frequencyPenalty property in the PromptExecutionSettings class of Microsoft Semantic Kernel Java is a configuration setting used during prompt execution. This parameter helps control the diversity of the language model outputs by discouraging the repetition of the same tokens in the generated text. Description Range: The frequencyPenalty value can be set in the range of [-2.0, 2.0]. Function: Positive values apply a penalty to tokens that appear frequently in the text generated so far, which reduces the likelihood of repeating those tokens. Lower values have less effect on repetition, while higher values strongly discourage it. Default Default Value: If not provided, the frequencyPenalty defaults to 0.0. Java Code Example import com.microsoft.semantickernel.orchestration.PromptExecutionSettings;\n\npublic class SemanticKernelExample {\n    public static void main(String[] args) {\n        // Create a PromptExecutionSettings.Builder instance\n        PromptExecutionSettings.Builder builder = new PromptExecutionSettings.Builder();\n        \n        // Set the frequencyPenalty for prompt execution\n        builder.withFrequencyPenalty(1.5); // Adjust the penalty between -2.0 and 2.0\n        \n        // Build the PromptExecutionSettings with the specified frequencyPenalty\n        PromptExecutionSettings settings = builder.build();\n        \n        // The frequency penalty is now set to 1.5 in the settings\n        System.out.println(&quot;Frequency Penalty: &quot; + settings.getFrequencyPenalty());\n    }\n}\n Key Takeaways Purpose: frequencyPenalty is used to control the tendency of the model to repeat tokens. Adjustment: Adjust it to affect how conservative or varied the output should be. This setting can be crucial when creating applications that require diverse and non-repetitive outputs, such as creative writing or dialogue generation tasks.","timestamp":1763300447887},"references/eClassifiers/PostChatCompletionHook/index.html":{"link-uuid":"8431cc16-4c98-45a4-8f3b-ff65447819eb","title":"PostChatCompletionHook","content":"In Microsoft Semantic Kernel Java, a PostChatCompletionHook is an interface that represents a hook used to intercept events after a chat completion is invoked. This interface allows for handling PostChatCompletionEvent instances, enabling developers to execute custom logic immediately following the execution of a chat completion operation. Here&rsquo;s a brief overview along with a Java code snippet demonstrating how to implement a PostChatCompletionHook: Implementation of PostChatCompletionHook To implement a PostChatCompletionHook, you would typically create a class that implements this interface and overrides its method to handle the post-completion event as required. import com.microsoft.semantickernel.hooks.KernelHook;\nimport com.microsoft.semantickernel.hooks.PostChatCompletionEvent;\n\n// Define a custom hook implementing the PostChatCompletionHook\npublic class CustomPostChatCompletionHook implements KernelHook.PostChatCompletionHook {\n\n    @Override\n    public void accept(PostChatCompletionEvent event) {\n        // Custom logic to handle after the chat completion\n        System.out.println(&quot;Chat completion finished with message: &quot; + event.getMessage());\n    }\n}\n\n// Register the hook with Semantic Kernel's KernelHooks system\nKernelHooks kernelHooks = new KernelHooks();\nkernelHooks.addPostChatCompletionHook(new CustomPostChatCompletionHook());\n Key Points Purpose: PostChatCompletionHook is utilized to perform specific actions following a chat operation&rsquo;s invocation. This can include logging results, processing output, or triggering further operations based on the completion. Integration: Hooks are integrated with Semantic Kernel&rsquo;s events system, allowing them to be automatically called when relevant events occur in the lifecycle of kernel operations. Use Case: Useful in scenarios where the outcome of a chat model needs to be processed or monitored for further actions or analysis. This setup provides a modular way to manage actions around critical points in the chat completion process, maintaining separation of concerns and enhancing the customizability of the kernel&rsquo;s behavior. Diagram ","timestamp":1763300447808},"references/eClassifiers/AudioToTextService/inheritance.html":{"path":"AudioToTextService/Inheritance","link-uuid":"c190a188-5ddd-4669-9080-6804d25e30ed","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300447126},"references/eClassifiers/OpenAITextEmbeddingGenerationService/index.html":{"link-uuid":"f68c5a87-d2f7-4651-a7ab-eb8c8afe84b4","title":"OpenAITextEmbeddingGenerationService","content":"The OpenAITextEmbeddingGenerationService class in Microsoft Semantic Kernel Java is an implementation used to generate text embeddings utilizing the OpenAI API. It is part of the com.microsoft.semantickernel.aiservices.openai.textembedding package. Overview This class provides methods to convert text into a vector of numbers (embedding) that captures the semantic meaning of the text. These embeddings can be used for various tasks such as similarity comparison, search, and clustering. Key Features Model Selection: You can specify different models such as text-embedding-3-large or text-embedding-3-small, each providing embeddings of different dimensionalities. Client Integration: Utilizes OpenAIAsyncClient for asynchronous operations. Service Abstraction: Implements the TextEmbeddingGenerationService interface. Java Code Snippets Here are usage examples of the OpenAITextEmbeddingGenerationService: Creating an Instance import com.azure.ai.openai.OpenAIAsyncClient;\nimport com.microsoft.semantickernel.aiservices.openai.textembedding.OpenAITextEmbeddingGenerationService;\n\n// Initialize OpenAI client (assuming the client is properly configured)\nOpenAIAsyncClient openAIClient = new OpenAIAsyncClient();\n\n// Create a service instance\nOpenAITextEmbeddingGenerationService embeddingService = new OpenAITextEmbeddingGenerationService(\n    openAIClient, \n    &quot;your-deployment-name&quot;, \n    &quot;your-model-id&quot;, \n    &quot;your-service-id&quot;, \n    1536 // dimensions for embedding\n);\n Generating Embeddings import reactor.core.publisher.Mono;\nimport com.microsoft.semantickernel.services.textembedding.Embedding;\n\n// For a single piece of text\nMono&lt;Embedding&gt; embeddingMono = embeddingService.generateEmbeddingAsync(&quot;Sample text to embed&quot;);\nembeddingMono.subscribe(embedding -&gt; {\n    // Process the embedding\n    System.out.println(&quot;Embedding: &quot; + embedding);\n});\n\n// For multiple pieces of text\nList&lt;String&gt; texts = Arrays.asList(&quot;First text&quot;, &quot;Second text&quot;);\nMono&lt;List&lt;Embedding&gt;&gt; embeddingsMono = embeddingService.generateEmbeddingsAsync(texts);\nembeddingsMono.subscribe(embeddings -&gt; {\n    // Process the list of embeddings\n    embeddings.forEach(System.out::println);\n});\n Field Summary EMBEDDING_DIMENSIONS_LARGE: Dimension size for the text-embedding-3-large model. EMBEDDING_DIMENSIONS_SMALL: Dimension size for the text-embedding-3-small model. Constructor Summary The OpenAITextEmbeddingGenerationService constructor initializes the service using a configured OpenAIAsyncClient along with necessary identifiers such as deploymentName, modelId, and serviceId. Methods Summary builder(): Creates a builder for constructing an instance of this service. generateEmbeddingAsync(String data): Generates embedding for a single string. generateEmbeddingsAsync(List data): Generates embeddings for a list of strings. This class provides a powerful and flexible way to integrate OpenAI&rsquo;s embedding capabilities into Java applications using Microsoft Semantic Kernel. Diagram ","timestamp":1763300447690},"references/eClassifiers/Kernel/references/eStructuralFeatures/aiServiceSelector/index.html":{"path":"Kernel/References/aiServiceSelector","link-uuid":"c1fb22be-e6b7-46b7-9323-786ad4cd5e16","title":"aiServiceSelector","content":"Type AIServiceSelector Multiplicity 0..1 AIServiceSelector in Microsoft Semantic Kernel Java The AIServiceSelector is a class responsible for selecting an AI service within the Semantic Kernel framework. This class can be extended and customized by subclassing it and overriding methods to modify its behavior. AIServiceSelector Class Overview Purpose: Selects an AI Service on a first-come, first-served basis. It first considers execution settings specified in arguments, then settings from the function being executed. If a service_id overlaps, the one provided in the arguments takes precedence. Customization: You can subclass the AIServiceSelector and override the select_ai_service method to customize how AI services are selected. Default Behavior The select_ai_service method in Java facilitates selecting an AI Service when not customized. Here&rsquo;s how it operates: // Assume kernel is already created with a collection of services\nAIServiceSelector serviceSelector = kernel.getServiceSelector();\n\n// Somewhere in your service selection or invocation logic\nAIServiceClientBase selectedService = serviceSelector.select_ai_service(\n    kernel,\n    exampleFunction, // an instance of KernelFunction or similar\n    exampleArguments, // KernelArguments or suitable arguments\n    ExampleAIService.class // Type of the AI service to select\n);\n In Java, when creating an instance of Kernel, you provide it with an AIServiceSelector. The kernel uses this selector to determine which AI services are invoked during function executions. Kernel Class Integration with AIServiceSelector import com.microsoft.semantickernel.Kernel;\nimport com.microsoft.semantickernel.services.AIServiceCollection;\nimport com.microsoft.semantickernel.services.AIServiceSelector;\nimport com.microsoft.semantickernel.plugin.KernelPlugin;\nimport com.microsoft.semantickernel.hooks.KernelHooks;\n\nimport java.util.function.Function;\nimport java.util.List;\n\n// Initialize Kernel with an AIServiceSelector\nKernel kernel = new Kernel(\n    new AIServiceCollection(/* service configurations */),\n    services -&gt; new AIServiceSelector(),  // or a custom implementation\n    List.of(/* KernelPlugin instances */),\n    new KernelHooks()\n);\n In the above example, the Kernel class is initialized with a set of services, a service selector provider, a list of plugins, and global kernel hooks. The serviceSelectorProvider can either use the default AIServiceSelector or be replaced with a custom implementation for advanced service selection logic. This allows the Kernel to interact dynamically with a variety of AI services, with the selector determining which specific service to route requests to.","timestamp":1763300447602},"references/eClassifiers/TextGenerationService/inheritance.html":{"path":"TextGenerationService/Inheritance","link-uuid":"2fc0f0bd-40d0-4297-85ee-91def62ba56a","title":"Inheritance","content":"Supertypes Subtypes  ","timestamp":1763300448197}}